[{"id":0,"href":"/note-cs/docs/study/book/basic/pl/go-in-action/zh/","title":"Go 语言实战","section":"Go in Action","content":" Go 语言实战 # 译者 # 李兆海，多年专注于后端分布式网络服务开发，曾使用过多个流行后端技术和相关架构实践，是 Go 语言和 Docker 的早期使用者和推广者，《第 1 本 Docker 书》的译者。作为项目技术负责人，成功开发了百万用户级直播系统。\n"},{"id":1,"href":"/note-cs/docs/basic/os/type/linux/","title":"Linux","section":"操作系统类型","content":" Linux # 详见：Linux 学习笔记\n"},{"id":2,"href":"/note-cs/docs/basic/pl/shell/command/ps/","title":"ps","section":"1.3.1 Shell 命令","content":" ps # "},{"id":3,"href":"/note-cs/docs/direction/be/db/mysql/basic/quick-start/","title":"Quick Start","section":"第一部分 基础入门","content":" Quick Start # Mysql Client # /etc/my.cnf\nMysql Server # "},{"id":4,"href":"/note-cs/docs/basic/pl/shell/type/sh/","title":"sh","section":"1.3.4 Shell 类型","content":" sh # 标记为 #!/bin/sh 的脚本不应使用任何 POSIX 没有规定的特性 (如 let 等命令，但 #!/bin/bash 可以)。\n"},{"id":5,"href":"/note-cs/docs/study/book/others/practical-vim/zh/","title":"Vim 实用技巧（第 2 版）","section":"Practical Vim","content":" Vim 实用技巧（第 2 版） # 译者 # 杨源 / 车文隆\n"},{"id":6,"href":"/note-cs/docs/tool/macos/imagehost/","title":"图床","section":"4.1 MacOS","content":" 图床 # 图床选择 # GitHub + jsdelivr # 上传图床软件 # PicGo # 参考官网：https://github.com/Molunerfinn/PicGo\nvs-picgo # https://github.com/PicGo/vs-picgo\n"},{"id":7,"href":"/note-cs/docs/domain/cc/istio/advanced/deploy/install/","title":"安装","section":"2.1 部署","content":" Istio 安装 # "},{"id":8,"href":"/note-cs/docs/direction/be/db/mysql/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # 问答 # Mysql 不指定 ip 与指定本地 ip，有什么区别？ # "},{"id":9,"href":"/note-cs/docs/direction/be/db/postgresql/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" PostgreSQL 实践 # "},{"id":10,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":11,"href":"/note-cs/docs/direction/client/android/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":12,"href":"/note-cs/docs/direction/client/ios/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":13,"href":"/note-cs/docs/direction/client/xiaochengxu/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":14,"href":"/note-cs/docs/direction/fe/frame/angular/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":15,"href":"/note-cs/docs/direction/fe/frame/react/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":16,"href":"/note-cs/docs/direction/fe/frame/vue/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":17,"href":"/note-cs/docs/direction/be/db/postgresql/basic/quick-start/","title":"快速上手","section":"第一部分 基础入门","content":" PostgreSQL 快速上手 # 安装 # MacOS # 安装：brew install postgresql 启动：brew services start postgresql 创建用户名数据库：createdb 基础命令 # 登录 PostgreSQL 控制台：psql # psql -U [user] -d [database] -h [host] -p [port]\n默认 psql\nuser：当前mac用户 database：用户同名数据库 主机：localhost 端口号：5432，postgresql的默认端口是5432 \\l # 使用 \\l 命令列出所有的数据库，看到已存在用户同名数据库、postgres 数据库。 但是 postgres 数据库的所有者是当前用户，没有 postgres 用户。\n创建 postgres 用户：CREATE USER postgres WITH PASSWORD 'password'; 删除默认生成的 postgres 数据库：DROP DATABASE postgres; 创建属于 postgres 用户的 postgres 数据库：CREATE DATABASE postgres OWNER postgres; 将数据库所有权限赋予 postgres 用户：GRANT ALL PRIVILEGES ON DATABASE postgres to postgres; 给 postgres 用户添加创建数据库的属性：ALTER ROLE postgres CREATEDB; 常用控制台命令 # \\password：设置当前登录用户的密码 \\h：查看SQL命令的解释，比如\\h select。 \\?：查看psql命令列表。 \\l：列出所有数据库。 \\c [database_name]：连接其他数据库。 \\d：列出当前数据库的所有表格。 \\d [table_name]：列出某一张表格的结构。 \\du：列出所有用户。 \\e：打开文本编辑器。 \\conninfo：列出当前数据库和连接的信息。 \\password [user]: 修改用户密码 \\q：退出 查询 # \\x # 类似 mysql 的 \\G\n# \\x Expanded display is on. # \\x Expanded display is off. 参考：\nDisplay select results vertically in psql, as is done by MySQL\u0026rsquo;s \\G 权限 # GRANT # GRANT on the database is not what you need. Grant on the tables directly.\nGranting privileges on the database mostly is used to grant or revoke connect privileges. This allows you to specify who may do stuff in the database if they have sufficient other permissions.\nGRANT ALL PRIVILEGES ON TABLE side_adzone TO jerry; 参考：\nPermission denied for relation "},{"id":18,"href":"/note-cs/docs/direction/be/db/mysql/basic/practice/optimize/","title":"性能优化","section":"实践","content":" Mysql 性能优化 # 存储引擎 # 使用 Innodb 存储引擎 # 没有特殊要求（即 Innodb 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 Innodb 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 Innodb）。\nInnodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。\n编码 # 统一使用 UTF8 # 库和表的字符集统一使用 UTF8\n表 # 控制单表数据量的大小 # 建议在 500 万以内。500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。\n可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小\n谨慎使用 MySQL 分区表 # 分区表在物理上表现为多个文件，在逻辑上表现为一个表；\n谨慎选择分区键，跨分区查询效率可能更低；\n建议采用物理分表的方式管理大数据。\n冷热数据分离，减小表的宽度 # MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。\n减少磁盘 IO, 保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大，也会消耗更多的 IO）；\n更有效的利用缓存，避免读入无用的冷数据；\n经常一起使用的列放到一个表中（避免更多的关联操作）。\n优先选择小的数据类型 # 列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。\n如：\n将 IP 地址转换成整形数据 对于非负型的数据 (如自增 ID, 整型 IP) 来说，要优先使用无符号整型来存储 列定义为 NOT NULL # 索引 NULL 列需要额外的空间来保存，所以要占用更多的空间。\n进行比较和计算时要对 NULL 值做特别的处理。\n索引 # 限制每张表上的索引数量 # 建议单张表索引不超过 5 个 索引并不是越多越好！索引可以提高效率同样可以降低效率。\n索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。\n因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。\n必须有个主键 # Innodb 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。\nInnodb 是按照主键索引的顺序来组织表的\n不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引） 不要使用 UUID,MD5,HASH, 字符串列作为主键（无法保证数据的顺序增长） 主键建议使用自增 ID 值 开发 # 避免数据类型的隐式转换 # 避免使用双 % 号的查询条件 # 联合索引 # 在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧。\n一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。\n使用 left join 替代 not in 操作 # 使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。\n参考 # MySQL 高性能优化规范建议 "},{"id":19,"href":"/note-cs/docs/basic/pl/assembly/basic/","title":"第一部分 基础入门","section":"汇编","content":" NASM: Netwide Assembler # 基于 x86 架构的汇编与反汇编软件。它可以用来编写 16 位（8086、80286 等）、32 位（IA-32）和 64 位（x86_64）的程序。 NASM 被认为是 Linux 平台上最受欢迎的汇编工具之一。\nNASM 可以输出多种二进制格式：\n通用对象文件格式（COFF） OMF（Relocatable Object Module Format，用于 80x86 系列处理器上） a.out 可执行与可链接格式（ELF） 地址无关代码仅支持 ELF 对象文件。 Mach-O 二进制文件（.bin，二进制磁盘映像，用于编译操作系统） Hello World # nasm -f macho64 -o test.o test.asm ld -o test test.o -macosx_version_min 11.5 -lSystem -L$(xcode-select -p)/SDKs/MacOSX.sdk/usr/lib ./test 参考：\nnasm - Can\u0026rsquo;t link object file with ld on macOS Mojave SECTION .data msg: db \u0026#34;hello assembly.\u0026#34;, 0x0a len: equ $-msg SECTION .text global _main kernel: syscall ret _main: mov rax,0x2000004 mov rdi,1 mov rsi,msg mov rdx,len call kernel mov rax,0x2000001 mov rdi,0 call kernel "},{"id":20,"href":"/note-cs/docs/direction/be/db/mysql/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":21,"href":"/note-cs/docs/direction/be/db/postgresql/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":22,"href":"/note-cs/docs/direction/be/db/redis/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":23,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":24,"href":"/note-cs/docs/direction/client/android/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":25,"href":"/note-cs/docs/direction/client/ios/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":26,"href":"/note-cs/docs/direction/client/xiaochengxu/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":27,"href":"/note-cs/docs/direction/embedded/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":28,"href":"/note-cs/docs/direction/fe/frame/angular/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":29,"href":"/note-cs/docs/direction/fe/frame/react/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":30,"href":"/note-cs/docs/direction/fe/frame/vue/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":31,"href":"/note-cs/docs/direction/security/basic/practice/spec/","title":"编程规范","section":"实践","content":" 编程规范 # "},{"id":32,"href":"/note-cs/docs/basic/pl/shell/type/bash/","title":"Bash","section":"1.3.4 Shell 类型","content":" Bash # "},{"id":33,"href":"/note-cs/docs/basic/compile/make/makefile/","title":"makefile","section":"make","content":" makefile # make 不带参数，只会执行 makefile 中第一条 target 声明（带冒号的语句）\n简介 # Makefile 用于定义如何创建目标文件，比如如何从源码到可执行文件。 创建这一工具的目标是 减少不必要的编译或者任务。 传说 Stuart Feldman 在 1976 年花了一个周末写出来的， 而今仍然使用广泛，特别是在 Unix 和 Linux 系统上。\n基础 # 语法 # 注释：# 文件名： 必须是 Makefile 区分大小写 make \u0026lt;target\u0026gt; 生成 target 重命名：make -f \u0026quot;filename\u0026quot; \u0026lt;target\u0026gt; 只认识 TAB，不认识空格 但是在 GNU Make 3.82 之后, 可以通过设置参数 .RECIPEPREFIX 进行修改 shell 符号 @：不把命令打印到 stdout -：发生错误了也没关系 $$ $ 是 make 变量 $$ 是 shell 变量 target 声明 # 创建一个 target： targets : prerequisites recipe prerequisites(依赖) 是可选的, recipe(做法) 也可以多个或者不给 没有给 prerequisites, 只会在目标文件文件不存在时执行 targets 和 prerequisites 都可以是多个, 以空格分割 file2.txt file3.txt: file0.txt file1.txt touch file2.txt touch file3.txt target 的声明顺序不重要 上面的依赖可以下面再声明 如果声明重复的 target，make 会给一个 warning，后面会覆盖前面的 但是如果不定义任何 recipe, 就不会冲突, 只是多了依赖关系 file2.txt: file0.txt file3.txt Phony(假的) Targets 意思是 tagets 并不是文件, 可以想象成一个任务的名字而已 因为不是文件, 无法比对是否有更新, 所以每次 make 都会执行 依赖于 phony target 的 target 也会每次 make 都执行, 即使 target 是文件 .PHONY 如果定义的 phony target 与文件名重名, 可以用 .PHONY 显式地指明哪些 targets 是 phony 常用 phony target # all clean install uninstall 变量与通配符 # $^: 代表 prerequisites # 即便分开定义依赖, $^ 依然能拿到 process: file*.txt # 非常智能的, ex1.txt 会被找到, file0.txt 会被去重 process: ex1.txt file0.txt @echo $^ $@: 代表 target, 如果 target 为多个, $@ 代表当前执行的那个 $\u0026lt;: prerequisite 中的第一个 $?: 需要更新的 prerequisite 文件列表 $+: 所有依赖, 包括重复的 $|: 竖线后面的 order-only prerequisites $*: target % 那部分, 包括路径 a.%.b: # $* match 的target % 那部分, 包括路径, 比如 `make dir/a.foo.b` 会打出 `dir/foo` @echo $* 模式匹配 # make 会找到最具体的匹配 make small/foo.png 则会匹配下面这个规则（在这之前要先有 small/foo.svg 这个文件） %.png: %.svg inkscape --export-png $^ small/%.png: %.svg inkscape --export-png --export-dpi 30 $^ make 已经有一些内置的规则, 比如从 _.c 到 _.o 竖线 # 竖线左边为：正常前提目标（Normal Prerequisites） 当正常前提目标变化时，target 重新生成 可以为空 竖线右边为：命令前提目标（order-only Prerequisites） 当命令前提目标变化时，target 不重新生成 process: file*.txt | dir/a.foo.b 变量 # 变量都是字符串类型\n# 这俩是一样一样的 name = Ted name2=\u0026#34;Sarah\u0026#34; 设置变量，按以下顺序由高到低:\n命令行参数. 比如试试 make echo name3=JICHAO Makefile 里面的 shell 中的环境变量 make 预设的一些变量 ?=\n# 如果 name 被设置过了, 就不设置了 name ?= Jean override\n# 用 override 可以防止命令行参数设置的覆盖 override name = David `` +\n# 用加号可以连接 (中间用空格分割) name4 +=grey 内置的变量\necho_inbuilt: echo $(CC) echo ${CXX)} echo $(FC) echo ${CFLAGS)} echo $(CPPFLAGS) echo ${CXXFLAGS} echo $(LDFLAGS) echo ${LDLIBS} :=\n等号声明时 recursively expanded 递归扩展 加个冒号可以声明 Simply expanded variables 即时扩展变量, 即只在声明时扩展一次 # var3 声明时找不到 var4, var3 会扩展成 `and good luck`，直接忽视 var4 var3 := $(var4) and good luck # var5 是正常的，扩展为 `good night and good luck` var5 = $(var4) and good luck var4 := good night 函数 # 函数调用格式\n$(func arg0,arg1,arg2...) wildcard：将后面的通配符变成一串文件路径\npatsubst：做替换\n# 把所有 markdown 后缀的文件重命名为 md 后缀 substitue: * @echo $(patsubst %.markdown,%.md,$* $^) 指令 # include：引入别的 Makefile 文件 流程控制语句顶格写 sport = tennis # 流程控制语句 (如if else 等等) 顶格写 report: ifeq ($(sport),tennis) @echo \u0026#39;game, set, match\u0026#39; else @echo \u0026#34;They think it\u0026#39;s all over; it is now\u0026#34; endif 分支和变体 # GNU make # 进阶 # 原理 # "},{"id":34,"href":"/note-cs/docs/study/skill/type/markdown/","title":"markdown","section":"文档类型","content":" markdown # 图片大小设置 \u0026lt;img src=\u0026quot;xxx\u0026quot; width=\u0026quot;30%\u0026quot; height=\u0026quot;30%\u0026quot;\u0026gt;\n"},{"id":35,"href":"/note-cs/docs/study/skill/type/markdown/formula/","title":"markdown 公式","section":"markdown","content":" \\(\\) markdown 公式 # 来源：一文学会在 Markdown 中编辑数学符号与公式\n行内公式：将公式插入到本行内 我在 1 年后：$0.99^{365} \\approx 0.02551796$\n$0.99^{365} \\approx 0.02551796$ 单独的公式块：将公式插入到新的一行内，并且居中 观众老爷们在 1 年后：\n$$ 1.01^{365} \\approx 37.78343433 $$\n$$ 1.01^{365} \\approx 37.78343433 $$ 符号 # 上下标、运算符 # 显示效果 markdown 公式语法 上标 $x^2、 x^y 、e^{365}$ x^2、 x^y 、e^{365} 下标 $x_0、a_1、Y_a$ x_0、a_1、Y_a 分式 $\\frac{x}{y}、\\frac{1}{x+1}$ \\frac{x}{y}、\\frac{1}{x+1} 乘 $\\times$ \\times 除 $\\div$ \\div 加减 $\\pm$ \\pm 减加 $\\mp$ \\mp 求和 $\\sum$ \\sum 求和上下标 $\\sum_0^3 、\\sum_0^{\\infty} 、\\sum_{-\\infty}^{\\infty}$ \\sum_0^3 、\\sum_0^{\\infty} 、\\sum_{-\\infty}^{\\infty} 求积 $\\prod$ \\prod 微分 $\\partial$ \\partial 积分 $\\int 、\\displaystyle\\int$ \\int 、\\displaystyle\\int 不等于 $\\neq$ \\neq 大于等于 $\\geq$ \\geq 小于等于 $\\leq$ \\leq 约等于 $\\approx$ \\approx 不大于等于 $x+y \\ngeq z$ x+y \\ngeq z 点乘 $a \\cdot b$ a \\cdot b 星乘 $a \\ast b$ a \\ast b 取整函数 $\\left \\lfloor \\frac{a}{b} \\right \\rfloor$ \\left \\lfloor \\frac{a}{b} \\right \\rfloor 取顶函数 $\\left \\lceil \\frac{c}{d} \\right \\rceil$ \\left \\lceil \\frac{c}{d} \\right \\rceil 括号 # 显示效果 markdown 公式语法 圆括号（小括号） $\\left( \\frac{a}{b} \\right)$ \\left( \\frac{a}{b} \\right) 方括号（中括号） $\\left[ \\frac{a}{b} \\right]$或者$[ \\frac{x}{y} ]$ \\left[ \\frac{a}{b} \\right]或者[ \\frac{x}{y} ] 花括号（大括号） $\\lbrace \\frac{a}{b} \\rbrace$ \\lbrace \\frac{a}{b} \\rbrace 角括号 $\\left \\langle \\frac{a}{b} \\right \\rangle$ \\left \\langle \\frac{a}{b} \\right \\rangle 混合括号 $\\left [ a,b \\right )$ \\left [ a,b \\right ) 三角函数、指数、对数 # 显示效果 markdown 公式语法 sin $\\sin(x)$ \\sin(x) cos $\\cos(x)$ \\cos(x) tan $\\tan(x)$ \\tan(x) cot $\\cot(x)$ \\cot(x) log $\\log_2 10$ \\log_2 10 lg $\\lg 100$ \\lg 100 ln $\\ln2$ \\ln2 数学符号 # 显示效果 markdown 公式语法 无穷 $\\infty$ \\infty 矢量 $\\vec{a}$ \\vec{a} 一阶导数 $\\dot{x}$ \\dot{x} 二阶导数 $\\ddot{x}$ \\ddot{x} 算数平均值 $\\bar{a}$ \\bar{a} 概率分布 $\\hat{a}$ \\hat{a} 虚数 i、j $\\imath、\\jmath$ \\imath、\\jmath 省略号(一) $1,2,3,\\ldots,n$ 1,2,3,\\ldots,n 省略号(二) $x_1 + x_2 + \\cdots + x_n$ x_1 + x_2 + \\cdots + x_n 省略号(三) $\\vdots$ \\vdots 省略号(四) $\\ddots$ \\ddots 斜线与反斜线 $\\left / \\frac{a}{b} \\right \\backslash$ \\left / \\frac{a}{b} \\right \\backslash 上下箭头 $\\left \\uparrow \\frac{a}{b} \\right \\downarrow$ \\left \\uparrow \\frac{a}{b} \\right \\downarrow $\\angle$ $\\angle$ \\angle $\\prime$ $\\prime$ \\prime $\\rightarrow$ $\\rightarrow$ \\rightarrow $\\leftarrow$ $\\leftarrow$ \\leftarrow $\\Rightarrow$ $\\Rightarrow$ \\Rightarrow $\\Leftarrow$ $\\Leftarrow$ \\Leftarrow $\\Uparrow$ $\\Uparrow$ \\Uparrow $\\Downarrow$ $\\Downarrow$ \\Downarrow $\\longrightarrow$ $\\longrightarrow$ \\longrightarrow $\\longleftarrow$ $\\longleftarrow$ \\longleftarrow $\\Longrightarrow$ $\\Longrightarrow$ \\Longrightarrow $\\Longleftarrow$ $\\Longleftarrow$ \\Longleftarrow $\\nabla$ $\\nabla$ \\nabla $\\because$ $\\because$ \\because $\\therefore$ $\\therefore$ \\therefore $\\mid$ $\\mid$ \\mid $\\backslash$ $\\backslash$ \\backslash $\\forall$ $\\forall$ \\forall $\\exists$ $\\exists$ \\exists $\\backsim$ $\\backsim$ \\backsim $\\cong$ $\\cong$ \\cong $\\oint$ $\\oint$ \\oint $\\implies$ $\\implies$ \\implies $\\iff$ $\\iff$ \\iff $\\impliedby$ $\\impliedby$ \\impliedby 连线符号 # 显示效果 markdown 公式语法 $\\overleftarrow{a+b+c}$ \\overleftarrow{a+b+c} $\\overrightarrow{a+b+c}$ \\overrightarrow{a+b+c} $\\overleftrightarrow{a+b+c}$ \\overleftrightarrow{a+b+c} $\\underleftarrow{a+b+c}$ \\underleftarrow{a+b+c} $\\underrightarrow{a+b+c}$ \\underrightarrow{a+b+c} $\\underleftrightarrow{a+b+c}$ \\underleftrightarrow{a+b+c} $\\overline{a+b+c}$ \\overline{a+b+c} $\\underline{a+b+c}$ \\underline{a+b+c} $\\overbrace{a+b+c}^{Sample}$ \\overbrace{a+b+c}^{Sample} $\\underbrace{a+b+c}_{Sample}$ \\underbrace{a+b+c}_{Sample} $\\overbrace{a+\\underbrace{b+c}_{1.0}}^{2.0}$ \\overbrace{a+\\underbrace{b+c}_{1.0}}^{2.0} $\\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}}$ \\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}} 高级运算符 # 显示效果 markdown 公式语法 平均数运算 $\\overline{xyz}$ \\overline{xyz} 开二次方运算 $\\sqrt {xy}$ \\sqrt {xy} 开方运算 $\\sqrt[n]{x}$ \\sqrt[n]{x} 极限运算(一) $\\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ \\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}} 极限运算(二) $\\displaystyle \\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ \\displaystyle \\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}} 求和运算(一) $\\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ \\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}} 求和运算(二) $\\displaystyle \\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ \\displaystyle \\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}} 积分运算(一) $\\int^{\\infty}_{0}{xdx}$ \\int^{\\infty}_{0}{xdx} 积分运算(二) $\\displaystyle \\int^{\\infty}_{0}{xdx}$ \\displaystyle \\int^{\\infty}_{0}{xdx} 微分运算 $\\frac{\\partial x}{\\partial y}、\\frac{\\partial^2x}{\\partial y^2}$ \\frac{\\partial x}{\\partial y}、\\frac{\\partial^2x}{\\partial y^2} 集合运算 # 显示效果 markdown 公式语法 属于 $A \\in B$ A \\in B 不属于 $A \\notin B$ A \\notin B 子集 $x \\subset y、y \\supset x$ x \\subset y、y \\supset x 真子集 $x \\subseteq y、y \\supseteq x$ x \\subseteq y、y \\supseteq x 并集 $A \\cup B$ A \\cup B 交集 $A \\cap B$ A \\cap B 差集 $A \\setminus B$ A \\setminus B 同或 $A \\bigodot B$ A \\bigodot B 同与 $A \\bigotimes B$ A \\bigotimes B 异或 $A \\bigoplus B$ A \\bigoplus B 实数集合 $\\mathbb{R}$ \\mathbb{R} 自然数集合 $\\mathbb{Z}$ \\mathbb{Z} 希腊字母 # 大写字母 markdown 语法 小写字母 markdown 语法 中文注音 $A$ A $\\alpha$ \\alpha 阿尔法 $B$ B $\\beta$ \\beta 贝塔 $\\Gamma$ \\Gamma $\\gamma$ \\gamma 伽马 $\\Delta$ \\Delta $\\delta$ \\delta 德尔塔 $E$ E $\\epsilon$ \\epsilon 伊普西龙 $Z$ Z $\\zeta$ \\zeta 截塔 $H$ H $\\eta$ \\eta 艾塔 $\\Theta$ \\Theta $\\theta$ \\theta 西塔 $I$ I $\\iota$ \\iota 约塔 $K$ K $\\kappa$ \\kappa 卡帕 $\\Lambda$ \\Lambda $\\lambda$ \\lambda 兰布达 $M$ M $\\mu$ \\mu 缪 $N$ N $\\nu$ \\nu 纽 $\\Xi$ \\Xi $\\xi$ \\xi 克西 $O$ O $\\omicron$ \\omicron 奥密克戎 $\\Pi$ \\Pi $\\pi$ \\pi 派 $P$ P $\\rho$ \\rho 肉 $\\Sigma$ \\Sigma $\\sigma$ \\sigma 西格马 $T$ T $\\tau$ \\tau 套 $\\Upsilon$ \\Upsilon $\\upsilon$ \\upsilon 宇普西龙 $\\Phi$ \\Phi $\\phi$ \\phi 佛爱 $X$ X $\\chi$ \\chi 西 $\\Psi$ \\Psi $\\psi$ \\psi 普西 $\\Omega$ \\Omega $\\omega$ \\omega 欧米伽 字体转换 # 若要对公式的某一部分字符进行字体转换，可以用 {\\font {需转换的部分字符}} 命令，其中\\font部分可以参照下表选择合适的字体。一般情况下，公式默认为意大利体。\n字体 显示效果 markdown 语法 罗马体 $\\rm D$ \\rm D 花体 $\\cal D$ \\cal D 意大利体 $\\it D$ \\it D 黑板粗体 $\\Bbb D$ \\Bbb D 粗体 $\\bf D$ \\bf D 数学斜体 $\\mit D$ \\mit D 等线体 $\\sf D$ \\sf D 手写体 $\\scr D$ \\scr D 打字机体 $\\tt D$ \\tt D 旧德式字体 $\\frak D$ \\frak D 黑体 $\\boldsymbol D$ \\boldsymbol D 公式 # 基本函数公式 # 行内公式：$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ $\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ 行间公式： $$ \\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt $$\n$$ \\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt $$ $y_k=\\varphi(u_k+v_k)$ $y_k=\\varphi(u_k+v_k)$ $y(x)=x^3+2x^2+x+1$ $y(x)=x^3+2x^2+x+1$ $x^{y}=(1+{\\rm e}^x)^{-2xy}$ $x^{y}=(1+{\\rm e}^x)^{-2xy}$ $\\displaystyle f(n)=\\sum_{i=1}^{n}{n*(n+1)}$ $\\displaystyle f(n)=\\sum_{i=1}^{n}{n*(n+1)}$ 分段函数 # 分段函数： $$ y=\\begin{cases} 2x+1, \u0026amp; x \\leq0\\\\ x, \u0026amp; x\u0026gt;0 \\end{cases} $$\n$$ y=\\begin{cases} 2x+1, \u0026amp; x \\leq0\\\\\\\\ x, \u0026amp; x\u0026gt;0 \\end{cases} $$ 方程组： $$ \\left \\{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\end{array} \\right. $$\n$$ \\left \\\\{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\\\\\\\ a_2x+b_2y+c_2z=d_2 \\\\\\\\ a_3x+b_3y+c_3z=d_3 \\end{array} \\right. $$ 积分 # 积分书写： $$ \\int_{\\theta_1(x)}^{\\theta_2(x)}=l $$\n$$ \\int_{\\theta_1(x)}^{\\theta_2(x)}=l $$ 二重积分： $$ \\iint dx dy=\\sigma $$\n$$ \\iint dx dy=\\sigma $$ 三重积分： $$ \\iiint dx dydz=\\nu $$\n$$ \\iiint dx dydz=\\nu $$ 微分和偏微分 # 一阶微分方程： $$ \\frac{dy}{dx}+P(x)y=Q(x) $$\n$$ \\frac{dy}{dx}+P(x)y=Q(x) $$ $$ \\left. \\frac{{\\rm d}y}{{\\rm d}x} \\right|_{x=0}=3x+1=1 $$\n$$ \\left. \\frac{{\\rm d}y}{{\\rm d}x} \\right|_{x=0}=3x+1=1 $$ 二阶微分方程： $$ y\u0026rsquo;\u0026rsquo;+py\u0026rsquo;+qy=f(x) $$\n$$ y\u0026#39;\u0026#39;+py\u0026#39;+qy=f(x) $$ $$ \\frac{d^2y}{dx^2}+p\\frac{dy}{dx}+qy=f(x) $$\n$$ \\frac{d^2y}{dx^2}+p\\frac{dy}{dx}+qy=f(x) $$ 偏微分方程： $$ \\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2}+ \\frac{\\partial^2 u}{\\partial z^2}\\right) $$\n$$ \\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2}+ \\frac{\\partial^2 u}{\\partial z^2}\\right) $$ 矩阵和行列式 # 起始标记 \\begin{matrix} ,结束标记\\end{matrix},每一行末尾标记\\\\，行间元素之间以\u0026amp;分隔。在起始、结束标记处用下列词替换matrix。\npmatrix ：小括号边框 $$ \\begin{pmatrix} 1\u0026amp;2\\\\ 3\u0026amp;4\\\\ \\end{pmatrix} $$\n$$ \\begin{pmatrix} 1\u0026amp;2\\\\\\\\ 3\u0026amp;4\\\\\\\\ \\end{pmatrix} $$ bmatrix ：中括号边框 $$ \\begin{bmatrix} 1\u0026amp;2\\\\ 3\u0026amp;4\\\\ \\end{bmatrix} $$\n$$ \\begin{bmatrix} 1\u0026amp;2\\\\\\\\ 3\u0026amp;4\\\\\\\\ \\end{bmatrix} $$ Bmatrix ：大括号边框 $$ \\begin{Bmatrix} 1\u0026amp;2\\\\ 3\u0026amp;4\\\\ \\end{Bmatrix} $$\n$$ \\begin{Bmatrix} 1\u0026amp;2\\\\\\\\ 3\u0026amp;4\\\\\\\\ \\end{Bmatrix} $$ vmatrix ：单竖线边框 $$ \\begin{vmatrix} 1\u0026amp;2\\\\ 3\u0026amp;4\\\\ \\end{vmatrix} $$\n$$ \\begin{vmatrix} 1\u0026amp;2\\\\\\\\ 3\u0026amp;4\\\\\\\\ \\end{vmatrix} $$ Vmatrix ：双竖线边框 $$ \\begin{Vmatrix} 1\u0026amp;2\\\\ 3\u0026amp;4\\\\ \\end{Vmatrix} $$\n$$ \\begin{Vmatrix} 1\u0026amp;2\\\\\\\\ 3\u0026amp;4\\\\\\\\ \\end{Vmatrix} $$ 无框矩阵： $$ \\begin{matrix} 1 \u0026amp; x \u0026amp; x^2 \\\\ 1 \u0026amp; y \u0026amp; y^2 \\\\ 1 \u0026amp; z \u0026amp; z^2 \\\\ \\end{matrix} $$\n$$ \\begin{matrix} 1 \u0026amp; x \u0026amp; x^2 \\\\\\\\ 1 \u0026amp; y \u0026amp; y^2 \\\\\\\\ 1 \u0026amp; z \u0026amp; z^2 \\\\\\\\ \\end{matrix} $$ 单位矩阵： $$ \\begin{bmatrix} 1\u0026amp;0\u0026amp;0\\\\ 0\u0026amp;1\u0026amp;0\\\\ 0\u0026amp;0\u0026amp;1\\\\ \\end{bmatrix} $$\n$$ \\begin{bmatrix} 1\u0026amp;0\u0026amp;0\\\\\\\\ 0\u0026amp;1\u0026amp;0\\\\\\\\ 0\u0026amp;0\u0026amp;1\\\\\\\\ \\end{bmatrix} $$ $m \\times n$矩阵： $$ A=\\begin{bmatrix} {a_{11}}\u0026amp;{a_{12}}\u0026amp;{\\cdots}\u0026amp;{a_{1n}}\\\\ {a_{21}}\u0026amp;{a_{22}}\u0026amp;{\\cdots}\u0026amp;{a_{2n}}\\\\ {\\vdots}\u0026amp;{\\vdots}\u0026amp;{\\ddots}\u0026amp;{\\vdots}\\\\ {a_{m1}}\u0026amp;{a_{m2}}\u0026amp;{\\cdots}\u0026amp;{a_{mn}}\\\\ \\end{bmatrix} $$\n$$ A=\\begin{bmatrix} {a_{11}}\u0026amp;{a_{12}}\u0026amp;{\\cdots}\u0026amp;{a_{1n}}\\\\\\\\ {a_{21}}\u0026amp;{a_{22}}\u0026amp;{\\cdots}\u0026amp;{a_{2n}}\\\\\\\\ {\\vdots}\u0026amp;{\\vdots}\u0026amp;{\\ddots}\u0026amp;{\\vdots}\\\\\\\\ {a_{m1}}\u0026amp;{a_{m2}}\u0026amp;{\\cdots}\u0026amp;{a_{mn}}\\\\\\\\ \\end{bmatrix} $$ 行列式： $$ D=\\begin{vmatrix} {a_{11}}\u0026amp;{a_{12}}\u0026amp;{\\cdots}\u0026amp;{a_{1n}}\\\\ {a_{21}}\u0026amp;{a_{22}}\u0026amp;{\\cdots}\u0026amp;{a_{2n}}\\\\ {\\vdots}\u0026amp;{\\vdots}\u0026amp;{\\ddots}\u0026amp;{\\vdots}\\\\ {a_{m1}}\u0026amp;{a_{m2}}\u0026amp;{\\cdots}\u0026amp;{a_{mn}}\\\\ \\end{vmatrix} $$\n$$ D=\\begin{vmatrix} {a_{11}}\u0026amp;{a_{12}}\u0026amp;{\\cdots}\u0026amp;{a_{1n}}\\\\\\\\ {a_{21}}\u0026amp;{a_{22}}\u0026amp;{\\cdots}\u0026amp;{a_{2n}}\\\\\\\\ {\\vdots}\u0026amp;{\\vdots}\u0026amp;{\\ddots}\u0026amp;{\\vdots}\\\\\\\\ {a_{m1}}\u0026amp;{a_{m2}}\u0026amp;{\\cdots}\u0026amp;{a_{mn}}\\\\\\\\ \\end{vmatrix} $$ 表格： $$ \\begin{array}{c|lll} {}\u0026amp;{a}\u0026amp;{b}\u0026amp;{c}\\\\ \\hline {R_1}\u0026amp;{c}\u0026amp;{b}\u0026amp;{a}\\\\ {R_2}\u0026amp;{b}\u0026amp;{c}\u0026amp;{c}\\\\ \\end{array} $$\n$$ \\begin{array}{c|lll} {}\u0026amp;{a}\u0026amp;{b}\u0026amp;{c}\\\\\\\\ \\hline {R_1}\u0026amp;{c}\u0026amp;{b}\u0026amp;{a}\\\\\\\\ {R_2}\u0026amp;{b}\u0026amp;{c}\u0026amp;{c}\\\\\\\\ \\end{array} $$ 增广矩阵： $$ \\left[ \\begin{array} {c c | c} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ \\end{array} \\right] $$\n$$ \\left[ \\begin{array} {c c | c} 1 \u0026amp; 2 \u0026amp; 3 \\\\\\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\\\\\ \\end{array} \\right] $$ 案例 # ^表示上标, _ 表示下标。如果上下标的内容多于一个字符，需要用{}将这些内容括成一个整体。上下标可以嵌套，也可以同时使用。 $$ x^{y^z}=(1+{\\rm e}^x)^{-2xy^w} $$\n$$ x^{y^z}=(1+{\\rm e}^x)^{-2xy^w} $$ 其中\\rm表示字体转换，上面有过具体说明。\n()、[]和|表示符号本身，使用 \\{ \\} 来表示 {}。当要显示大号的括号或分隔符时，要用 \\left 和 \\right 命令。 $$ f(x,y,z) = 3y^2z \\left( 3+\\frac{7x+5}{1+y^2} \\right) $$\n$$ f(x,y,z) = 3y^2z \\left( 3+\\frac{7x+5}{1+y^2} \\right) $$ 行标的使用：在公式末尾前使用\\tag{行标}来实现行标。 $$ f\\left( \\left[ \\frac{ 1+\\left\\{x,y\\right\\} }{ \\left( \\frac{x}{y}+\\frac{y}{x} \\right) \\left(u+1\\right) }+a \\right]^{3/2} \\right) \\tag{公式1} $$\n$$ f\\left( \\left[ \\frac{ 1+\\left\\\\{x,y\\right\\\\} }{ \\left( \\frac{x}{y}+\\frac{y}{x} \\right) \\left(u+1\\right) }+a \\right]^{3/2} \\right) \\tag{公式1} $$ 有时要用 \\left. 或 \\right. 进行匹配而不显示本身。 $$ \\left. \\frac{{\\rm d}u}{{\\rm d}x} \\right| _{x=0} $$\n$$ \\left. \\frac{{\\rm d}u}{{\\rm d}x} \\right| _{x=0} $$ 添加注释文字 \\text $$ f(n)= \\begin{cases} n/2, \u0026amp; \\text {if $n$ is even} \\\\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\\\ \\end{cases} $$\n$$ f(n)= \\begin{cases} n/2, \u0026amp; \\text {if $n$ is even} \\\\\\\\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\\\\\\\ \\end{cases} $$ 整齐且居中的方程式序列 $$ \\begin{align} \\sqrt{37} \u0026amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\\\ \u0026amp; = \\frac{73}{12}\\sqrt{1-\\frac{1}{73^2}} \\\\ \u0026amp; \\approx \\frac{73}{12}\\left(1-\\frac{1}{2\\cdot73^2}\\right) \\\\ \\end{align} $$\n$$ \\begin{align} \\sqrt{37} \u0026amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\\\\\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\\\\\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\\\\\\\ \u0026amp; = \\frac{73}{12}\\sqrt{1-\\frac{1}{73^2}} \\\\\\\\ \u0026amp; \\approx \\frac{73}{12}\\left(1-\\frac{1}{2\\cdot73^2}\\right) \\\\\\\\ \\end{align} $$ 在一个方程式序列的每一行中注明原因 $$ \\begin{align} v + w \u0026amp; = 0 \u0026amp; \\text{Given} \\tag 1 \\\\ -w \u0026amp; = -w + 0 \u0026amp; \\text{additive identity} \\tag 2 \\\\ -w + 0 \u0026amp; = -w + (v + w) \u0026amp; \\text{equations $(1)$ and $(2)$} \\\\ \\end{align} $$\n$$ \\begin{align} v + w \u0026amp; = 0 \u0026amp; \\text{Given} \\tag 1 \\\\\\\\ -w \u0026amp; = -w + 0 \u0026amp; \\text{additive identity} \\tag 2 \\\\\\\\ -w + 0 \u0026amp; = -w + (v + w) \u0026amp; \\text{equations $(1)$ and $(2)$} \\\\\\\\ \\end{align} $$ 文字在左对齐显示 $$ \\left. \\begin{array}{l} \\text{if $n$ is even:} \u0026amp; n/2 \\\\ \\text{if $n$ is odd:} \u0026amp; 3n+1 \\\\ \\end{array} \\right\\} =f(n) $$\n$$ \\left. \\begin{array}{l} \\text{if $n$ is even:} \u0026amp; n/2 \\\\\\\\ \\text{if $n$ is odd:} \u0026amp; 3n+1 \\\\\\\\ \\end{array} \\right\\\\} =f(n) $$ 连分式 $$ x = a_0 + \\cfrac{1^2}{a_1 + \\cfrac{2^2}{a_2 + \\cfrac{3^2}{a_3 + \\cfrac{4^4}{a_4 + \\cdots } } } } $$\n$$ x = a_0 + \\cfrac{1^2}{a_1 + \\cfrac{2^2}{a_2 + \\cfrac{3^2}{a_3 + \\cfrac{4^4}{a_4 + \\cdots } } } } $$ 表格 通常，一个格式化后的表格比单纯的文字或排版后的文字更具有可读性。 数组和表格均以 \\begin{array} 开头，并在其后定义列数及每一列的文本对齐属性，c l r 分别代表居中、左对齐及右对齐。若需要插入垂直分割线，在定义式中插入 | ，若要插入水平分割线，在下一行输入前插入 \\hline 。 与矩阵相似，每行元素间均须要插入 \u0026amp; ，每行元素以 \\\\ 结尾，最后以 \\ end{array} 结束数组。\n$$ \\begin{array}{c|lcr} n \u0026amp; \\text{左对齐} \u0026amp; \\text{居中对齐} \u0026amp; \\text{右对齐} \\\\ \\hline 1 \u0026amp; 0.24 \u0026amp; 1 \u0026amp; 125 \\\\ 2 \u0026amp; -1 \u0026amp; 189 \u0026amp; -8 \\\\ 3 \u0026amp; -20 \u0026amp; 2000 \u0026amp; 1+10i \\\\ \\end{array} $$\n$$ \\begin{array}{c|lcr} n \u0026amp; \\text{左对齐} \u0026amp; \\text{居中对齐} \u0026amp; \\text{右对齐} \\\\\\\\ \\hline 1 \u0026amp; 0.24 \u0026amp; 1 \u0026amp; 125 \\\\\\\\ 2 \u0026amp; -1 \u0026amp; 189 \u0026amp; -8 \\\\\\\\ 3 \u0026amp; -20 \u0026amp; 2000 \u0026amp; 1+10i \\\\\\\\ \\end{array} $$ "},{"id":36,"href":"/note-cs/docs/domain/cc/istio/basic/arch/components/mixer/","title":"Mixer","section":"组件","content":" Mixer 基础 # Mixer 已弃用。\nMixer 所提供的功能已迁移至 Envoy 代理中。 在 Istio 中对 Mixer 的支持将截止到 Istio 1.7 发行版。\n请参考 Telemetry V2，它取代了 Mixer 遥测。\n"},{"id":37,"href":"/note-cs/docs/basic/os/type/android/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":38,"href":"/note-cs/docs/basic/os/type/ios/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":39,"href":"/note-cs/docs/basic/os/type/macos/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":40,"href":"/note-cs/docs/basic/os/type/unix/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":41,"href":"/note-cs/docs/basic/os/type/windows/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":42,"href":"/note-cs/docs/basic/pl/assembly/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":43,"href":"/note-cs/docs/basic/pl/erlang/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":44,"href":"/note-cs/docs/basic/pl/haskell/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":45,"href":"/note-cs/docs/basic/pl/lua/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":46,"href":"/note-cs/docs/basic/pl/r/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":47,"href":"/note-cs/docs/basic/pl/ruby/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":48,"href":"/note-cs/docs/basic/pl/swift/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":49,"href":"/note-cs/docs/direction/be/db/mysql/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":50,"href":"/note-cs/docs/direction/be/db/postgresql/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":51,"href":"/note-cs/docs/direction/be/db/redis/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # Redis 有哪些数据类型，分别适合什么场景？ # Redis 如何做持久化？ # Redis 如何实现高可用？ # Redis 如何与 Mysql 做一致性同步？ # "},{"id":52,"href":"/note-cs/docs/direction/be/platform/nodejs/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":53,"href":"/note-cs/docs/direction/client/android/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":54,"href":"/note-cs/docs/direction/client/ios/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":55,"href":"/note-cs/docs/direction/client/xiaochengxu/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":56,"href":"/note-cs/docs/direction/embedded/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":57,"href":"/note-cs/docs/direction/fe/frame/angular/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":58,"href":"/note-cs/docs/direction/fe/frame/react/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":59,"href":"/note-cs/docs/direction/fe/frame/vue/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":60,"href":"/note-cs/docs/direction/security/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":61,"href":"/note-cs/docs/study/book/basic/cc/csapp/","title":"深入理解计算机系统","section":"5.1.1 计算机组成原理","content":" 深入理解计算机系统 # 豆瓣 学习参考 # 如何阅读《深入理解计算机系统》这本书？ # EugeneLiu/translationCSAPP # 为 CSAPP 视频课程提供字幕，翻译 PPT，Lab\nDreamAndDead/CSAPP-3e-Solutions # CSAPP 3e Solutions gitbook\nvonzhou/CSAPP # CSAPP,《深入理解计算机系统结构》2nd ，阅读与实践！\nExely/CSAPP-Labs # Solutions and Notes for Labs of Computer Systems: A Programmer\u0026rsquo;s Perspective 3rd Editon // 《深入理解计算机系统》第三版的实验文件、解答与笔记\n"},{"id":62,"href":"/note-cs/docs/basic/os/type/android/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":63,"href":"/note-cs/docs/basic/os/type/ios/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":64,"href":"/note-cs/docs/basic/os/type/macos/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":65,"href":"/note-cs/docs/basic/os/type/unix/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":66,"href":"/note-cs/docs/basic/os/type/windows/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":67,"href":"/note-cs/docs/basic/pl/assembly/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":68,"href":"/note-cs/docs/basic/pl/erlang/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":69,"href":"/note-cs/docs/basic/pl/haskell/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":70,"href":"/note-cs/docs/basic/pl/lua/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":71,"href":"/note-cs/docs/basic/pl/r/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":72,"href":"/note-cs/docs/basic/pl/ruby/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":73,"href":"/note-cs/docs/basic/pl/swift/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":74,"href":"/note-cs/docs/direction/be/db/mysql/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":75,"href":"/note-cs/docs/direction/be/db/postgresql/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":76,"href":"/note-cs/docs/direction/be/db/redis/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":77,"href":"/note-cs/docs/direction/be/platform/nodejs/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":78,"href":"/note-cs/docs/direction/client/android/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":79,"href":"/note-cs/docs/direction/client/ios/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":80,"href":"/note-cs/docs/direction/client/xiaochengxu/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":81,"href":"/note-cs/docs/direction/embedded/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":82,"href":"/note-cs/docs/direction/fe/frame/angular/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":83,"href":"/note-cs/docs/direction/fe/frame/react/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":84,"href":"/note-cs/docs/direction/fe/frame/vue/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":85,"href":"/note-cs/docs/direction/security/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":86,"href":"/note-cs/docs/basic/compile/make/cmake/","title":"cmake","section":"make","content":" cmake # 推荐 xmake\n参考：\nCMake 是不是阻碍了 C++的发展? CMake 教程 Modern-CMake 的简体中文翻译 "},{"id":87,"href":"/note-cs/docs/study/book/be/Designing-Data-Intensive-Applications/","title":"Designing Data-Intensive Applications","section":"5.2 后端","content":" Designing Data-Intensive Applications # 简介 # published by O’Reilly in March 2017.\n作者 # Martin Kleppmann\nMartin Kleppmann\u0026rsquo;s blog\n阅读笔记 # "},{"id":88,"href":"/note-cs/docs/basic/pl/shell/command/kill/","title":"kill","section":"1.3.1 Shell 命令","content":" kill # kill -9 与 kill 的区别 # kill 等于 kill -15，是安全的 TERM kill -9 是不安全的 SIGKILL kill aka kill -TERM aka kill -15 is the safe and correct way of terminating a process. It\u0026rsquo;s equivalent to safely shutting down a computer.\nkill -9 is the unsafe way of brutally murdering a process. It\u0026rsquo;s equivalent to pulling the power cord, and may cause data corruption.\n参考：\nwhat-is-the-difference-between-kill-and-kill-9 what-is-the-purpose-of-the-9-option-in-the-kill-command Linux kill -9 和 kill -15 的区别 "},{"id":89,"href":"/note-cs/docs/basic/os/type/macos/","title":"MacOS","section":"操作系统类型","content":" MacOS # "},{"id":90,"href":"/note-cs/docs/basic/pl/shell/command/netcat/","title":"netcat","section":"1.3.1 Shell 命令","content":" netcat # netcat -u 127.0.0.1 9502 "},{"id":91,"href":"/note-cs/docs/basic/pl/shell/command/netstat/","title":"netstat","section":"1.3.1 Shell 命令","content":" netstat # "},{"id":92,"href":"/note-cs/docs/study/book/ai/prml/","title":"Pattern Recognition and Machine Learning","section":"5.8 人工智能","content":" Pattern Recognition and Machine Learning # "},{"id":93,"href":"/note-cs/docs/domain/cc/istio/basic/arch/components/pilot/","title":"Pilot","section":"组件","content":" Pilot 基础 # 参考：\n深入理解 Istio 核心组件之 Pilot 深入解读 Service Mesh 背后的技术细节 "},{"id":94,"href":"/note-cs/docs/basic/pl/shell/command/telnet/","title":"telnet","section":"1.3.1 Shell 命令","content":" telnet # 只能测试 tcp 端口连接\n无法测试 udp 端口连接（可以用 netcat）\ntelnet domain/ip [port] telnet 退出 # 按 CTRL + ] 然后输入 quit "},{"id":95,"href":"/note-cs/docs/basic/os/type/windows/","title":"Windows","section":"操作系统类型","content":" Windows # "},{"id":96,"href":"/note-cs/docs/study/book/ai/d2l/","title":"动手学深度学习","section":"5.8 人工智能","content":" 动手学深度学习 # pytorch 版本 安装环境 # # 安装 conda wget -c --no-check-certificate https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh conda create --name d2l python=3.9 -y conda activate d2l pip install torch==1.12.0 pip install torchvision==0.13.0 pip install d2l==0.17.6 mkdir code/d2l \u0026amp;\u0026amp; cd d2l wget -c vultr.kingye.me/d2l-zh.zip unzip d2l-zh.zip \u0026amp;\u0026amp; rm d2l-zh.zip cd pytorch jupyter notebook --ip=0.0.0.0 --port=8215 "},{"id":97,"href":"/note-cs/docs/basic/pl/lua/code/","title":"第三部分 设计与实现","section":"Lua","content":" 设计与实现 # lua # lua/lua LuaJIT # LuaJIT/LuaJIT LuaJIT is a Just-In-Time Compiler (JIT) for the Lua programming language.\nGopherLua # yuin/gopher-lua GopherLua is a Lua5.1 VM and compiler written in Go. GopherLua has a same goal with Lua: Be a scripting language with extensible semantics . It provides Go APIs that allow you to easily embed a scripting language to your Go host programs.\n"},{"id":98,"href":"/note-cs/docs/domain/cc/istio/code/","title":"第三部分 设计与实现","section":"Istio","content":" 如无特殊说明，源码版本为 1.5.2 "},{"id":99,"href":"/note-cs/docs/basic/os/type/android/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":100,"href":"/note-cs/docs/basic/os/type/ios/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":101,"href":"/note-cs/docs/basic/os/type/macos/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":102,"href":"/note-cs/docs/basic/os/type/unix/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":103,"href":"/note-cs/docs/basic/os/type/windows/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":104,"href":"/note-cs/docs/direction/be/db/mysql/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":105,"href":"/note-cs/docs/direction/be/db/postgresql/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":106,"href":"/note-cs/docs/direction/be/db/redis/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":107,"href":"/note-cs/docs/direction/be/platform/nodejs/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":108,"href":"/note-cs/docs/direction/client/android/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":109,"href":"/note-cs/docs/direction/client/ios/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":110,"href":"/note-cs/docs/direction/client/xiaochengxu/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":111,"href":"/note-cs/docs/direction/embedded/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":112,"href":"/note-cs/docs/direction/fe/frame/angular/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":113,"href":"/note-cs/docs/direction/fe/frame/react/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":114,"href":"/note-cs/docs/direction/fe/frame/vue/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":115,"href":"/note-cs/docs/direction/security/appendix/interview/expert/","title":"高阶","section":"4.2 面试题","content":" 高阶面试题 # "},{"id":116,"href":"/note-cs/docs/domain/cc/istio/basic/arch/components/citadel/","title":"Citadel","section":"组件","content":" Citadel # "},{"id":117,"href":"/note-cs/docs/direction/be/mq/mqtt/mosquitto/","title":"mosquitto","section":"MQTT","content":" mosquitto # eclipse/mosquitto 物联网（Internet of Things，IoT）最近曝光率越来越高。虽然 HTTP 是网页的事实标准，不过机器之间（Machine-to-Machine，M2M）的大规模沟通需要不同的模式：之前的请求 / 回答（Request/Response）模式不再合适，取而代之的是发布 / 订阅（Publish/Subscribe）模式。这就是轻量级、可扩展的 MQTT（Message Queuing Telemetry Transport）可以施展拳脚的舞台。\nMQTT 是基于二进制消息的发布 / 订阅编程模式的消息协议，最早由 IBM 提出的，如今已经成为 OASIS 规范。由于规范很简单，非常适合需要低功耗和网络带宽有限的 IoT 场景，比如：\n遥感数据 汽车 智能家居 智慧城市 医疗医护 mosquitto_pub # mosquitto_pub {[-h host] [-p port] [-u username] [-P password] -t topic | -L URL} {-f file | -l | -n | -m message} [-c] [-k keepalive] [-q qos] [-r] [--repeat N] [--repeat-delay time] [-A bind_address] [-i id] [-I id_prefix] [-d] [--quiet] [-M max_inflight] [-u username [-P password]] [--will-topic [--will-payload payload] [--will-qos qos] [--will-retain]] [{--cafile file | --capath dir} [--cert file] [--key file] [--ciphers ciphers] [--insecure] [--tls-alpn protocol] [--tls-engine engine] [--keyform keyform] [--tls-engine-kpass-sha1]] [--psk hex-key --psk-identity identity [--ciphers ciphers]] [--proxy socks-url] [--property command identifier value] [-D command identifier value] mosquitto_pub -t \u0026lsquo;application/1/device/ffffff100000d143/rx\u0026rsquo; -m \u0026lsquo;{\u0026ldquo;applicationID\u0026rdquo;:\u0026ldquo;1\u0026rdquo;,\u0026ldquo;applicationName\u0026rdquo;:\u0026ldquo;0000000000000001\u0026rdquo;,\u0026ldquo;deviceName\u0026rdquo;:\u0026ldquo;d143-K5-out\u0026rdquo;,\u0026ldquo;devEUI\u0026rdquo;:\u0026ldquo;ffffff100000d143\u0026rdquo;,\u0026ldquo;txInfo\u0026rdquo;:{\u0026ldquo;frequency\u0026rdquo;:481700000,\u0026ldquo;dr\u0026rdquo;:2},\u0026ldquo;adr\u0026rdquo;:false,\u0026ldquo;fCnt\u0026rdquo;:68570,\u0026ldquo;fPort\u0026rdquo;:44,\u0026ldquo;data\u0026rdquo;:\u0026ldquo;BQEA\u0026rdquo;}\u0026rsquo;\nmosquitto_pub -t \u0026lsquo;application/1/device/ffffff100000d143/rx\u0026rsquo; -m \u0026lsquo;{\u0026ldquo;applicationID\u0026rdquo;:\u0026ldquo;1\u0026rdquo;}\u0026rsquo;\nmosquitto_sub # mosquitto_sub -t \u0026lsquo;application/1/device/ffffff100000d143/rx\u0026rsquo; mosquitto_sub -h 120.241.124.226 -t \u0026lsquo;application/1/device/ffffff100000d143/rx\u0026rsquo;\n安装 # MacOS # brew install mosquitto\n参考：https://mosquitto.org/download/\n"},{"id":118,"href":"/note-cs/docs/basic/os/type/unix/","title":"Unix","section":"操作系统类型","content":" Unix # "},{"id":119,"href":"/note-cs/docs/basic/pl/assembly/appendix/","title":"第四部分 附录","section":"汇编","content":" MacOS 上开发 nasm # 安装：brew install nasm\n"},{"id":120,"href":"/note-cs/docs/domain/cc/istio/basic/arch/components/galley/","title":"Galley","section":"组件","content":" Galley 基础 # "},{"id":121,"href":"/note-cs/docs/basic/compile/gcc/","title":"gcc","section":"1.6 编译原理","content":" gcc # 安装 # gcc 4.8 # curl -Lks http://www.hop5.in/yum/el6/hop5.repo \u0026gt; /etc/yum.repos.d/hop5.repo yum install gcc gcc-g++ gcc --version 参考： Linux 之 CentOS 6 通过 yum 安装 gcc 4.9 5.2 等高版本 gcc\n升级 # 升级到 gcc 6.3 # yum -y install centos-release-scl yum -y install devtoolset-6-gcc devtoolset-6-gcc-c++ devtoolset-6-binutils # scl 命令启用只是临时的，退出 shell 或重启就会恢复原系统 gcc 版本 scl enable devtoolset-6 bash # 长期 echo \u0026#34;source /opt/rh/devtoolset-6/enable\u0026#34; \u0026gt;\u0026gt;/etc/profile 参考：\n为 CentOS 6、7 升级 gcc 至 4.8、4.9、5.2、6.3、7.3 等高版本 "},{"id":122,"href":"/note-cs/docs/study/skill/stream-media/debug/gdb/","title":"GDB","section":"Debug","content":" GDB # GDB 的主要功能就是监控程序的执行流程，\n只有当源程序文件编译为可执行文件并执行时，GDB 才会派上用场。\n# -g Generate source-level debug information $ gcc -g main.c -o main # 启动时不显示提示信息 # -q, --quiet, --silent $ gdb -q # 显示 gdb 版本信息 (gdb) show version # 查看 gdb 版权相关信息 (gdb) show copying # 输出信息多时不会暂停输出 (gdb) set pagination off # 列出函数的名字 (gdb) info functions (gdb) info functions regex GDB 常用的调试指令 # 调试指令 作 用 (gdb) break xxx (gdb) b xxx 在源代码指定的某一行设置断点，其中 xxx 用于指定具体打断点的位置。 (gdb) run (gdb) r 执行被调试的程序，其会自动在第一个断点处暂停执行。 (gdb) continue (gdb) c 当程序在某一断点处停止运行后，使用该指令可以继续执行，直至遇到下一个断点或者程序结束。 (gdb) next (gdb) n 令程序一行代码一行代码的执行。 (gdb) print xxx (gdb) p xxx 打印指定变量的值，其中 xxx 指的就是某一变量名。 (gdb) list (gdb) l 显示源程序代码的内容，包括各行代码所在的行号。 (gdb) quit (gdb) q 终止调试。 问题 # 解决 GDB 在 Mac 下不能调试的问题 # Darwin 内核在你没有特殊权限的情况下，不允许调试其它进程。 调试某个进程，意味着你对这个进程有完全的控制权限，所以为了防止被恶意利用，它是默认禁止的。允许 gdb 控制其它进程最好的方法就是用系统信任的证书对它进行签名。\n创建代码签名的证书 # 打开 Keychain Access 应用程序（/Applications/Utilities/Keychain Access.app） 执行菜单 钥匙串访问 -\u0026gt; 证书助理 -\u0026gt; 创建证书 填写如下信息： 名称：gdb_codesign 身份类型：自签名根证书 证书类型：代码签名 钩选：让我覆盖这些默认设置\n一路确定，直到指定证书位置的步骤，选择系统\n点击 \u0026ldquo;创建\u0026rdquo;，会提示用输入系统登录密码，创建完成 在钥匙串访问程序中，选择左侧栏的系统和我的证书，找到你刚刚创建的 gdb_codesign 证书并双击打开证书信息窗口，展开 信任项，设置使用此证书时：为始终信任。\n关闭证书信息窗口，系统会再次要求输入系统登录密码。 签名 # 如果是之前的系统，直接执行：\ncodesign -fs gdb-cert $(which gdb)\n如果是 Mojave (10.14) 之后的系统，\n先创建一个文件 gdb-entitlement.xml，内容为:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.debugger\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; \u0026lt;/pre\u0026gt; 再执行:\ncodesign --entitlements gdb-entitlement.xml -fs gdb-cert $(which gdb)\n具体参考这里：https://sourceware.org/gdb/wi\u0026hellip;\n参考：\n解决 GDB 在 Mac 下不能调试的问题 工具 # cyrus-and/gdb-dashboard "},{"id":123,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/build/gulp/","title":"gulp","section":"构建","content":" gulp # 类似与 make 参考：https://learnxinyminutes.com/docs/zh-cn/make-cn/\n"},{"id":124,"href":"/note-cs/docs/domain/cc/istio/basic/concept/crd/","title":"Istio CRD","section":"1.2 概念","content":" Istio CRD # CRD List # CRD API group 作用 meshpolicies authentication.istio.io policies authentication.istio.io adapters config.istio.io attributemanifests config.istio.io handlers config.istio.io httpapispecbindings config.istio.io httpapispecs config.istio.io instances config.istio.io quotaspecbindings config.istio.io quotaspecs config.istio.io rules config.istio.io templates config.istio.io destinationrules networking.istio.io envoyfilters networking.istio.io gateways networking.istio.io serviceentries networking.istio.io sidecars networking.istio.io virtualservices networking.istio.io clusterrbacconfigs rbac.istio.io rbacconfigs rbac.istio.io servicerolebindings rbac.istio.io serviceroles rbac.istio.io authorizationpolicies security.istio.io peerauthentications security.istio.io requestauthentications security.istio.io kubectl get customresourcedefinitions\nPilot # 38 个，详见：pilot/pkg/config/kube/crd/types.gen.go\nMockConfig MockConfigList VirtualService VirtualServiceList Gateway GatewayList ServiceEntry ServiceEntryList SyntheticServiceEntry SyntheticServiceEntryList DestinationRule DestinationRuleList EnvoyFilter EnvoyFilterList Sidecar SidecarList HTTPAPISpec HTTPAPISpecList HTTPAPISpecBinding HTTPAPISpecBindingList QuotaSpec QuotaSpecList QuotaSpecBinding QuotaSpecBindingList Policy PolicyList MeshPolicy MeshPolicyList ServiceRole ServiceRoleList ServiceRoleBinding ServiceRoleBindingList RbacConfig RbacConfigList ClusterRbacConfig ClusterRbacConfigList AuthorizationPolicy AuthorizationPolicyList "},{"id":125,"href":"/note-cs/docs/basic/compile/make/","title":"make","section":"1.6 编译原理","content":" make # 教程 # learn make in y minutes 跟我一起写 Makefile GNU make manual "},{"id":126,"href":"/note-cs/docs/direction/be/db/redis/basic/quick-start/","title":"Quick Start","section":"第一部分 基础入门","content":" Quick Start # redis-cli -h host -p port -a password 安装 # 开机自启 # sudo vi /usr/lib/systemd/system/redis.service\n[Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/usr/bin/redis-server /etc/redis.conf --supervised systemd ExecStop=/usr/libexec/redis-shutdown Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target 保存退出，执行 sudo systemctl daemon-reload 启动服务 sudo systemctl start redis.service 设置开机自启动 sudo systemctl enable redis.service\n设置密码 # 打开文件 /etc/redis.conf， 找到其中的 # requirepass foobared，去掉前面的 #， 并把 foobared 改成你的密码。\nps: 如果 redis 没有启用密码，我使用 redis-cli -a xxx 可以访问吗？ 答案是：可以\n为什么 Redis 默认端口是 6379 # 6379 在是手机按键上 MERZ 对应的号码，而 MERZ 取自意大利歌女 Alessia Merz 的名字。 MERZ 长期以来被 antirez 及其朋友当作愚蠢的代名词。\n参考：http://oldblog.antirez.com/post/redis-as-LRU-cache.html\n问答 # MySQL 和 Redis 如何保持数据的一致性？ # MySQL binlog 增量订阅消费 + 消息队列 + 处理并把数据更新到 redis\n参考：\nliukelin/canal_mysql_nosql_sync # alibaba/canal # 阿里巴巴 MySQL binlog 增量订阅 \u0026amp; 消费组件\n分布式的环境下， MySQL 和 Redis 如何保持数据的一致性？ "},{"id":127,"href":"/note-cs/docs/basic/pl/shell/type/zsh/","title":"Zsh","section":"1.3.4 Shell 类型","content":" Zsh # "},{"id":128,"href":"/note-cs/docs/direction/be/db/mysql/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":129,"href":"/note-cs/docs/direction/be/db/postgresql/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":130,"href":"/note-cs/docs/direction/be/db/redis/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":131,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":132,"href":"/note-cs/docs/direction/client/android/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":133,"href":"/note-cs/docs/direction/client/ios/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":134,"href":"/note-cs/docs/direction/client/xiaochengxu/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":135,"href":"/note-cs/docs/direction/fe/frame/angular/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":136,"href":"/note-cs/docs/direction/fe/frame/react/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":137,"href":"/note-cs/docs/direction/fe/frame/vue/basic/practice/snippet/","title":"代码片段","section":"实践","content":" 代码片段 # "},{"id":138,"href":"/note-cs/docs/direction/be/db/redis/basic/type/","title":"数据类型","section":"第一部分 基础入门","content":" 数据类型 # string # Redis 规定了字符串的长度不得超过 512 MB。\nlist # hash # set # zset # "},{"id":139,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/build/","title":"构建","section":"第一部分 基础入门","content":" Node.js 构建 # "},{"id":140,"href":"/note-cs/docs/direction/be/platform/nodejs/basic/version/","title":"版本","section":"第一部分 基础入门","content":" Node.js 版本 # 版本控制 # nvm-sh/nvm # Node Version Manager - POSIX-compliant bash script to manage multiple active node.js versions\n安装 # curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash export NVM_DIR=\u0026#34;$([ -z \u0026#34;${XDG_CONFIG_HOME-}\u0026#34; ] \u0026amp;\u0026amp; printf %s \u0026#34;${HOME}/.nvm\u0026#34; || printf %s \u0026#34;${XDG_CONFIG_HOME}/nvm\u0026#34;)\u0026#34; [ -s \u0026#34;$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/nvm.sh\u0026#34; # This loads nvm 基础命令 # # 安装最新版 nvm install node # 安装最新 LTS 版本 nvm install --lts # 设置默认版本 nvm alias default lts/* # 查看本地版本列表 nvm ls # 查看全部版本列表 nvm ls-remote nvm ls-remote --lts # 使用最新版本 LTS nvm use lts/* # 查看安装路径 nvm which node nvm which v12.14.1 "},{"id":141,"href":"/note-cs/docs/study/book/basic/cc/sicp/","title":"计算机程序的构造和解释","section":"5.1.1 计算机组成原理","content":" 计算机程序的构造和解释 # 豆瓣 参考 # 黄健宏：SICP 解题集 "},{"id":142,"href":"/note-cs/docs/direction/se/design-pattern/principle/","title":"设计原则","section":"2.1.1 设计模式","content":" 设计原则 # "},{"id":143,"href":"/note-cs/docs/direction/be/db/redis/design/lock/","title":"锁","section":"第二部分 设计","content":" 锁 # setnx # setnx msetnx hsetnx SET key value [EX seconds|PX milliseconds] [NX|XX] [KEEPTTL] 那么删除锁的正确姿势之一，就是可以使用 lua 脚本，通过 redis 的 eval/evalsha 命令来运行：\n-- lua删除锁： -- KEYS和ARGV分别是以集合方式传入的参数，对应上文的Test和uuid。 -- 如果对应的value等于传入的uuid。 if redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1] then -- 执行删除操作 return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) else -- 不成功，返回0 return 0 end 通过 lua 脚本能保证原子性的原因说的通俗一点：\n就算你在 lua 里写出花，执行也是一个命令 (eval/evalsha) 去执行的，一条命令没执行完，其他客户端是看不到的。\n那么既然这么麻烦，有没有比较好的工具呢？就要说到 redisson 了。\nredLock # 并非是一个工具，而是 redis 官方提出的一种分布式锁的算法。\nredisson # Redisson 是 java 的 redis 客户端之一，提供了一些 api 方便操作 redis。\nredisson 就实现了 redLock 版本的锁。也就是说除了 getLock 方法，还有 getRedLock 方法。\n"},{"id":144,"href":"/note-cs/docs/direction/be/platform/dotnet/","title":".NET","section":"平台","content":" .NET Framework # "},{"id":145,"href":"/note-cs/docs/direction/be/platform/dotnet/core/","title":".NET Core","section":".NET","content":" .NET Core # "},{"id":146,"href":"/note-cs/docs/direction/be/platform/dotnet/asp/","title":"ASP.NET","section":".NET","content":" ASP.NET # Razor # Razor is an ASP.NET programming syntax used to create dynamic web pages with the C# or VB.NET programming languages.\nMVC # Blazor # Blazor is a feature of ASP.NET for building interactive web UIs using C# instead of JavaScript. It\u0026rsquo;s real .NET running in the browser on WebAssembly.\n客户端 # "},{"id":147,"href":"/note-cs/docs/direction/be/platform/nodejs/","title":"Node.js","section":"平台","content":" Node.js # "},{"id":148,"href":"/note-cs/docs/direction/be/db/redis/basic/cmd/","title":"命令","section":"第一部分 基础入门","content":" Redis 命令 # key # DEL DUMP EXISTS EXPIRE EXPIREAT KEYS MOVE PERSIST PEXPIREAT PEXPIREAT PTTL RANDOMKEY RENAME RENAMENX TTL TYPE string # APPEND DECR DECRBY DEL EXISTS GET GETRANGE GETSET INCR INCRBY INCRBYFLOAT MGET MSET MSETNX PSETEX SET SETBIT SETEX SETNX SET if Not eXists 只在键 key 不存在的情况下， 将键 key 的值设置为 value 。 STRLEN list # DEL DUMP EXISTS EXPIRE EXPIREAT KEYS MOVE PERSIST PEXPIREAT PEXPIREAT PTTL RANDOMKEY RENAME RENAMENX TTL TYPE hash # HDEL HEXISTS HGET HGETALL HINCRBY HINCRBYFLOAT HKEYS HLEN HMGET HMSET HSET HSETNX HVALS set # SADD SCARD SDIFF SDIFFSTORE SINTER SINTERSTORE SISMEMBER SMEMBERS SMOVE SPOP SRANDMEMBER SREM SSCAN SUNION SUNIONSTORE zset # ZADD ZCARD ZCOUNT ZINCRBY ZINTERSTORE ZLEXCOUNT ZRANGE ZRANGEBYLEX ZRANGEBYSCORE ZRANK ZREM ZREMRANGEBYLEX ZREMRANGEBYRANK ZREMRANGEBYSCORE ZREVRANGE ZREVRANGEBYSCORE ZREVRANK ZSCAN ZSCORE ZUNIONSTORE 连接 # AUTH ECHO PING QUIT SELECT 服务器 # BGREWRITEAOF BGSAVE CLIENT GETNAME CLIENT KILL CLIENT LIST CLIENT PAUSE CLIENT SETNAME CLUSTER SLOTS COMMAND COMMAND COUNT COMMAND GETKEYS COMMAND INFO CONFIG GET CONFIG RESETSTAT CONFIG REWRITE CONFIG SET DBSIZE DEBUG OBJECT DEBUG SEGFAULT FLUSHALL FLUSHDB INFO LASTSAVE MONITOR ROLE SAVE SHOWLOG SHUTDOWN SLAVEOF SYNC TIME 脚本 # EVAL EVALSHA SCRIPT EXISTS SCRIPT FLUSH SCRIPT KILL SCRIPT LOAD 事务 # DISCARD EXEC MULTI UNWATCH WATCH HyperLogLog # PFADD PFCOUNT PGMERGE 发布订阅 # PSUBSCRIBE PUBLISH PUBSUB PUNSUBSCRIBE SUBSCRIBE UNSUBSCRIBE 地理位置 (geo) # GEOADD GEODIST GEOHASH GEOPOS GEORADIUS GEORADIUSBYMEMBER 参考 # www.redis.net.cn/order 神奇的 HyperLogLog 算法 "},{"id":149,"href":"/note-cs/docs/direction/be/db/redis/source/type/","title":"类型实现","section":"第三部分 源码实现","content":" Redis 类型实现 # 参考 # 5 种基本数据结构 "},{"id":150,"href":"/note-cs/docs/basic/os/type/ios/","title":"iOS","section":"操作系统类型","content":" iOS # "},{"id":151,"href":"/note-cs/docs/study/skill/type/pdf/","title":"pdf","section":"文档类型","content":" pdf # "},{"id":152,"href":"/note-cs/docs/domain/cc/istio/code/source/1.0.0/","title":"1.0.0","section":"3.7 源码分析","content":" istio 1.0.0 源码分析 # 代码行数 # AlDanial/cloc $ cloc . 12059 text files. 11502 unique files. 1441 files ignored. github.com/AlDanial/cloc v 1.86 T=61.76 s (172.6 files/s, 58960.4 lines/s) -------------------------------------------------------------------------------- Language files blank comment code -------------------------------------------------------------------------------- Go 8710 270101 337300 2808944 YAML 665 1244 1748 32486 HTML 90 3350 194 28257 JSON 67 41 0 23021 Markdown 297 7243 0 20422 Protocol Buffers 370 9111 33369 18498 Python 46 1140 755 10919 Bourne Shell 138 1501 2158 6628 Assembly 67 893 1611 6487 JavaScript 12 272 167 2827 make 105 772 1871 2501 CSS 3 219 20 1042 Bourne Again Shell 10 89 110 622 TOML 10 206 198 480 Dockerfile 18 67 151 244 XML 8 14 22 199 Java 6 30 77 196 C/C++ Header 2 33 2 135 Ruby 1 24 23 103 Bazel 3 13 1 53 C 2 15 30 45 Gradle 4 8 0 45 SVG 6 0 0 37 Starlark 2 4 37 36 diff 16 0 1032 32 INI 2 5 0 18 SQL 1 2 0 11 DOS Batch 1 0 0 2 vim script 1 0 0 1 -------------------------------------------------------------------------------- SUM: 10663 296397 380876 2964291 -------------------------------------------------------------------------------- "},{"id":153,"href":"/note-cs/docs/domain/cc/istio/basic/quick/","title":"1.1 快速上手","section":"第一部分 基础入门","content":" Istio 快速上手 # 官网：https://github.com/istio/istio\nketacoda # 快速开始 Istio (by istio-handbook) # 概念 # listener # envoy 既然是 proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，这个监听的地址称为 listener\nroute # cluster # 由完全相同行为的多个 endpoint 组成，从 cluster 到 endpoint 的过程称为负载均衡。 cluster 里面配置负载均衡策略\nendpoint # 目标的 ip 地址和端口，这个是 proxy 最终将请求转发到的地方\n静态配置的例子如下： workload # WORKLOAD 是 operators 部署的二进制文件，用于提供服务网格应用的一些功能。\n在 Kubernetes 环境中，一个工作负载通常对应一个 Kubernetes deployment， 并且一个工作负载实例对应一个独立的被 deployment 管理的 pod。\n工作负载实例 # 工作负载实例是工作负载的一个二进制实例化对象。 一个工作负载实例可以开放零个或多个服务 endpoint， 也可以消费零个或多个 服务。\n工作负载实例具有许多属性：\n名称和命名空间 唯一的 ID IP 地址 标签 主体 通过访问 source.* 和 destination.* 下面的属性，在 Istio 的策略和遥测配置功能中，可以用到这些属性。\n工作负载实例主体 # WORKLOAD INSTANCE PRINCIPAL 工作负载实例主体是工作负载实例的可验证权限。Istio 的服务到服务身份验证用于生成工作负载实例主体。默认情况下，工作负载实例主体与 SPIFFE ID 格式兼容。\n在 policy 和 telemetry 配置中用到了工作负载实例主体，对应的属性是 source.principal 和 destination.principal。\n遥测（telemetry） # "},{"id":154,"href":"/note-cs/docs/basic/cc/","title":"1.1 计算机组成原理","section":"第一部分 基础","content":" 计算机组成原理 computer composition # "},{"id":155,"href":"/note-cs/docs/basic/pl/assembly/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":156,"href":"/note-cs/docs/basic/pl/erlang/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":157,"href":"/note-cs/docs/basic/pl/haskell/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":158,"href":"/note-cs/docs/basic/pl/lua/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":159,"href":"/note-cs/docs/basic/pl/r/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":160,"href":"/note-cs/docs/basic/pl/ruby/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":161,"href":"/note-cs/docs/basic/pl/swift/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":162,"href":"/note-cs/docs/basic/pl/zig/basic/grammar/","title":"1.1 语法","section":"第一部分 基础入门","content":" 语法 # "},{"id":163,"href":"/note-cs/docs/basic/pl/assembly/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":164,"href":"/note-cs/docs/basic/pl/erlang/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":165,"href":"/note-cs/docs/basic/pl/haskell/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":166,"href":"/note-cs/docs/basic/pl/lua/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":167,"href":"/note-cs/docs/basic/pl/r/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":168,"href":"/note-cs/docs/basic/pl/ruby/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":169,"href":"/note-cs/docs/basic/pl/swift/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":170,"href":"/note-cs/docs/basic/pl/zig/basic/grammar/type/","title":"1.1.1 数据类型","section":"1.1 语法","content":" 数据类型 # "},{"id":171,"href":"/note-cs/docs/basic/pl/shell/command/","title":"1.3.1 Shell 命令","section":"Shell","content":" Shell 命令 # 查看服务器信息 # CPU # # 物理 cpu 个数 cat /proc/cpuinfo| grep \u0026#39;physical id\u0026#39; | sort | uniq | wc -l # 每个物理 cpu 的核心数 cat /proc/cpuinfo| grep \u0026#39;core id\u0026#39; | sort | uniq | wc -l # 逻辑 cpu 个数（线程数） cat /proc/cpuinfo| grep \u0026#39;processor\u0026#39; | sort | uniq | wc -l # CPU 位数 getconf LONG_BIT # CPU 型号 dmidecode -s processor-version 系统版本 # # 操作系统版本 cat /etc/issue cat /etc/*release # 系统内核 uname -a cat /proc/version Linux 内核版本 # 参考：\nThe Linux Kernel Archives Linux 内核 Linux 内核开发指南 磁盘 # # 目录空间大小排行 du -m --max-depth=2 | sort -rn | head -10 # macos du -m -d 2 | sort -rn | head -10 文件类型 # 文件类型分为 p、d、l、s、c、b 和 -：\n表示普通文件 p 表示命名管道文件 d 表示目录文件 l 表示符号连接文件 s 表示 socket 文件 c 表示字符设备文件 b 表示块设备文件 带宽 # ifconfig sudo ethtool 网卡名 | grep Speed 查看运行信息 # lsof # # 列出所有 tcp 网络连接信息 lsof -i tcp # 列出所有 udp 网络连接信息 lsof -i udp # 列出谁在使用某个端口 lsof -i :3306 # 列出谁在使用某个特定的 udp 端口 lsof -i udp:55 # 列出特定的 tcp 端口 lsof -i tcp:80 文件删除，但是磁盘没有释放 # lsof | grep deleted 进程 # # 查看文件被哪个进程占用 lsof /path/to/file # 怎么查看进程打开的文件 lsof -p pid lsof -c cmd 参考 # Linux 工具快速教程 # "},{"id":172,"href":"/note-cs/docs/basic/pl/assembly/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":173,"href":"/note-cs/docs/basic/pl/erlang/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":174,"href":"/note-cs/docs/basic/pl/haskell/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":175,"href":"/note-cs/docs/basic/pl/lua/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":176,"href":"/note-cs/docs/basic/pl/r/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":177,"href":"/note-cs/docs/basic/pl/ruby/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":178,"href":"/note-cs/docs/basic/pl/swift/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":179,"href":"/note-cs/docs/basic/pl/zig/advanced/pattern/","title":"2.1 设计模式","section":"第二部分 进阶实战","content":" 设计模式 # "},{"id":180,"href":"/note-cs/docs/direction/se/","title":"2.1 软件工程","section":"第二部分 方向","content":" 软件工程 # 教程 # The System Design Primer # donnemartin/system-design-primer Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.\n系统设计入门 # 学习如何设计可扩展的系统将会有助于你成为一个更好的工程师。\n系统设计是一个很宽泛的话题。在互联网上，关于系统设计原则的资源也是多如牛毛。\n这个仓库就是这些资源的组织收集，它可以帮助你学习如何构建可扩展的系统。\n参考 # 如何构建高扩展性网站 # 参考：\n如何构建高扩展性网站？ A Word on Scalability "},{"id":181,"href":"/note-cs/docs/domain/cc/istio/advanced/deploy/","title":"2.1 部署","section":"第二部分 进阶实战","content":" 部署 # "},{"id":182,"href":"/note-cs/docs/direction/se/design-pattern/","title":"2.1.1 设计模式","section":"2.1 软件工程","content":" 设计模式 # 设计原则 # 单一职责原则 开闭原则 里氏替换原则 依赖倒置原则 接口隔离原则 迪米特原则 设计模式 # 设计模式 类型 重要性 备注 单例 创建型 ★★★★★ 构造器 创建型 ★★★★ 建造者 工厂方法 创建型 ★★★★ 工厂模式 适配器 架构型 ★★★★ 装饰 架构型 ★★★★ 代理 架构型 ★★★★ 简单工厂 其他 ★★★★ 静态工厂方法 抽象工厂 创建型 ★★★ 原型 创建型 ★★★ 桥接 架构型 ★★★ 组合 架构型 ★★★ 外观 架构型 ★★★ 享元 架构型 ★★★ 命令 行为型 ★★★ 翻译器 行为型 ★★★ 迭代器 行为型 ★★★ 中介者 行为型 ★★★ 回忆 行为型 ★★★ 职责链 行为型 ★★★ 观察者 行为型 ★★★ 状态机 行为型 ★★★ 策略 行为型 ★★★ 模板方法 行为型 ★★★ 参观者 行为型 ★★★ 并行模式 其他 ★★ 参考 # 综合 kamranahmedse/design-patterns-for-humans DovAmir/awesome-design-patterns 图说设计模式：me115/design_patterns PHP domnikl/DesignPatternsPHP Java iluwatar/java-design-patterns Go tmrts/go-patterns senghoo/golang-design-pattern Python faif/python-patterns "},{"id":183,"href":"/note-cs/docs/direction/fe/html/","title":"2.2.1 HTML","section":"2.3 前端","content":" HTML # "},{"id":184,"href":"/note-cs/docs/direction/be/db/","title":"2.2.1 数据库","section":"2.2 后端","content":" 数据库 # OLTP vs OLAP # OLTP (On-line Transaction Processing) is involved in the operation of a particular system.\nOLAP (On-line Analytical Processing) deals with Historical Data or Archival Data.\n参考：\nWhat are OLTP and OLAP. What is the difference between them? OLAP # prestodb/presto The official home of the Presto distributed SQL query engine for big data http://prestodb.github.io Presto 是 Facebook 开发的分布式大数据 SQL 查询引擎，专门进行快速数据分析。特点： 可以将多个数据源的数据进行合并，可以跨越整个组织进行分析。 直接从 HDFS 读取数据，在使用前不需要大量的 ETL 操作。 apache/druid Apache Druid: a high performance real-time analytics database. https://druid.apache.org/ Druid 是广告分析公司 Metamarkets 开发的一个用于大数据实时查询和分析的分布式实时处理系统，主要用于广告分析，互联网广告系统监控、度量和网络监控。 apache/impala apache/kylin Apache Kylin 最初由 eBay 开发并贡献至开源社区的分布式分析引擎，提供 Hadoop 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据。 apache/hive The Apache Hive (TM) data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. "},{"id":185,"href":"/note-cs/docs/direction/be/db/mysql/","title":"2.2.1.1 Mysql","section":"2.2.1 数据库","content":" Mysql # mysql/mysql-server 查看版本 # # client $ mysql --version $ mysql -V # server $ mysqld --version $ mysqld -V select version(); select @@version; show variables like \u0026#34;%version%\u0026#34;; "},{"id":186,"href":"/note-cs/docs/direction/be/mq/kafka/","title":"2.2.2.1 Kafka","section":"2.2.2 消息队列","content":" Kafka # apache/kafka Kafka 是 linkedin 开源的 MQ 系统，主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，0.8 开始支持复制，不支持事务，适合产生大量数据的互联网服务的数据收集业务。\n序列化 # StringSerializer 序列化，写入时使用 dest.kafka.1\u0026amp;key.serializer=org.apache.kafka.common.serialization.StringSerializer dest.kafka.1\u0026amp;value.serializer=org.apache.kafka.common.serialization.StringSerializer\nStringDeserializer 反序列化，读出时使用 source.kafka.2\u0026amp;key.deserializer=org.apache.kafka.common.serialization.StringDeserializer source.kafka.2\u0026amp;value.deserializer=org.apache.kafka.common.serialization.StringDeserializer\n"},{"id":187,"href":"/note-cs/docs/direction/fe/frame/vue/","title":"2.2.3.1 Vue","section":"2.2.3 框架","content":" Vue # "},{"id":188,"href":"/note-cs/docs/direction/be/distributed/raft/","title":"2.2.4.1 Raft","section":"2.2.4 分布式系统","content":" Raft # https://raft.github.io\n由于 Paxos 难以理解，所以才有了 Raft\nRaft 以可理解性和易于实现为目标：\nLeader 选举（Leader election） 日志同步（Log replication） 安全性（Safety） 日志压缩（Log compaction） 成员变更（Membership change） 教程 # maemual/raft-zh_cn # 关注 # baidu/braft # tikv/raft-rs # Raft distributed consensus algorithm implemented in Rust.\nhashicorp/raft # Golang implementation of the Raft consensus protocol\netcd-io/etcd # Distributed reliable key-value store for the most critical data of a distributed system\n"},{"id":189,"href":"/note-cs/docs/direction/be/microservices/rpc/","title":"2.2.5.1 RPC","section":"2.2.5 微服务","content":" RPC # "},{"id":190,"href":"/note-cs/docs/direction/be/microservices/rpc/protobuf/","title":"2.2.5.1.1 protobuf","section":"2.2.5.1 RPC","content":" protobuf # "},{"id":191,"href":"/note-cs/docs/direction/client/android/","title":"2.4.1 Android","section":"2.4 客户端","content":" Android # "},{"id":192,"href":"/note-cs/docs/domain/cc/istio/code/istio/","title":"3.1 Istio","section":"第三部分 设计与实现","content":" Istio # "},{"id":193,"href":"/note-cs/docs/domain/cc/","title":"3.1 云计算","section":"第三部分 领域","content":" 云计算 # "},{"id":194,"href":"/note-cs/docs/basic/pl/assembly/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":195,"href":"/note-cs/docs/basic/pl/erlang/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":196,"href":"/note-cs/docs/basic/pl/haskell/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":197,"href":"/note-cs/docs/basic/pl/lua/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":198,"href":"/note-cs/docs/basic/pl/r/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":199,"href":"/note-cs/docs/basic/pl/ruby/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":200,"href":"/note-cs/docs/basic/pl/swift/code/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":201,"href":"/note-cs/docs/basic/pl/zig/design/type/","title":"3.1 数据类型","section":"第三部分 设计与实现","content":" 数据类型 # "},{"id":202,"href":"/note-cs/docs/domain/cc/istio/code/istio/structure/","title":"3.1.1 Istio 源码结构","section":"3.1 Istio","content":" Istio 源码结构 # 1.6.5 ```shell $ tree -L 2 . ├── BUGS-AND-FEATURE-REQUESTS.md ├── CODEOWNERS ├── CONTRIBUTING.md ├── LICENSE ├── Makefile ├── Makefile.core.mk ├── Makefile.overrides.mk ├── README.md ├── SUPPORT.md ├── bin │ ├── check_no_modify.sh │ ├── check_samples.sh │ ├── codecov.sh │ ├── codecov_diff.sh │ ├── diff_yaml.py │ ├── init.sh │ ├── mixer_codegen.sh │ ├── nomodify.md5 │ ├── protoc.sh │ ├── update_crds.sh │ ├── update_deps.sh │ └── update_no_modify.sh ├── codecov.skip ├── codecov.threshold ├── common │ ├── Makefile.common.mk │ ├── config │ └── scripts ├── common-protos │ ├── github.com │ ├── gogoproto │ ├── google │ └── k8s.io ├── docker │ ├── Dockerfile.base │ └── ca-certificates.tgz ├── galley │ ├── README.md │ ├── pkg │ ├── testdatasets │ └── tools ├── go.mod ├── go.sum ├── install │ ├── consul │ ├── gcp │ └── tools ├── istio.deps ├── istioctl │ ├── cmd │ ├── docker │ └── pkg ├── licenses │ ├── ... ├── manifests │ ├── addons │ ├── charts │ └── profiles ├── mixer │ ├── README.md │ ├── adapter │ ├── cmd │ ├── docker │ ├── pkg │ ├── template │ ├── test │ ├── testdata │ └── tools ├── operator │ ├── ARCHITECTURE.md │ ├── LICENSE │ ├── README.md │ ├── cmd │ ├── codecov.skip │ ├── codecov.threshold │ ├── data │ ├── deploy │ ├── docker │ ├── images │ ├── operator.mk │ ├── pkg │ ├── samples │ ├── scripts │ └── version ├── pilot │ ├── cmd │ ├── docker │ ├── pkg │ ├── test │ └── tools ├── pkg │ ├── adsc │ ├── bootstrap │ ├── cmd │ ├── config │ ├── dns │ ├── envoy │ ├── istio-agent │ ├── jwt │ ├── keepalive │ ├── kube │ ├── mcp │ ├── proto │ ├── queue │ ├── spiffe │ ├── test │ ├── tracing │ ├── util │ └── webhooks ├── prow │ ├── config │ ├── integ-suite-kind.sh │ ├── integ-suite-local.sh │ ├── lib.sh │ ├── release-commit.sh │ ├── release-test.sh │ └── upload-istioio-snippets.sh ├── release │ ├── downloadIstioCandidate.sh │ └── downloadIstioCtl.sh ├── samples │ ├── README.md │ ├── addons │ ├── bookinfo │ ├── certs │ ├── custom-bootstrap │ ├── external │ ├── fortio │ ├── health-check │ ├── helloworld │ ├── httpbin │ ├── https │ ├── kubernetes-blog │ ├── multicluster │ ├── rawvm │ ├── security │ ├── sleep │ ├── tcp-echo │ └── websockets ├── security │ ├── README.md │ ├── cmd │ ├── pkg │ ├── proto │ ├── samples │ └── tools ├── test.go ├── tests │ ├── apps │ ├── binary │ ├── codecov │ ├── common │ ├── integration │ ├── istio.mk │ ├── testdata │ └── util ├── tools │ ├── buildx-gen.sh │ ├── certs │ ├── convert_RbacConfig_to_ClusterRbacConfig.sh │ ├── dump_kubernetes.sh │ ├── gen_istio_image_list.sh │ ├── istio-clean-iptables │ ├── istio-docker.mk │ ├── istio-iptables │ └── packaging └── vendor ├── cloud.google.com ├── code.cloudfoundry.org ├── contrib.go.opencensus.io ├── fortio.org ├── github.com ├── go.opencensus.io ├── go.uber.org └── golang.org 144 directories, 54 files ``` 1.4.6 "},{"id":203,"href":"/note-cs/docs/tool/macos/","title":"4.1 MacOS","section":"第四部分 工具","content":" MacOS # 新应用不滞留在 Dock # defaults write com.apple.dock static-only -bool true killall Dock 参考 # jaywcjlove/awesome-mac # jaywcjlove/awesome-mac CP Editor # cpeditor/cpeditor CP Editor - 提升你的算法竞赛编程体验！\nHammerspoon # Hammerspoon/hammerspoon This is a tool for powerful automation of OS X.\nAt its core, Hammerspoon is just a bridge between the operating system and a Lua scripting engine.\nneovim # neovim/neovim Vim-fork focused on extensibility and usability https://neovim.io\n微信助手 # MustangYM/WeChatExtension-ForMac Mac 微信功能拓展 / 微信插件 / 微信小助手 (A plugin for Mac WeChat)\nlmk123/oh-my-wechat # 安装 curl -o- -L https://omw.limingkai.cn/install.sh | bash -s # 开机自动安装小助手的功能（即在开机后自动运行一次 omw -n） omw open # 解决重启错误问题，参考：https://github.com/MustangYM/WeChatExtension-ForMac/issues/816 sudo codesign --sign - --force --deep /Applications/WeChat.app 语雀 # http://yuque.com/\n命令行工具 # fd # sharkdp/fd A simple, fast and user-friendly alternative to \u0026lsquo;find\u0026rsquo;\nbrew install fd goproxy # snail007/goproxy Proxy 是 golang 实现的高性能 http,https,websocket,tcp,socks5 代理服务器，支持内网穿透，链式代理，通讯加密，智能 HTTP,SOCKS5 代理，黑白名单，限速，限流量，限连接数，跨平台，KCP 支持，认证 API。\nhub # github/hub A command-line tool that makes git easier to use with GitHub. https://hub.github.com/\nhyperfine # sharkdp/hyperfine A command-line benchmarking tool\nMac App Store command line interface # mas-cli/mas nps # ehang-io/nps server\n# 安装 sudo ./nps install # 启动 sudo nps start # 访问 web http://localhost:8080/ # 账户密码 # admin/123 # 日志 sudo tail -f /var/log/nps.log client\n下载 client\n./npc -server=192.168.64.1:8024 -vkey=qlati48ufop46lln -type=tcp nteract # nteract/nteract The interactive computing suite for you!\nTmux # 见 Tmux\nAlfred # https://www.alfredapp.com/\nwensonsmith/YoudaoTranslate 有道翻译 Keyboard Maestro # V2Ray # v2ray/v2ray-core V2RayX # Cenmrev/V2RayX WakaTime # 统计你的编程时间\nhttps://wakatime.com/\nvscode # wakatime dashboard 一直显示插件未安装 开启 debug，发现下载 wakatime-cli 出错。\n然后 cmd+shift+p，触发 wakatime enable，看到 wakatime-cli 解压且 chmod 成功，就 ok 了。\n这样就是成功了。\nGoLand # 见 Goland\nHomebrew # Homebrew/brew The missing package manager for macOS (or Linux) https://brew.sh\nIntelliJ IDEA # 见 IntelliJ IDEA\niTerm2 # https://www.iterm2.com/\nOh My Zsh # https://ohmyz.sh/\nhttps://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh # 提示符 export PROMPT=\u0026#39;%{$fg[magenta]%}%(?..%?%1v)%n@%{$fg[green]%}%M:%{$fg[cyan]%}%c%{$reset_color%} $(git_prompt_info)\u0026#39; # 设置默认 shell sudo chsh -s /usr/bin/zsh VSCode # 详见：VSCode\n格式转换 # 富文本 -\u0026gt; markdown # euangoddard/clipboard2markdown http://euangoddard.github.io/clipboard2markdown/ pandoc # https://pandoc.org/\n"},{"id":204,"href":"/note-cs/docs/basic/os/type/android/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":205,"href":"/note-cs/docs/basic/os/type/ios/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":206,"href":"/note-cs/docs/basic/os/type/macos/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":207,"href":"/note-cs/docs/basic/os/type/unix/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":208,"href":"/note-cs/docs/basic/os/type/windows/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":209,"href":"/note-cs/docs/basic/pl/assembly/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # NASM 程序设计 - 雨痕 # 进阶 # "},{"id":210,"href":"/note-cs/docs/basic/pl/erlang/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":211,"href":"/note-cs/docs/basic/pl/haskell/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # Real World Haskell 中文版 # huangz1990/real-world-haskell-cn 进阶 # "},{"id":212,"href":"/note-cs/docs/basic/pl/lua/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # X 分钟速成 Lua Lua 面向对象实现: dingshukai/lua-oop 进阶 # "},{"id":213,"href":"/note-cs/docs/basic/pl/r/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":214,"href":"/note-cs/docs/basic/pl/ruby/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 如何快速学习 Ruby on Rails？ 进阶 # "},{"id":215,"href":"/note-cs/docs/basic/pl/swift/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":216,"href":"/note-cs/docs/basic/pl/zig/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":217,"href":"/note-cs/docs/direction/be/db/mysql/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":218,"href":"/note-cs/docs/direction/be/db/postgresql/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":219,"href":"/note-cs/docs/direction/be/db/redis/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # karlseguin/the-little-redis-book # 中文版\nilivebox/the-little-redis-book JasonLai256/the-little-redis-book 进阶 # "},{"id":220,"href":"/note-cs/docs/direction/be/platform/nodejs/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":221,"href":"/note-cs/docs/direction/client/android/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":222,"href":"/note-cs/docs/direction/client/ios/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":223,"href":"/note-cs/docs/direction/client/xiaochengxu/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":224,"href":"/note-cs/docs/direction/embedded/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":225,"href":"/note-cs/docs/direction/fe/frame/angular/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":226,"href":"/note-cs/docs/direction/fe/frame/react/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":227,"href":"/note-cs/docs/direction/fe/frame/vue/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":228,"href":"/note-cs/docs/direction/security/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 进阶 # "},{"id":229,"href":"/note-cs/docs/domain/cc/istio/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" Istio 教程 # 基础 # katacoda: 使用 istioctl 安装 istio 绿色记忆: Istio 学习笔记 绿色记忆: Istio Pilot 与 Envoy 的交互机制解读 进阶 # "},{"id":230,"href":"/note-cs/docs/tool/linux/ubuntu/","title":"4.2.1 Ubuntu","section":"4.2 Linux","content":" Ubuntu # 开源镜像 # 清华开源镜像 CentOS Ubuntu 中科大 CentOS 阿里巴巴开源镜像 Ubuntu 24.04 x86 # # 清华 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-backports main restricted universe multiverse # 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换 deb http://security.ubuntu.com/ubuntu/ noble-security main restricted universe multiverse # deb-src http://security.ubuntu.com/ubuntu/ noble-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-proposed main restricted universe multiverse # # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ noble-proposed main restricted universe multiverse EOF apt update # 阿里云 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse # deb https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse EOF apt update 24.04 arm64 # # 清华 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-backports main restricted universe multiverse # 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换 deb http://ports.ubuntu.com/ubuntu-ports/ noble-security main restricted universe multiverse # deb-src http://ports.ubuntu.com/ubuntu-ports/ noble-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-proposed main restricted universe multiverse # # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ noble-proposed main restricted universe multiverse EOF apt update # 阿里云 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://mirrors.aliyun.com/ubuntu-ports/ noble main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu-ports/ noble main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports/ noble-security main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu-ports/ noble-security main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports/ noble-updates main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu-ports/ noble-updates main restricted universe multiverse # deb https://mirrors.aliyun.com/ubuntu-ports/ noble-proposed main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu-ports/ noble-proposed main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports/ noble-backports main restricted universe multiverse deb-src https://mirrors.aliyun.com/ubuntu-ports/ noble-backports main restricted universe multiverse EOF apt update 22.04 x86 # # 清华 sudo tee /etc/apt/sources.list \u0026gt; /dev/null \u0026lt;\u0026lt; EOF # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse # deb-src http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse EOF 20.04 x86 # # 清华 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse EOF # 阿里 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse EOF ubuntu 20.04 x86 # 阿里云，清华，中科大，这些都用不了，\n下面这个可以（来自：https://gist.github.com/ishad0w/788555191c7037e249a439542c53e170）\ncat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb http://archive.ubuntu.com/ubuntu/ focal main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ focal main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ focal-updates main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ focal-security main restricted universe multiverse deb http://archive.ubuntu.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://archive.ubuntu.com/ubuntu/ focal-backports main restricted universe multiverse deb http://archive.canonical.com/ubuntu focal partner deb-src http://archive.canonical.com/ubuntu focal partner EOF cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb http://cn.archive.ubuntu.com/ubuntu focal main restricted deb http://cn.archive.ubuntu.com/ubuntu focal-updates main restricted deb http://cn.archive.ubuntu.com/ubuntu focal universe deb http://cn.archive.ubuntu.com/ubuntu focal-updates universe deb http://cn.archive.ubuntu.com/ubuntu focal multiverse deb http://cn.archive.ubuntu.com/ubuntu focal-updates multiverse deb http://cn.archive.ubuntu.com/ubuntu focal-backports main restricted universe multiverse deb http://cn.archive.ubuntu.com/ubuntu focal-security main restricted deb http://cn.archive.ubuntu.com/ubuntu focal-security universe deb http://cn.archive.ubuntu.com/ubuntu focal-security multiverse EOF 20.04 arm # cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://mirrors.aliyun.com/ubuntu-ports focal main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports focal-security main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports focal-updates main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports focal-proposed main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports focal-backports main restricted universe multiverse EOF 19.04 x86 # cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://repo.huaweicloud.com/ubuntu-ports/ disco main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ disco main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ disco-security main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ disco-security main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ disco-updates main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ disco-updates main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ disco-backports main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ disco-backports main restricted universe multiverse EOF 18.04 x86 # # 华为 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://repo.huaweicloud.com/ubuntu-ports/ bionic main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ bionic main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ bionic-security main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ bionic-security main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ bionic-updates main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ bionic-updates main restricted universe multiverse deb https://repo.huaweicloud.com/ubuntu-ports/ bionic-backports main restricted universe multiverse deb-src https://repo.huaweicloud.com/ubuntu-ports/ bionic-backports main restricted universe multiverse EOF # 清华的用不了了 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse EOF 18.04 arm # cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://mirrors.aliyun.com/ubuntu-ports bionic main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports bionic-security main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports bionic-updates main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports bionic-proposed main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports bionic-backports main restricted universe multiverse EOF 16.04 arm # cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/apt/sources.list deb https://mirrors.aliyun.com/ubuntu-ports xenial main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports xenial-security main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports xenial-updates main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports xenial-proposed main restricted universe multiverse deb https://mirrors.aliyun.com/ubuntu-ports xenial-backports main restricted universe multiverse EOF "},{"id":231,"href":"/note-cs/docs/direction/se/arch/scene/circuit-breaker/attention/","title":"4.3 关注项目","section":"熔断","content":" 关注 # 其他 # resilience4j/resilience4j # ehcache/ehcache3 # ehcache 是 ​​ 一个用 Java 实现的使用简单，高速，实现线程安全的缓存管理类库， ehcache 提供了用内存，磁盘文件存储，以及分布式存储方式等多种灵活的 cache 管理方案。 http://www.ehcache.org\nNetflix/Hystrix # Hystrix 是 Netflix OSS 的一部分，是微服务领域的领先的熔断工具。Hystrix 可以被视为白盒监控工具，而 Istio 可以被视为黑盒监控工具，\nIstio 是无缝衔接服务，istio 可以在不更改应用程序代码的情况下配置和使用。Hystrix 的使用需要更改每个服务来引入 Hystrix libraries。\n"},{"id":232,"href":"/note-cs/docs/study/book/basic/","title":"5.1 计算机基础","section":"4.2 读书","content":" 计算机基础 # 计算机组成原理 # 操作系统 # 数据结构与算法 # 计算机网络 # 编程语言 # 数据库 # 编译原理 # "},{"id":233,"href":"/note-cs/docs/study/book/basic/cc/","title":"5.1.1 计算机组成原理","section":"5.1 计算机基础","content":" 计算机组成原理 # Computer Composition\n"},{"id":234,"href":"/note-cs/docs/domain/cc/edge/5g-edge/","title":"5G 边缘计算","section":"边缘计算","content":" 5G 边缘计算 # 5G 的 G 是英文 Generation 的缩写，也就是 “世代” 的意思\n简单说，5G 就是第五代移动通信系统\n5G 与边缘计算有什么关系？ # 5G 通信网络更加去中心化，需要在网络边缘部署小规模或者便携式数据中心，进行终端请求的本地化处理，以满足 URLLC 和 mMTC 的超低延时需求，因此边缘计算是 5G 核心技术之一。\n5G 的三大典型应用场景对网络性能的要求有显著差异，但为控制成本，运营商必然选择一张承载网 + 网络切片 / 边缘计算技术，实现在最少的资本投入下最丰富的网络功能。\n在 5G 时代，承载网的带宽瓶颈、时延抖动等性能瓶颈难以突破，引入边缘计算后将大量业务在网络边缘终结。\n5G 与边缘计算的关系 # 5G 为边缘计算产业的落地和发展提供了良好的网络基础， 主要体现在三大场景（eMBB，uRLLC 和 mMTC）的支持、核心网用户面功能的灵活部署以及 5G 网络能力开放等方面。\n“5G + MEC + AI”是 5G 在网络边缘更好使能各行各业的关键； 是运营商助力垂直行业数字化和智能化的新模式； 是运营商进入垂直行业的触点和重点场景； 也是 5G 应用是否成功的一个重要标志。\n5G 支持将网络能力开放给边缘应用。 无线网络信息服务、位置服务、QoS服务等网络能力，可以封装成边缘计算 PaaS 平台的 API，开放给应用。 5G 与边缘计算结合，是运营商使能边缘计算的新核心竞争力和最大独特优势。 同时，边缘计算也成为 5G 服务垂直行业，充分发挥 5G 新网络特性的重要利器之一。\n5G MEC 将云计算和 5G 核心网带到网络边缘，带来了新的流量模型和部署模型。 如果运营商还继续采用 4G 移动承载网的设计思路，在 5G 时代，运营商网络将面临边缘计算的困局。\nQoS（Quality of Service，服务质量）指一个网络能够利用各种基础技术，为指定的网络通信提供更好的服务能力，是网络的一种安全机制， 是用来解决网络延迟和阻塞等问题的一种技术。\n核心网 UPF 下移到企业园区 # 关键业务数据不出园区，更易提供低延迟承载方案； 运营商可以为每个用户配置单独的 UPF，给企业用户定制 5G 服务。\n开放 5G 通信服务的能力 # 运营商以 API 模式开放的 5G 通信服务可编程能力（如定位，无线通信能力，带宽管理等）， 可以集成到企业生产业务系统中，企业可以定制自己的 5G 创新应用。\n和企业网直接互联互通 # 下沉的 5G MEC 系统和企业网直接互联互通，使分布在企业和运营商两个网络系统上的业务系统可以实时地集成拉通， 加上 5G 新的面向行业应用的通信功能（低延迟 uRLLC、物联网 mMTC、无线超级上行和业务连续性等）， 各行业可以做出很多创新应用。\neMBB # Enhanced Mobile Broadband\neMBB（特别是超级上行技术）增强移动带宽\n对于带宽要求较高的 AR/VR、直播\nCloud VR # uRLLC # ultra-Reliable and Low Latency Communications 超高可靠性低时延业务\n对于时延要求极高的工业控制\nTSN # TSN（时间敏感网络）\nTSN 的主要目标是通过 IEEE 802（以太网）有线网络提供确定性服务。这意味着低时延、小抖动、低丢包率、有保证的数据包传输。\n5G 和 TSN 进行融合，5G 作为 TSN 网络的 bridge\n实现 TSN 网络 controller 和 5G AF 的协同\n低时延只是一方面吧，更重要的是时延确定； 工业通信（大部分是有线通信）会有这样的要求，5G 是想把工业通信的场景也 cover 进来\n奇速播 # 奇速播是专门应用于酒店、商场等场所，改善公共 WiFi 用户视频体验的新概念服务，为酒店、商场公共网络环境中的用户带来极致的超高清视频体验\n带宽 max 300MB；时延\u0026lt;20ms\nmMTC # massive Machine Type Communications 大物联业务\n海量机器类通信，可以分别支持不同需求的边缘计算场景\n对于海量连接需求高的 IoT 设备接入\n5G MEC 网络规划建议和网络架构参考模型 # 5G MEC 网络规划建议，供运营商网络设计时参考。\n建议采用 ECA、ECN 和 ECI 模型分段设计网络，ECA 和 ECI 可以部署在不同的物理网络上（如两个运营商共享共建 5G 承载网）。 MEC 业务和网络隔离：MEC 内部的业务变化（如部署新的 UPF）和网络连接变化（如增加服务器），尽量少或不影响外部网络，即 MEC 系统和外部网络隔离。 网络方案规划要和运营商内部网络运维团队的界面分工相匹配，减少不同运维团队间的工作交叉，例如，如果 ECN 和 IP RAN 的运维是两个数通团队，网络功能设计就要尽量保持两个团队的专业运维界面清晰。 网络设计要满足 5G MEC 按需建设的增量模式，即增量部署 5G MEC 系统，要尽量减少对网络的影响。 建议 ECI 按逻辑网络来构建，统一控制管理，在跨越多个网络时也能保证快速建立网络连接和保证 SLA，支持 5G MEC 业务的迅速部署。 参考 # 终于有人把 5G 和边缘计算的关系说清楚了 5G 边缘计算跟我们有什么关系？ "},{"id":235,"href":"/note-cs/docs/study/course/basic/","title":"6.1 计算机基础","section":"4.3 课程","content":" 计算机基础 # 计算机组成原理 # 操作系统 # 数据结构与算法 # 计算机网络 # 编程语言 # 数据库 # 编译原理 # "},{"id":236,"href":"/note-cs/docs/study/course/basic/cc/","title":"6.1.1 计算机组成原理","section":"6.1 计算机基础","content":" 计算机组成原理 # Computer Composition\n"},{"id":237,"href":"/note-cs/docs/basic/os/type/android/","title":"Android","section":"操作系统类型","content":" Android # "},{"id":238,"href":"/note-cs/docs/direction/be/web/api-doc/","title":"API 文档","section":"Web Service","content":" API 文档 # swagger-api/swagger-core # swagger-api/swagger-ui # apidoc/apidoc # "},{"id":239,"href":"/note-cs/docs/basic/pl/c/","title":"C","section":"1.5 编程语言","content":" C 学习笔记 # 详见：C 学习笔记\n"},{"id":240,"href":"/note-cs/docs/study/course/basic/pl/cpp/","title":"C++","section":"6.1.5 编程语言","content":" C++ # "},{"id":241,"href":"/note-cs/docs/study/course/basic/pl/cpp/cpp-faq/","title":"C++ FAQ","section":"C++","content":" C++ FAQ # 学习进度 # Copying permissions On-line sites that distribute this document C++-FAQ-Book versus (on-line) C++-FAQ Recent changes to this document Netiquette when posting to comp.lang.c++ Big Picture Issues Classes and objects References Inline functions Constructors Destructors Assignment operators Operator overloading Friends Input/output via \u0026lt;iostream\u0026gt; and \u0026lt;cstdio\u0026gt; Freestore management Exceptions and error handling Const correctness Inheritance \u0026mdash; basics Inheritance \u0026mdash; virtual functions Inheritance \u0026mdash; proper inheritance and substitutability Inheritance \u0026mdash; abstract base classes (ABCs) Inheritance \u0026mdash; what your mother never told you Inheritance \u0026mdash; private and protected inheritance Inheritance \u0026mdash; multiple and virtual inheritance Built-in / intrinsic / primitive data types Coding standards Learning OO/C++ Newbie Questions / Answers Learning C++ if you already know Smalltalk Reference and value semantics How to mix C and C++ Pointers to member functions Container classes Templates Serialization and Unserialization Class libraries Compiler dependencies Miscellaneous technical issues Miscellaneous environmental issues "},{"id":242,"href":"/note-cs/docs/direction/se/arch/principle/cap/","title":"CAP","section":"原则","content":" CAP # P 是前提 # 在理论计算机科学中，CAP 定理（CAP theorem），又被称作布鲁尔定理（Brewer\u0026rsquo;s theorem），它指出对于一个 distributed data store 来说，不可能同时满足以下三点：\n一致性（Consistency） 每次读取要么获得最近写入的数据，要么获得一个错误。 可用性（Availability） 每次请求都能获得一个非错误响应，但不保证返回的是最新写入的数据。 分区容错性（Partition tolerance） 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。 尽管任意数量的消息被节点间的网络丢失（或延迟），系统仍继续运行。 分区指网络分区，通信的两台服务器之间网络断开，就发生了网络分区 一般选 AP # 也就是说，在存在网络分区的情况下，一致性和可用性必须二选一。\n比如：A 服务器 B 服务器同步数据，现在 A B 之间网络断掉了，那么现在发来 A 一个写入请求，但是 B 却没有相关的请求，显然，\n如果 A 不写，保持一致性，那么我们就失去了 A 的服务， 但是如果 A 写了，跟 B 的数据就不一致了，我们自然就丧失了一致性。 这里的一致性（Consistency）是强一致性，意思是 AB 的数据时刻都是同步的， 如果我们放弃了强一致性，不代表我们的数据就是一定是不一致的了，我们可以让 A 先写入本地，等到通信恢复了再同步给 B，这就是所谓的最终一致性，长远的看我们的数据还是一致的，我们只是在某一个时间窗口里数据不一致罢了。 如果这个时间窗口小过了用户逻辑处理的时间。那么其实对于用户来说根本感觉不到。\n现实中的 CAP # CAP 对实际工作缺乏指导性。\n实际系统主要有三种：\n强调 availability 的 eventual consistency 系统， 比如 Amazon Dynamo 及他们的复制品； 强调一致性的系统， 典型的是基于 Paxos 的系统； 强调性能不顾其他的系统， 典型的是 Async replication 的主从备份系统。 参考 # CAP 理论常被解释为一种 “三选二” 定律，这是否是一种误解？ 分布式事务中的最终一致具体应该如何实现？ 分布式系统中的数据一致性和性能怎么权衡？ "},{"id":243,"href":"/note-cs/docs/direction/be/auth/sso/cas/","title":"CAS","section":"SSO","content":" CAS # 简介 # 集中式认证服务（英语：Central Authentication Service，缩写 CAS）是一种针对万维网的单点登录协议。它的目的是允许一个用户访问多个应用程序，而只需提供一次凭证（如用户名和密码）。它还允许 web 应用程序在没有获得用户的安全凭据（如密码）的情况下对用户进行身份验证。\u0026ldquo;CAS\u0026rdquo; 也指实现了该协议的软件包。\nCAS 是由耶鲁大学 的 Shawn Bayern 创始的，后来由耶鲁大学的 Drew Mazurek 维护。CAS1.0 实现了单点登录。 CAS2.0 引入了多级代理认证（Multi-tier proxy authentication）。CAS 其他几个版本已经有了新的功能。\n2004 年 12 月，CAS 成为 Jasig（英语：Jasig）的一个项目，2008 年该组织负责 CAS 的维护和发展。CAS 原名 \u0026ldquo;耶鲁大学 CAS\u0026rdquo;，现在则被称为 \u0026ldquo;Jasig CAS\u0026rdquo;。\n原理 # Cas Server # sequenceDiagram participant c as Client (The browser) participant ws as Web Server participant cs as CAS Server c-\u0026gt;\u0026gt;ws: 访问网站地址 Note over ws: 尝试从 cookie 获取 pToken 和 sToken alt pToken 和 sToken 同时存在 ws--\u0026gt;\u0026gt;cs: /validate 验证合法性 alt 正常登录 cs--\u0026gt;\u0026gt;ws: 返回用户信息 ws-\u0026gt;\u0026gt;c: 返回用户请求内容 else 不正常 cs--\u0026gt;\u0026gt;ws: 返回状态码 204 ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 Note over c, cs: 后面流程参考底下 Loop 循环 end else 不同时存在 ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 loop 访问 CAS 登录页面 c-\u0026gt;\u0026gt;cs: 登录 alt 登录成功 cs-\u0026gt;\u0026gt;c: 返回带 ticket 的重定向，并在浏览器写入 pToken 的 cookie c-\u0026gt;\u0026gt;ws: 带有 ticket 的请求 ws--\u0026gt;\u0026gt;cs: 使用 ticket 置换 sToken alt 合法 ticket cs--\u0026gt;\u0026gt;ws: 返回 sToken ws-\u0026gt;\u0026gt;c: 返回用户请求内容，并在浏览器写入 sToken 的 cookie else 非法 ticket ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 end else 登录失败 cs-\u0026gt;\u0026gt;c: 返回错误提示页面 end end end Session Server + Cas Server # sequenceDiagram participant c as Client (The browser) participant ws as Web Server participant cs as CAS Server participant ss as Session Server c-\u0026gt;\u0026gt;ws: 访问网站地址 Note over ws: 尝试从 cookie 获取 pToken 和 sToken alt pToken 和 sToken 同时存在 ws--\u0026gt;\u0026gt;ss: /validate 验证合法性 alt 正常登录 ss--\u0026gt;\u0026gt;ws: 返回用户信息 ws-\u0026gt;\u0026gt;c: 返回用户请求内容 else 不正常 ss--\u0026gt;\u0026gt;ws: 返回状态码 204 ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 Note over c, ss: 后面流程参考底下 Loop 循环 end else 不同时存在 ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 loop 访问 CAS 登录页面 c-\u0026gt;\u0026gt;cs: 登录 alt 登录成功 cs-\u0026gt;\u0026gt;c: 返回带 ticket 的重定向，并在浏览器写入 pToken 的 cookie c-\u0026gt;\u0026gt;ws: 带有 ticket 的请求 ws--\u0026gt;\u0026gt;cs: 使用 ticket 置换 sToken alt 合法 ticket cs--\u0026gt;\u0026gt;ws: 返回 sToken ws-\u0026gt;\u0026gt;c: 返回用户请求内容，并在浏览器写入 sToken 的 cookie else 非法 ticket ws-\u0026gt;\u0026gt;c: 返回重定向到 CAS 登录接口 end else 登录失败 ss-\u0026gt;\u0026gt;c: 返回错误提示页面 end end end 参考 # mermaid "},{"id":244,"href":"/note-cs/docs/tool/macos/codelabs/","title":"Codelabs","section":"4.1 MacOS","content":" Codelabs # 简介 # Google Developers Codelabs # 中国内地访问 clmirror.storage.googleapis.com\nHello Istio Codelab(with Google Kubernetes Engine) googlecodelabs/tools # Codelabs management \u0026amp; hosting tools\n"},{"id":245,"href":"/note-cs/docs/domain/cc/others/saas/crm/","title":"CRM","section":"SaaS","content":" CRM # "},{"id":246,"href":"/note-cs/docs/basic/pl/shell/type/dash/","title":"Dash","section":"1.3.4 Shell 类型","content":" Dash # Dash 与 Bash 的区别 # 定义函数 bash: function 在 bash 中为关键字\ndash: dash 中没有 function 这个关键字\n2.select var in list; do command; done\nbash: 支持\ndash: 不支持，替代方法：采用 while+read+case 来实现\necho {0..10} bash: 支持 {n..m} 展开\ndash: 不支持，替代方法，采用 seq 外部命令\nhere string bash: 支持 here string\ndash: 不支持，替代方法：可采用 here documents\n\u0026amp;word 重定向标准输出和标准错误\nbash: 当 word 为非数字时，\u0026gt;\u0026amp;word 变成重定向标准错误和标准输出到文件 word\ndash: \u0026gt;\u0026amp;word, word 不支持非数字，替代方法: \u0026gt;word 2\u0026gt;\u0026amp;1; 常见用法 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1\n数组 bash: 支持数组，bash4 支持关联数组\ndash: 不支持数组，替代方法，采用变量名 + 序号来实现类似的效果\n子字符串扩展 bash: 支持 ${parameter:offset:length},${parameter:offset}\ndash: 不支持， 替代方法：采用 expr 或 cut 外部命令代替\n大小写转换 bash: 支持 ${parameter^pattern},${parameter^^pattern},${parameter,pattern},${parameter,,pattern}\ndash: 不支持，替代方法：采用 tr/sed/awk 等外部命令转换\n进程替换 \u0026lt;(command), \u0026gt;(command) bash: 支持进程替换\ndash: 不支持，替代方法，通过临时文件中转\n[string1 = string2] 和 [ string1 == string2 ] bash: 支持两者\ndash: 只支持 =\n[[ 加强版 test bash: 支持 [[]], 可实现正则匹配等强大功能\ndash: 不支持 [[]], 替代方法，采用外部命令\nfor (( expr1 ; expr2 ; expr3 )) ; do list ; done bash: 支持 C 语言格式的 for 循环\ndash: 不支持该格式的 for, 替代方法，用 while+$((expression)) 实现\nlet 命令和 ((expression)) bash: 有内置命令 let, 也支持 ((expression)) 方式\ndash: 不支持，替代方法，采用 $((expression)) 或者外部命令做计算\n$((expression)) bash: 支持 id++,id–,++id,–id 这样到表达式\ndash: 不支持 ++,–, 替代方法:id+=1,id-=1, id=id+1,id=id-1\n为什么 Ubuntu 要将 sh 链接到 dash # 因为 Ubuntu 不存在 sh。而系统很多脚本指定用 sh。 /bin/sh is meant for system scripts, which may or may not have come from older versions of Ubuntu and/or other systems.\n参考：https://askubuntu.com/questions/976485/what-is-the-point-of-sh-being-linked-to-dash\n"},{"id":247,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/","title":"Envoy","section":"2.8 生态","content":" Envoy # envoyproxy/envoy 线程模型 # Envoy 使用单进程 - 多线程的架构模型。 一个 master 线程管理各种琐碎的任务，而一些 worker 线程则负责执行监听、过滤和转发。 当监听器接收到一个连接请求时，该连接将其生命周期绑定到一个单独的 worker 线程。 这使得 Envoy 主要使用大量单线程（ embarrassingly parallel ）处理工作，并且只有少量的复杂代码用于实现 worker 线程之间的协调工作。 通常情况下，Envoy 实现了 100% 的非阻塞。 对于大多数工作负载，我们建议将 worker 线程数配置为 CPU 的线程数。\n参考：\nhttps://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/intro/threading_model BUILT ON ENVOY # datawire/ambassador cilium/cilium Cloud Foundry hashicorp/consul projectcontour/contour saarasio/enroute projectcontour/gimbal solo-io/envoy-operator tetratelabs/getenvoy solo-io/gloo istio/istio kumahq/kuma turbinelabs/rotor solo-io/service-mesh-hub 参考：\nhttps://www.envoyproxy.io/community envoy timeout # chemicL/envoy-timeouts Demonstrating Envoy timeouts and their impact on service to service communication\n"},{"id":248,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/api/","title":"Envoy API","section":"Envoy","content":" Envoy API # API versioning guidelines # UDPA # Universal Data Plane API\ncncf/udpa Universal Data Plane API Working Group (UDPA-WG) Goal: The objective of the Universal Data Plane API Working Group (UDPA-WG) is to bring together parties across the industry interested in a common control and configuration API for data plane proxies and load balancers.\n"},{"id":249,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/filter/","title":"Envoy filters","section":"Envoy","content":" Envoy filters # Lua filter # envoy-apisix # api7/envoy-apisix A Lua framework that support Apache APISIX plugins run directly in Envoy Lua filter without modify Envoy.\n"},{"id":250,"href":"/note-cs/docs/study/skill/type/epub/","title":"epub","section":"文档类型","content":" epub # "},{"id":251,"href":"/note-cs/docs/study/skill/stream-media/debug/gdb/tutorial/","title":"GDB 教程","section":"GDB","content":" GDB 教程 # "},{"id":252,"href":"/note-cs/docs/study/course/basic/pl/go/","title":"go","section":"6.1.5 编程语言","content":" go # "},{"id":253,"href":"/note-cs/docs/study/course/basic/pl/go/go-wiki/","title":"go wiki","section":"go","content":" go wiki # 学习进度 # Getting started with Go Working with Go Learning more about Go Learning Go - A collection of resources for learning Go - beginner to advanced. Best Practices for a New Go Developer - Insights from Go community members. Server programming - Building web, mobile, and API servers. More on concurrency More on error handling More on testing More on mobile - Android and iOS Books - A list of Go books that have been published (ebook, paper) Blogs - Blogs about Go Podcasts - Podcasts and episodes featuring Go Videos, Talks and Presentations GopherVids is a searchable index of videos about Go. GoTalks - A collection of talks from Go conferences and meetups. Screencasts Articles - A collection of articles to help you learn more about Go. Training - Free and commercial, online and classroom training for Go. University Courses - A list of CS programs and classes using Go. Resources for non-English speakers The Go Community Using the go toolchain Additional Go Programming Wikis Why Go doesn\u0026rsquo;t Support Generics: A Summary of Go Generics Discussions - Start here before you join the debate. Concurrency Timeouts - Abandon async calls that take too long LockOSThread MutexOrChannel - When to use one vs the other RaceDetector - How to detect and fix race conditions Working with Databases database/sql - Online tutorial for working with the database/sql package. TUGTBDDAwG - Guide to building data driven apps. SQLDrivers SQLInterface From other languages Go for Java Programmers Go for C++ Programmers Strings GoStrings String Matching Comments CommonMistakes Errors GcToolchainTricks Hashing HttpFetch HttpStaticFiles InterfaceSlice Iota MethodSets PanicAndRecover Range RateLimiting Rationales SendingMail SignalHandling SimultaneousAssignment SliceTricks Switch TableDrivenTests Online Services that work with Go Troubleshooting Go Programs in Production Understand the performance of your Go apps using the pprof package Heap Dumps heapdump13 heapdump14 heapdump15 Contributing to the Go Project Platform Specific Information Release Specific Information Questions "},{"id":254,"href":"/note-cs/docs/tool/macos/hugo/","title":"Hugo","section":"4.1 MacOS","content":" Hugo 快速上手 # 简介 # 参考官网：https://gohugo.io\nHugo 配置 # 参考：https://themes.gohugo.io/hugo-book\nHugo 主题 # hugo-academic # 适合作为个人主页，内容比较丰富，尤其适合作为技术或科研人员的博客。\nhugo-book # 适合记笔记，或者写书。我很喜欢他右侧的页面目录，类似语雀。 其实语雀编辑体验很好，尤其是最近改版后允许用户直接在左侧目录操作新增页面。 不使用语雀，而使用 github pages，最关键也可以说唯一的原因就是对其他平台不放心，内容还是自己保管比较好。 不然万一哪天平台下线，只是一个道歉页面，而作为免费用户，只能自己想办法导出笔记，想想还是算了。 参考：https://themes.gohugo.io\nAcademic # 配置 # 写博客 # hugo new \u0026ndash;kind post post/my-post\nhugo-book # 参考 # https://github.com/alex-shpak/hugo-book https://themes.gohugo.io/hugo-book KaTeX/KaTeX TeX wiki "},{"id":255,"href":"/note-cs/docs/domain/cc/virtual/hyperkit/","title":"HyperKit","section":"虚拟化","content":" HyperKit # "},{"id":256,"href":"/note-cs/docs/domain/cc/others/iaas/","title":"IaaS","section":"其他","content":" IaaS # "},{"id":257,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/tracing/jaeger/","title":"Jaeger","section":"Distributed Tracing","content":" Jaeger # Jaeger \\ˈyā-gər\\\njaegertracing/jaeger CNCF Jaeger, a Distributed Tracing Platform https://www.jaegertracing.io/\n"},{"id":258,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/kong-ingress/","title":"Kong Ingress","section":"Ingress Controller","content":" Kong Ingress # Kong/kubernetes-ingress-controller Kong for Kubernetes\n"},{"id":259,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/xds/lds/","title":"LDS","section":"xDS","content":" LDS # 监听器发现服务（LDS）是一个可选的 API，Envoy 将调用它来动态获取监听器。Envoy 将协调 API 响应，并根据需要添加、修改或删除已知的监听器。\n监听器更新的语义如下：\n每个监听器必须有一个独特的名字。如果没有提供名称，Envoy 将创建一个 UUID。要动态更新的监听器，管理服务必须提供监听器的唯一名称。 当一个监听器被添加，在参与连接处理之前，会先进入 “预热” 阶段。例如，如果监听器引用 RDS 配置，那么在监听器迁移到 “active” 之前，将会解析并提取该配置。 监听器一旦创建，实际上就会保持不变。因此，更新监听器时，会创建一个全新的监听器（使用相同的侦听套接字）。新增加的监听者都会通过上面所描述的相同 “预热” 过程。 当更新或删除监听器时，旧的监听器将被置于 “draining（逐出）” 状态，就像整个服务重新启动时一样。监听器移除之后，该监听器所拥有的连接，经过一段时间优雅地关闭（如果可能的话）剩余的连接。逐出时间通过 --drain-time-s 选项设置。 注意\n任何在 Envoy 配置中静态定义的监听器都不能通过 LDS API 进行修改或删除。\n"},{"id":260,"href":"/note-cs/docs/study/skill/stream-media/debug/lldb/","title":"LLDB","section":"Debug","content":" LLDB # "},{"id":261,"href":"/note-cs/docs/study/skill/stream-media/debug/lldb/tutorial/","title":"LLDB 教程","section":"LLDB","content":" LLDB 教程 # "},{"id":262,"href":"/note-cs/docs/study/skill/stream-media/lorawan/chirpstack/network/","title":"Network","section":"ChirpStack","content":" ChirpStack Network Server # ChirpStack Network Server is an open-source LoRaWAN network-server. https://www.chirpstack.io\n数据库 # Schema Name Type Owner public code_migration table chirpstack_ns public device table chirpstack_ns public device_activation table chirpstack_ns public device_activation_id_seq sequence chirpstack_ns public device_multicast_group table chirpstack_ns public device_profile table chirpstack_ns public device_queue table chirpstack_ns public device_queue_id_seq sequence chirpstack_ns public gateway table chirpstack_ns public gateway_board table chirpstack_ns public gateway_profile table chirpstack_ns public gateway_profile_extra_channel table chirpstack_ns public gateway_profile_extra_channel_id_seq sequence chirpstack_ns public gateway_stats table chirpstack_ns public gateway_stats_id_seq sequence chirpstack_ns public gorp_migrations table chirpstack_ns public multicast_group table chirpstack_ns public multicast_queue table chirpstack_ns public multicast_queue_id_seq sequence chirpstack_ns public routing_profile table chirpstack_ns public service_profile table chirpstack_ns (21 rows)\n"},{"id":263,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/nginx/","title":"Nginx","section":"2.8 生态","content":" Nginx # nginx/nginx 教程 # Nginx 开发从入门到精通 # taobao/nginx-book "},{"id":264,"href":"/note-cs/docs/direction/be/auth/oauth/","title":"OAuth","section":"认证与授权","content":" OAuth # 版本 # 2.0 # OAuth 2.0 协议参考 rfc6749\n1.0 # 参考：\nOAuth 1.0，1.0a 和 2.0 的之间的区别有哪些？ 授权方式 # 授权码（authorization-code） 隐藏式（implicit） 密码式（password）： 客户端凭证（client credentials） 参考：\n一口气说出 OAuth2.0 的四种授权方式 问答 # 为什么需要 Refresh Token # 这样的处理是为了职责的分离：\nrefresh token 负责身份认证 access token 负责请求资源。 参考 # Choosing an SSO Strategy: SAML vs OAuth2 rfc6749 为什么 OAuth2 里面在获取 access token 之前一定要先获取 code，然后再用 code 去获取 access token？ Oauth 为什么不直接返回用户信息，而是返回 Access Token，然后用 AT 再去请求用户信息？ "},{"id":265,"href":"/note-cs/docs/direction/be/auth/openid/","title":"OpenID","section":"认证与授权","content":" OpenID # OpenID vs OAuth # OpenID 只用于身份认证（Authentication），允许你以同一个账户在多个网站登陆。它仅仅是为你的合法身份背书，当你以 Facebook 账号登陆某个站点之后，该站点无权访问你的在 Facebook 上的数据 OAuth 用于授权（Authorisation），允许被授权方访问授权方的用户数据 "},{"id":266,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/openresty/","title":"OpenResty","section":"2.8 生态","content":" OpenResty # openresty/openresty 参考：\nOpenResty 究竟解决了什么痛点？ 教程 # 参考：\nProgramming OpenResty - 章亦春 OpenResty 最佳实践 "},{"id":267,"href":"/note-cs/docs/domain/cc/istio/code/istio/pilot/","title":"Pilot","section":"3.1 Istio","content":" Pilot # 若无特别说明，本文是根据 [Istio 1.6.5](https://github.com/istio/istio/tree/1.6.5) 进行分析。 pilot discovery # 函数调用栈 # NewServer initConfigController makeKubeConfigController (add schema) collections.Pilot.All() NewClient NewController (add stores for CRD kinds) addInformer newCacheHandler informer := cache.NewSharedIndexInformer(\u0026hellip;) informer.AddEventHandler queue.Push(onEvent) s.ConfigStores = append(s.ConfigStores, configController) aggregateConfigController, err := configaggregate.MakeCache(s.ConfigStores) s.configController = aggregateConfigController addStartFunc initServiceControllers NewServiceDiscovery RegisterEventHandler: 注册 serviceEntryKind 与 workloadEntryKind 的 handler initDiscoveryService initEventHandlers 定义 handler s.EnvoyXdsServer.ConfigUpdate(pushReq): 真正做的事情，更新 envoy xds 配置 添加 handler discoveryServer.Start(stop) (crd controller) Run informer.Run(stop) cache.WaitForCacheSync(stop, c.HasSynced): 等待 Informer 完成一次本地缓存的数据同步操作 c.queue.Run(stop): 执行 queue.tasks，即 cacheHandler.onEvent 执行 handlers "},{"id":268,"href":"/note-cs/docs/direction/be/web/rest/","title":"REST","section":"Web Service","content":" REST # Representational state transfer (REST) is a software architectural style that defines a set of constraints to be used for creating Web services.\n"},{"id":269,"href":"/note-cs/docs/study/skill/stream-media/stream-media/rtmp/","title":"RTMP","section":"流媒体技术","content":" RTMP # Real-Time Messaging Protocol\n默认端口：1935\n握手 # 复杂握手 # RTMP vs RTSP # 目前直播方案是：rtmp 推到 server，然后转 rtmp/http-flv/hls.\n直播走的是互联网的路子，浏览器和 Flash 不支持 RTSP。 国内的 CDN 对 RTMP 做过优化，而 RTSP 没有。 网络中的路由器或防火墙可能对 RTSP 端口不开放。 参考：\n为什么现在的视频直播不使用 RTSP 协议而是使用 RTMP？ "},{"id":270,"href":"/note-cs/docs/study/skill/stream-media/stream-media/rtp/","title":"RTP","section":"流媒体技术","content":" RTP # 报文结构 # Ver.（2 bits）是目前协议的版本号码，目前版号是 2。 P（1 bit）是用于 RTP 报文（packet）结束点的预留空间，视报文是否需要多余的填塞空间。 X（1 bit）是否在使用延伸空间于报文之中。 CC（4 bits）包含了 CSRC 数目用于修正标头（fixed header）。 M（1 bit）是用于应用等级以及其原型（profile）的定义。如果不为零表示目前的数据有特别的程序解译。 PT（7 bits）是指 payload 的格式并决定将如何去由应用程序加以解译。 SSRC 是同步化来源。 RTP Header # 前 12 个字节出现在每个 RTP 包中，仅仅在被混合器插入时，才出现 CSRC 识别符列表。\nRTP/PS/H.264 # 基于 RTP 的 PS 封装 首先按照 ISO/IEC 13818-1:2000 将视音频封装成 PS 包， 再将 PS 包以负载的方式封装成 RTP 包。\nPS 包 # 进行 PS 封装时，将每个视频帧封装为一个PS 包， 且每个关键帧的 PS 包中包含系统头（System Header）和 PSM（Program Stream Map）。\n系统头和 PSM 放置于 PS 包头之后，第一个 PES 包之前。\nRTP 包 # 首条数据结构：RTP Header + PS Header + PS System Header + PSM + PESV（Header + Payload）\n非首条数据结构：RTP Header + PS Header + PESV（Header + Payload）\n少了 PS System Header + PSM\nPESV: 视频 PESA: 音频 知道了 PS 包的结构，就可以用处理程序解析数据， 从而把原始流 ES（H264）从 PES 包中解析出来\nPES Payload 就是 H264 数据\nRTP 头部 # 去掉 12 字节的 RTP 头部，保存下来的就是 H264 PS 流， VLC 可播放\n第 1 字节\n第 2 字节\n第 3-4 字节\n第 5-8 字节\n第 9-12 字节\nRTP Payload # RTP Payload 中承载的即为 PS 数据 起始的 00 00 01 ba 代表 PS 包的开始 接下来跳过 9 个字节，暂时不关心它的内容 看第 10 个字节 fe，对应着二进制数据的 1111 1110 它的后三位为 110 为十进制的 6，即接下来的六个字节是扩展内容 跳过 6 个字节后，遇到了 00 00 01 bb，这时来到了 PS System Header 部分 PS 数据格式的标准文档可以参考这个 PDF：iso13818-1:2000.pdf 紧邻的 00 12 两个字节表示 System Header 的长度，换算为十进制，即为 18 个字节 在 header_length 后共有 6 个字节的数据 之后就是 stream_id 字段（码流种类） system_id 值为 e0 0xE0: 视频流 0xC0: 音频流 payload type: PS (96) SSRC: Synchronization source Synchronization Source identifier (32 bits) CSRC: Contributing source Contributing source IDs (32 bits each) RTP -\u0026gt; RTSP/RTMP # 需要遇到 sps pps idr 才能生成\nNALU (NAL Units) 组成\nNALU 头（00 00 00 01 或者 00 00 01） sps (序列参数集) pps (图像参数集合) slice sei IDR 帧 I 帧（在图像运动变化较少时，I 帧后面是 7 个 P 帧，如果图像运动变化大时，一个序列就短了，I 帧后面可能是 3 个或者 4 个 P 帧） P 帧 B 帧等数据。 一个完整的 NALU 单元结构图\n参考：\nRTP 接收 28281 的收流生成流媒体的时间很长 H.264 码流结构 (H.264 Data Structure) 参考 # 海康摄像头 PS 流格式解析（RTP/PS/H264） 基于 GB28181 从海康 NVR 获取目录 / 点播 / 回播信令备忘 RTP 协议全解析（H264 码流和 PS 流） "},{"id":271,"href":"/note-cs/docs/study/skill/stream-media/stream-media/rtsp/","title":"RTSP","section":"流媒体技术","content":" RTSP # Real Time Streaming Protocol\n默认端口：554\n方法 # 一般的顺序是：\nOPTIONS DESCRIBE SETUP PLAY TEARDOWN OPTIONS # 请求返回服务器将接受的请求类型。\nC-\u0026gt;S: OPTIONS rtsp://example.com/media.mp4 RTSP/1.0 CSeq: 1 Require: implicit-play Proxy-Require: gzipped-messages S-\u0026gt;C: RTSP/1.0 200 OK CSeq: 1 Public: DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE DESCRIBE # SETUP # TEARDOWN # PLAY # PAUSE # 包详情 # 海康摄像头\nOPTIONS rtsp://172.17.11.155:554/h264/ch1/main/av_stream RTSP/1.0 CSeq: 2 User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) # OPTIONS ：这个是选项，问下服务器我到底有啥本领技能？ RTSP/1.0 200 OK CSeq: 2 Public: OPTIONS, DESCRIBE, PLAY, PAUSE, SETUP, TEARDOWN, SET_PARAMETER, GET_PARAMETER Date: Tue, May 23 2017 16:08:47 GMT # 服务器回复你，你有这么多技能：OPTIONS, DESCRIBE, PLAY, PAUSE, SETUP, TEARDOWN, SET_PARAMETER, GET_PARAMETER DESCRIBE rtsp://172.17.11.155:554/h264/ch1/main/av_stream RTSP/1.0 CSeq: 3 User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Accept: application/sdp # DESCRIBE ：我想让服务器描述一下流的情况，你用sdp的格式告诉我吧 RTSP/1.0 401 Unauthorized CSeq: 3 WWW-Authenticate: Digest realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, stale=\u0026#34;FALSE\u0026#34; WWW-Authenticate: Basic realm=\u0026#34;1868cb21d4df\u0026#34; Date: Tue, May 23 2017 16:08:47 GMT # 服务器回答，你没有认证（用户密码），所以给你401吧 DESCRIBE rtsp://172.17.11.155:554/h264/ch1/main/av_stream RTSP/1.0 CSeq: 4 Authorization: Digest username=\u0026#34;admin\u0026#34;, realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, uri=\u0026#34;rtsp://172.17.11.155:554/h264/ch1/main/av_stream\u0026#34;, response=\u0026#34;8b9d4d3e6ae627b62f430874a8c6e333\u0026#34; User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Accept: application/sdp # DESCRIBE ：我表示不服，再上诉：让服务器描述一下流的情况，你用sdp的格式告诉我吧 RTSP/1.0 200 OK CSeq: 4 Content-Type: application/sdp Content-Base: rtsp://172.17.11.155:554/h264/ch1/main/av_stream/ Content-Length: 598 v=0 o=- 1495555727123750 1495555727123750 IN IP4 172.17.10.7 s=Media Presentation e=NONE b=AS:5050 t=0 0 a=control:rtsp://172.17.11.155:554/h264/ch1/main/av_stream/ m=video 0 RTP/AVP 96 c=IN IP4 0.0.0.0 b=AS:5000 a=recvonly a=x-dimensions:1920,1080 a=control:rtsp://172.17.11.155:554/h264/ch1/main/av_stream/trackID=1 a=rtpmap:96 H264/90000 a=fmtp:96 profile-level-id=420029; packetization-mode=1; sprop-parameter-sets=Z00AKpWoHgCJ+WEAAAcIAAFfkAQ=,aO48gA== a=Media_header:MEDIAINFO=494D4B48010200000400000100000000000000000000000000000000000000000000000000000000; a=appversion:1.0 # 服务器答应了，然后把SDP发给我了 # 里面有各种信息：我看到只有一路视频，1080P的，H264编码； # 96是视频流ID, 这符合规范，mediainfo可能是sps pps的加密信息 SETUP rtsp://172.17.11.155:554/h264/ch1/main/av_stream/trackID=1 RTSP/1.0 CSeq: 5 Authorization: Digest username=\u0026#34;admin\u0026#34;, realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, uri=\u0026#34;rtsp://172.17.11.155:554/h264/ch1/main/av_stream/\u0026#34;, response=\u0026#34;a34897f9b42eb7f501d549f6fa558838\u0026#34; User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Transport: RTP/AVP/TCP;unicast;interleaved=0-1 # SETUP ：为了透过防火墙，我想指定传输机制RTP/AVP/TCP告诉服务器 RTSP/1.0 200 OK CSeq: 5 Session: 313720730;timeout=60 Transport: RTP/AVP/TCP;unicast;interleaved=0-1;ssrc=72a9bdb8;mode=\u0026#34;play\u0026#34; Date: Tue, May 23 2017 16:08:47 GMT # 服务器准了，并告诉你可以play了 PLAY rtsp://172.17.11.155:554/h264/ch1/main/av_stream/ RTSP/1.0 CSeq: 6 Authorization: Digest username=\u0026#34;admin\u0026#34;, realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, uri=\u0026#34;rtsp://172.17.11.155:554/h264/ch1/main/av_stream/\u0026#34;, response=\u0026#34;13e073b1f7a0d1be0442491ba4613c35\u0026#34; User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Session: 313720730 Range: npt=0.000- # PLAY ：我想告诉服务器以SETUP指定的机制开始发送数据； # 还可以用关键字Range指定play的范围 RTSP/1.0 200 OK CSeq: 6 Session: 313720730 RTP-Info: url=rtsp://172.17.11.155:554/h264/ch1/main/av_stream/trackID=1;seq=13657;rtptime=106503066 Date: Tue, May 23 2017 16:08:47 GMT # 服务器很听话，给到了初始的随机序列号和随机时间戳seq=13657;rtptime=106503066 GET_PARAMETER rtsp://172.17.11.155:554/h264/ch1/main/av_stream/ RTSP/1.0 CSeq: 7 Authorization: Digest username=\u0026#34;admin\u0026#34;, realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, uri=\u0026#34;rtsp://172.17.11.155:554/h264/ch1/main/av_stream/\u0026#34;, response=\u0026#34;5845426a0c6ce7ca7839ac9e639d7197\u0026#34; User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Session: 313720730 # GET_PARAMETER ：我请求检查URL指定的演示与媒体的参数值。 # 没有实体体时，也许能用来测试用户与服务器的连通情况 $.. .`5Y.Y..r...gM.*......a......_..$....`5Z.Y..r...h.\u0026lt;.$....`5[.Y..r......y....$....`5\\.Y..r...|....sT...e....Z\u0026amp;x]A....UF...8..I..O...x.4ZC/|$.. # 一堆数据？ TEARDOWN rtsp://172.17.11.155:554/h264/ch1/main/av_stream/ RTSP/1.0 CSeq: 14 Authorization: Digest username=\u0026#34;admin\u0026#34;, realm=\u0026#34;1868cb21d4df\u0026#34;, nonce=\u0026#34;cfbaf30c677edba80dbd7f0eb1df5db6\u0026#34;, uri=\u0026#34;rtsp://172.17.11.155:554/h264/ch1/main/av_stream/\u0026#34;, response=\u0026#34;a52194fbc2c6433e1f1dbf33576a7f7c\u0026#34; User-Agent: LibVLC/2.2.4 (LIVE555 Streaming Media v2016.02.22) Session: 313720730 $..(......[.r.........l...................[. # TEARDOWN ：不玩了，就停止给定URL流发送数据，并释放相关资源 RTSP/1.0 200 OK CSeq: 14 Session: 313720730 Date: Tue, May 23 2017 16:15:10 GMT # 好的，服务器说：对你这个会话Session: 313720730， 我把它干掉 参考：\nRTSP 抓包详解 参考 # WireShark 查看 vlc 播放 rtsp 流过程，抓包分离出 h264 流 "},{"id":272,"href":"/note-cs/docs/basic/pl/ruby/advanced/frame/rainls/","title":"Ruby on Rails","section":"2.7 框架","content":" Ruby on Rails # rails/rails "},{"id":273,"href":"/note-cs/docs/domain/cc/others/saas/crm/salesforce/","title":"Salesforce","section":"CRM","content":" Salesforce # "},{"id":274,"href":"/note-cs/docs/direction/be/db/redis/source/type/string/","title":"String 实现","section":"类型实现","content":" Redis String 类型实现 # Redis 中的字符串是一种 动态字符串，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 ArrayList，有一个字符数组，从源码的 sds.h/sdshdr 文件 中可以看到 Redis 底层对于字符串的定义 SDS，即 Simple Dynamic String 结构：\n/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 你会发现同样一组结构 Redis 使用泛型定义了好多次，为什么不直接使用 int 类型呢？\n因为当字符串比较短的时候，len 和 alloc 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。\nSDS 与 C 字符串的区别 # 为什么不考虑直接使用 C 语言的字符串呢？\nC 字符串太简单 # 因为 C 语言这种简单的字符串表示方式 不符合 Redis 对字符串在安全性、效率以及功能方面的要求。\nC 语言使用了一个长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组最后一个元素总是 \u0026lsquo;\\0\u0026rsquo;。\n这样简单的数据结构可能会造成以下一些问题：\n获取字符串长度为 O (N) 级别的操作 → 因为 C 不保存数组的长度，每次都需要遍历一遍整个数组； 不能很好的杜绝 缓冲区溢出 / 内存泄漏 的问题 → 跟上述问题原因一样，如果执行拼接 or 缩短字符串的操作，如果操作不当就很容易造成上述问题； C 字符串 只能保存文本数据 → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中间出现的 \u0026lsquo;\\0\u0026rsquo; 可能会被判定为提前结束的字符串而识别不了； 以追加字符串的操作举例，Redis 源码如下：\n/* Append the specified binary-safe string pointed by \u0026#39;t\u0026#39; of \u0026#39;len\u0026#39; bytes to the * end of the specified sds string \u0026#39;s\u0026#39;. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */ sds sdscatlen(sds s, const void *t, size_t len) { // 获取原字符串的长度 size_t curlen = sdslen(s); // 按需调整空间，如果容量不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中 s = sdsMakeRoomFor(s,len); if (s == NULL) return NULL; // 内存不足 memcpy(s+curlen, t, len); // 追加目标字符串到字节数组中 sdssetlen(s, curlen+len); // 设置追加后的长度 s[curlen+len] = \u0026#39;\\0\u0026#39;; // 让字符串以 \\0 结尾，便于调试打印 return s; } 参考 # 5 种基本数据结构 "},{"id":275,"href":"/note-cs/docs/domain/cc/virtual/vmware/","title":"VMware Fusion","section":"虚拟化","content":" VMware Fusion # "},{"id":276,"href":"/note-cs/docs/study/skill/stream-media/stream-media/webrtc/","title":"WebRTC","section":"流媒体技术","content":" WebRTC # Web Real-Time Communication\n支持网页浏览器进行实时语音对话或视频对话的 API\n"},{"id":277,"href":"/note-cs/docs/basic/pl/lua/appendix/tutorial/learn-lua-in-x-minutes/","title":"X 分钟速成 Lua","section":"4.1 教程","content":" X 分钟速成 Lua # -- 单行注释以两个连字符开头 --[[ 多行注释 --]] ---------------------------------------------------- -- 1. 变量和流程控制 ---------------------------------------------------- num = 42 -- 所有的数字都是双精度浮点型。 -- 别害怕，64位的双精度浮点型数字中有52位用于 -- 保存精确的整型值; 对于52位以内的整型值， -- 不用担心精度问题。 s = \u0026#39;walternate\u0026#39; -- 和Python一样，字符串不可变。 t = \u0026#34;也可以用双引号\u0026#34; u = [[ 多行的字符串 以两个方括号 开始和结尾。]] t = nil -- 撤销t的定义; Lua 支持垃圾回收。 -- 块使用do/end之类的关键字标识： while num \u0026lt; 50 do num = num + 1 -- 不支持 ++ 或 += 运算符。 end -- If语句： if num \u0026gt; 40 then print(\u0026#39;over 40\u0026#39;) elseif s ~= \u0026#39;walternate\u0026#39; then -- ~= 表示不等于。 -- 像Python一样，用 == 检查是否相等 ；字符串同样适用。 io.write(\u0026#39;not over 40\\n\u0026#39;) -- 默认标准输出。 else -- 默认全局变量。 thisIsGlobal = 5 -- 通常使用驼峰。 -- 如何定义局部变量： local line = io.read() -- 读取标准输入的下一行。 -- ..操作符用于连接字符串： print(\u0026#39;Winter is coming, \u0026#39; .. line) end -- 未定义的变量返回nil。 -- 这不是错误： foo = anUnknownVariable -- 现在 foo = nil. aBoolValue = false --只有nil和false为假; 0和 \u0026#39;\u0026#39;均为真！ if not aBoolValue then print(\u0026#39;false\u0026#39;) end -- \u0026#39;or\u0026#39;和 \u0026#39;and\u0026#39;短路 -- 类似于C/js里的 a?b:c 操作符： ans = aBoolValue and \u0026#39;yes\u0026#39; or \u0026#39;no\u0026#39; --\u0026gt; \u0026#39;no\u0026#39; karlSum = 0 for i = 1, 100 do -- 范围包含两端 karlSum = karlSum + i end -- 使用 \u0026#34;100, 1, -1\u0026#34; 表示递减的范围： fredSum = 0 for j = 100, 1, -1 do fredSum = fredSum + j end -- 通常，范围表达式为begin, end[, step]. -- 循环的另一种结构： repeat print(\u0026#39;the way of the future\u0026#39;) num = num - 1 until num == 0 ---------------------------------------------------- -- 2. 函数。 ---------------------------------------------------- function fib(n) if n \u0026lt; 2 then return n end return fib(n - 2) + fib(n - 1) end -- 支持闭包及匿名函数： function adder(x) -- 调用adder时，会创建返回的函数， -- 并且会记住x的值： return function (y) return x + y end end a1 = adder(9) a2 = adder(36) print(a1(16)) --\u0026gt; 25 print(a2(64)) --\u0026gt; 100 -- 返回值、函数调用和赋值都可以 -- 使用长度不匹配的list。 -- 不匹配的接收方会被赋值nil； -- 不匹配的发送方会被丢弃。 x, y, z = 1, 2, 3, 4 -- x = 1、y = 2、z = 3, 而 4 会被丢弃。 function bar(a, b, c) print(a, b, c) return 4, 8, 15, 16, 23, 42 end x, y = bar(\u0026#39;zaphod\u0026#39;) --\u0026gt; 打印 \u0026#34;zaphod nil nil\u0026#34; -- 现在 x = 4, y = 8, 而值15..42被丢弃。 -- 函数是一等公民，可以是局部的，也可以是全局的。 -- 以下表达式等价： function f(x) return x * x end f = function (x) return x * x end -- 这些也是等价的： local function g(x) return math.sin(x) end local g; g = function (x) return math.sin(x) end -- 以上均因\u0026#39;local g\u0026#39;，使得g可以自引用。 local g = function(x) return math.sin(x) end -- 等价于 local function g(x)..., 但函数体中g不可自引用 -- 顺便提下，三角函数以弧度为单位。 -- 用一个字符串参数调用函数，可以省略括号： print \u0026#39;hello\u0026#39; --可以工作。 -- 调用函数时，如果只有一个table参数， -- 同样可以省略括号（table详情见下）： print {} -- 一样可以工作。 ---------------------------------------------------- -- 3. Table。 ---------------------------------------------------- -- Table = Lua唯一的组合数据结构; -- 它们是关联数组。 -- 类似于PHP的数组或者js的对象， -- 它们是哈希表或者字典，也可以当列表使用。 -- 按字典/map的方式使用Table： -- Dict字面量默认使用字符串类型的key： t = {key1 = \u0026#39;value1\u0026#39;, key2 = false} -- 字符串key可以使用类似js的点标记： print(t.key1) -- 打印 \u0026#39;value1\u0026#39;. t.newKey = {} -- 添加新的键值对。 t.key2 = nil -- 从table删除 key2。 -- 使用任何非nil的值作为key： u = {[\u0026#39;@!#\u0026#39;] = \u0026#39;qbert\u0026#39;, [{}] = 1729, [6.28] = \u0026#39;tau\u0026#39;} print(u[6.28]) -- 打印 \u0026#34;tau\u0026#34; -- 数字和字符串的key按值匹配的 -- table按id匹配。 a = u[\u0026#39;@!#\u0026#39;] -- 现在 a = \u0026#39;qbert\u0026#39;. b = u[{}] -- 我们或许期待的是 1729, 但是得到的是nil: -- b = nil ，因为没有找到。 -- 之所以没找到，是因为我们用的key与保存数据时用的不是同 -- 一个对象。 -- 所以字符串和数字是移植性更好的key。 -- 只需要一个table参数的函数调用不需要括号： function h(x) print(x.key1) end h{key1 = \u0026#39;Sonmi~451\u0026#39;} -- 打印\u0026#39;Sonmi~451\u0026#39;. for key, val in pairs(u) do -- 遍历Table print(key, val) end -- _G 是一个特殊的table，用于保存所有的全局变量 print(_G[\u0026#39;_G\u0026#39;] == _G) -- 打印\u0026#39;true\u0026#39;. -- 按列表/数组的方式使用： -- 列表字面量隐式添加整数键： v = {\u0026#39;value1\u0026#39;, \u0026#39;value2\u0026#39;, 1.21, \u0026#39;gigawatts\u0026#39;} for i = 1, #v do -- #v 是列表的大小 print(v[i]) -- 索引从 1 开始!! 太疯狂了！ end -- \u0026#39;list\u0026#39;并非真正的类型，v 其实是一个table， -- 只不过它用连续的整数作为key，可以像list那样去使用。 ---------------------------------------------------- -- 3.1 元表（metatable） 和元方法（metamethod）。 ---------------------------------------------------- -- table的元表提供了一种机制，支持类似操作符重载的行为。 -- 稍后我们会看到元表如何支持类似js prototype的行为。 f1 = {a = 1, b = 2} -- 表示一个分数 a/b. f2 = {a = 2, b = 3} -- 这会失败： -- s = f1 + f2 metafraction = {} function metafraction.__add(f1, f2) local sum = {} sum.b = f1.b * f2.b sum.a = f1.a * f2.b + f2.a * f1.b return sum end setmetatable(f1, metafraction) setmetatable(f2, metafraction) s = f1 + f2 -- 调用在f1的元表上的__add(f1, f2) 方法 -- f1, f2 没有关于元表的key，这点和js的prototype不一样。 -- 因此你必须用getmetatable(f1)获取元表。 -- 元表是一个普通的table， -- 元表的key是普通的Lua中的key，例如__add。 -- 但是下面一行代码会失败，因为s没有元表： -- t = s + s -- 下面提供的与类相似的模式可以解决这个问题： -- 元表的__index 可以重载用于查找的点操作符： defaultFavs = {animal = \u0026#39;gru\u0026#39;, food = \u0026#39;donuts\u0026#39;} myFavs = {food = \u0026#39;pizza\u0026#39;} setmetatable(myFavs, {__index = defaultFavs}) eatenBy = myFavs.animal -- 可以工作！感谢元表 -- 如果在table中直接查找key失败，会使用 -- 元表的__index 递归地重试。 -- __index的值也可以是function(tbl, key) -- 这样可以支持自定义查找。 -- __index、__add等的值，被称为元方法。 -- 这里是一个table元方法的清单： -- __add(a, b) for a + b -- __sub(a, b) for a - b -- __mul(a, b) for a * b -- __div(a, b) for a / b -- __mod(a, b) for a % b -- __pow(a, b) for a ^ b -- __unm(a) for -a -- __concat(a, b) for a .. b -- __len(a) for #a -- __eq(a, b) for a == b -- __lt(a, b) for a \u0026lt; b -- __le(a, b) for a \u0026lt;= b -- __index(a, b) \u0026lt;fn or a table\u0026gt; for a.b -- __newindex(a, b, c) for a.b = c -- __call(a, ...) for a(...) ---------------------------------------------------- -- 3.2 与类相似的table和继承。 ---------------------------------------------------- -- Lua没有内建的类；可以通过不同的方法，利用表和元表 -- 来实现类。 -- 下面是一个例子，解释在后面： Dog = {} -- 1. function Dog:new() -- 2. local newObj = {sound = \u0026#39;woof\u0026#39;} -- 3. self.__index = self -- 4. return setmetatable(newObj, self) -- 5. end function Dog:makeSound() -- 6. print(\u0026#39;I say \u0026#39; .. self.sound) end mrDog = Dog:new() -- 7. mrDog:makeSound() -- \u0026#39;I say woof\u0026#39; -- 8. -- 1. Dog看上去像一个类；其实它是一个table。 -- 2. 函数tablename:fn(...) 等价于 -- 函数tablename.fn(self, ...) -- 冒号（:）只是添加了self作为第一个参数。 -- 阅读7 \u0026amp; 8条 了解self变量是如何得到其值的。 -- 3. newObj是类Dog的一个实例。 -- 4. self = 被继承的类。通常self = Dog，不过继承可以改变它。 -- 如果把newObj的元表和__index都设置为self， -- newObj就可以得到self的函数。 -- 5. 备忘：setmetatable返回其第一个参数。 -- 6. 冒号（：）的作用和第2条一样，不过这里 -- self是一个实例，而不是类 -- 7. 等价于Dog.new(Dog)，所以在new()中，self = Dog。 -- 8. 等价于mrDog.makeSound(mrDog); self = mrDog。 ---------------------------------------------------- -- 继承的例子： LoudDog = Dog:new() -- 1. function LoudDog:makeSound() local s = self.sound .. \u0026#39; \u0026#39; -- 2. print(s .. s .. s) end seymour = LoudDog:new() -- 3. seymour:makeSound() -- \u0026#39;woof woof woof\u0026#39; -- 4. -- 1. LoudDog获得Dog的方法和变量列表。 -- 2. 因为new()的缘故，self拥有了一个\u0026#39;sound\u0026#39; key，参见第3条。 -- 3. 等价于LoudDog.new(LoudDog)，转换一下就是 -- Dog.new(LoudDog)，这是因为LoudDog没有\u0026#39;new\u0026#39; key， -- 但是它的元表中有 __index = Dog。 -- 结果: seymour的元表是LoudDog，并且 -- LoudDog.__index = Dog。所以有seymour.key -- = seymour.key, LoudDog.key, Dog.key -- 从其中第一个有指定key的table获取。 -- 4. 在LoudDog可以找到\u0026#39;makeSound\u0026#39;的key； -- 等价于LoudDog.makeSound(seymour)。 -- 如果有必要，子类也可以有new()，与基类相似： function LoudDog:new() local newObj = {} -- 初始化newObj self.__index = self return setmetatable(newObj, self) end ---------------------------------------------------- -- 4. 模块 ---------------------------------------------------- --[[ 我把这部分给注释了，这样脚本剩下的部分可以运行 -- 假设文件mod.lua的内容类似这样： local M = {} local function sayMyName() print(\u0026#39;Hrunkner\u0026#39;) end function M.sayHello() print(\u0026#39;Why hello there\u0026#39;) sayMyName() end return M -- 另一个文件可以使用mod.lua的功能： local mod = require(\u0026#39;mod\u0026#39;) -- 运行文件mod.lua. -- require是包含模块的标准做法。 -- require等价于: (针对没有被缓存的情况；参见后面的内容) local mod = (function () \u0026lt;contents of mod.lua\u0026gt; end)() -- mod.lua被包在一个函数体中，因此mod.lua的局部变量 -- 对外不可见。 -- 下面的代码可以工作，因为在这里mod = mod.lua 中的 M： mod.sayHello() -- Says hello to Hrunkner. -- 这是错误的；sayMyName只在mod.lua中存在： mod.sayMyName() -- 错误 -- require返回的值会被缓存，所以一个文件只会被运行一次， -- 即使它被require了多次。 -- 假设mod2.lua包含代码\u0026#34;print(\u0026#39;Hi!\u0026#39;)\u0026#34;。 local a = require(\u0026#39;mod2\u0026#39;) -- 打印Hi! local b = require(\u0026#39;mod2\u0026#39;) -- 不再打印; a=b. -- dofile与require类似，但是不缓存： dofile(\u0026#39;mod2\u0026#39;) --\u0026gt; Hi! dofile(\u0026#39;mod2\u0026#39;) --\u0026gt; Hi! (再次运行，与require不同) -- loadfile加载一个lua文件，但是并不运行它。 f = loadfile(\u0026#39;mod2\u0026#39;) -- Calling f() runs mod2.lua. -- loadstring是loadfile的字符串版本。 g = loadstring(\u0026#39;print(343)\u0026#39;) --返回一个函数。 g() -- 打印343; 在此之前什么也不打印。 --]] 参考：\nX 分钟速成 Lua "},{"id":278,"href":"/note-cs/docs/basic/pl/shell/command/xargs/","title":"xargs","section":"1.3.1 Shell 命令","content":" xargs # xargs 命令的作用，是将标准输入转为命令行参数\n-L # xargs -L 1 xargs --max-lines=1 # synonym for the -L option -L 参数指定多少行作为一个命令行参数。\n执行子目录里所有的 deploy.sh find . -name deploy.sh | xargs -L 1 sh\n-n # -L 参数虽然解决了多行的问题，但是有时用户会在同一行输入多项。 -n 参数指定每次将多少项，作为命令行参数。\n参考 # 阮一峰 xargs 命令教程 "},{"id":279,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/xds/","title":"xDS","section":"Envoy","content":" xDS # envoy 接口列表\nconst auto methods = { \u0026#34;envoy.api.v2.ClusterDiscoveryService.FetchClusters\u0026#34;, \u0026#34;envoy.api.v2.ClusterDiscoveryService.StreamClusters\u0026#34;, \u0026#34;envoy.api.v2.EndpointDiscoveryService.FetchEndpoints\u0026#34;, \u0026#34;envoy.api.v2.EndpointDiscoveryService.StreamEndpoints\u0026#34;, \u0026#34;envoy.api.v2.ListenerDiscoveryService.FetchListeners\u0026#34;, \u0026#34;envoy.api.v2.ListenerDiscoveryService.StreamListeners\u0026#34;, \u0026#34;envoy.api.v2.RouteDiscoveryService.FetchRoutes\u0026#34;, \u0026#34;envoy.api.v2.RouteDiscoveryService.StreamRoutes\u0026#34;, \u0026#34;envoy.service.discovery.v2.AggregatedDiscoveryService.StreamAggregatedResources\u0026#34;, \u0026#34;envoy.service.discovery.v2.HealthDiscoveryService.FetchHealthCheck\u0026#34;, \u0026#34;envoy.service.discovery.v2.HealthDiscoveryService.StreamHealthCheck\u0026#34;, \u0026#34;envoy.service.discovery.v2.RuntimeDiscoveryService.FetchRuntime\u0026#34;, \u0026#34;envoy.service.discovery.v2.RuntimeDiscoveryService.StreamRuntime\u0026#34;, \u0026#34;envoy.service.accesslog.v2.AccessLogService.StreamAccessLogs\u0026#34;, \u0026#34;envoy.service.metrics.v2.MetricsService.StreamMetrics\u0026#34;, \u0026#34;envoy.service.ratelimit.v2.RateLimitService.ShouldRateLimit\u0026#34;, \u0026#34;udpa.service.orca.v1.OpenRcaService.StreamCoreMetrics\u0026#34;, }; CDS # EDS # LDS # RDS # 参考：\n深入解读 Service Mesh 背后的技术细节 "},{"id":280,"href":"/note-cs/docs/direction/be/web/xml/","title":"XML","section":"Web Service","content":" XML # "},{"id":281,"href":"/note-cs/docs/direction/security/basic/xss/","title":"XSS","section":"第一部分 基础入门","content":" XSS # Cross-site scripting 跨站脚本 (wiki)\nXSS 发生的原因 # 没有将用户输入的文本进行合适的过滤，就贸然插入到 HTML 中，这很容易造成注入漏洞。 攻击者可以利用漏洞，构造出恶意的代码指令，进而利用恶意代码危害数据安全。\n不仅仅是业务上的 “用户的 UGC 内容” 可以进行注入，包括 URL 上的参数等都可以是攻击的来源。在处理输入时，以下内容都不可信：\n来自用户的 UGC 信息 来自第三方的链接 URL 参数 POST 参数 Referer （可能来自不可信的来源） Cookie （可能来自其他子域注入） XSS 有哪些注入的方法 # 在 HTML 中内嵌的文本中，恶意内容以 script 标签形成注入。 在内联的 JavaScript 中，拼接的数据突破了原本的限制（字符串，变量，方法名等）。 在标签属性中，恶意内容包含引号，从而突破属性值的限制，注入其他属性或者标签。 在标签的 href、src 等属性中，包含 javascript: 等可执行代码。 在 onload、onerror、onclick 等事件中，注入不受控制代码。 在 style 属性和标签中，包含类似 background-image:url(\u0026quot;javascript:...\u0026quot;); 的代码（新版本浏览器已经可以防范）。 在 style 属性和标签中，包含类似 expression(...) 的 CSS 表达式代码（新版本浏览器已经可以防范）。 XSS 分类 # 存储型 # 存储型 XSS 的攻击步骤：\n攻击者将恶意代码提交到目标网站的数据库中。 用户打开目标网站时，网站服务端将恶意代码从数据库取出，拼接在 HTML 中返回给浏览器。 用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行。 恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。 这种攻击常见于带有用户保存数据的网站功能，如论坛发帖、商品评论、用户私信等。\n反射型 # 反射型 XSS 的攻击步骤：\n攻击者构造出特殊的 URL，其中包含恶意代码。 用户打开带有恶意代码的 URL 时，网站服务端将恶意代码从 URL 中取出，拼接在 HTML 中返回给浏览器。 用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行。 恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。 反射型 XSS 跟存储型 XSS 的区别是：\n存储型 XSS 的恶意代码存在数据库里， 反射型 XSS 的恶意代码存在 URL 里。 反射型 XSS 漏洞常见于通过 URL 传递参数的功能，如网站搜索、跳转等。\n由于需要用户主动打开恶意的 URL 才能生效，攻击者往往会结合多种手段诱导用户点击。\nPOST 的内容也可以触发反射型 XSS，只不过其触发条件比较苛刻（需要构造表单提交页面，并引导用户点击），所以非常少见。\nDOM 型 # DOM 型 XSS 的攻击步骤：\n攻击者构造出特殊的 URL，其中包含恶意代码。 用户打开带有恶意代码的 URL。 用户浏览器接收到响应后解析执行，前端 JavaScript 取出 URL 中的恶意代码并执行。 恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。 DOM 型 XSS 跟前两种 XSS 的区别：\nDOM 型 XSS 攻击中，取出和执行恶意代码由浏览器端完成，属于前端 JavaScript 自身的安全漏洞， 其他两种 XSS 都属于服务端的安全漏洞。 防止 XSS # 输入过滤 # 输入侧过滤能够在某些情况下解决特定的 XSS 问题，但会引入很大的不确定性和乱码问题。 在防范 XSS 攻击时应避免此类方法。\n当然，对于明确的输入类型，例如数字、URL、电话号码、邮件地址等等内容，进行输入过滤还是必要的。\n纯前端渲染 # 纯前端渲染，把代码和数据分隔开\n纯前端渲染的过程：\n浏览器先加载一个静态 HTML，此 HTML 中不包含任何跟业务相关的数据。 然后浏览器执行 HTML 中的 JavaScript。 JavaScript 通过 Ajax 加载业务数据，调用 DOM API 更新到页面上。 在纯前端渲染中，我们会明确的告诉浏览器： 下面要设置的内容是文本（.innerText），还是属性（.setAttribute），还是样式（.style）等等。 浏览器不会被轻易的被欺骗，执行预期外的代码了。\n但纯前端渲染还需注意避免 DOM 型 XSS 漏洞（例如 onload 事件和 href 中的 javascript:xxx 等）。\n在很多内部、管理系统中，采用纯前端渲染是非常合适的。 但对于性能要求高，或有 SEO 需求的页面，我们仍然要面对拼接 HTML 的问题。\n对 HTML 做充分转义 # 对插入到页面中的数据进行转义， 通常是把 \u0026amp; \u0026lt; \u0026gt; \u0026quot; ' / 这几个字符转义掉， 确实能起到一定的 XSS 防护作用，但要完善 XSS 防护措施，我们要使用更完善更细致的转义策略。\nHTML 转义是非常复杂的，在不同的情况下要采用不同的转义规则。如果采用了错误的转义规则，很有可能会埋下 XSS 隐患。 应当尽量避免自己写转义库，而应当采用成熟的、业界通用的转义库。\n常用的模板引擎，如 doT.js、ejs、FreeMarker 等， Java 工程里，常用的转义库为 org.owasp.encoder。\n验证 href 的值 # 对于链接跳转，如 \u0026lt;a href=\u0026quot;xxx\u0026quot; 或 location.href=\u0026quot;xxx\u0026quot;，要检验其内容，禁止以 javascript: 开头的链接，和其他非法的 scheme。\n// 根据项目情况进行过滤，禁止掉 \u0026#34;javascript:\u0026#34; 链接、非法 scheme 等 allowSchemes = [\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;]; valid = isValid(getParameter(\u0026#34;redirect_to\u0026#34;), allowSchemes); if (valid) { \u0026lt;a href=\u0026#34;\u0026lt;%= escapeHTML(getParameter(\u0026#34;redirect_to\u0026#34;))%\u0026gt;\u0026#34;\u0026gt; 跳转... \u0026lt;/a\u0026gt; } else { \u0026lt;a href=\u0026#34;/404\u0026#34;\u0026gt; 跳转... \u0026lt;/a\u0026gt; } 不区分大小写，可以带空格 # JavaScript 不区分大小写： jAvascRipt:alert('XSS') 可以带空格 %20： %20javascript:alert('XSS') escapeEmbedJSON # 插入 JSON 的地方不能使用 escapeHTML()，因为转义 \u0026quot; 后，JSON 格式会被破坏。\n\u0026lt;script\u0026gt; var initData = \u0026lt;%= data.toJSON() %\u0026gt; \u0026lt;/script\u0026gt; 这样内联 JSON 也是不安全的\n当 JSON 中包含 U+2028 或 U+2029 这两个字符时，不能作为 JavaScript 的字面量使用，否则会抛出语法错误。 当 JSON 中包含字符串 \u0026lt;/script\u0026gt; 时，当前的 script 标签将会被闭合，后面的字符串内容浏览器会按照 HTML 进行解析；通过增加下一个 \u0026lt;script\u0026gt; 标签等方法就可以完成注入。 \u0026lt;script\u0026gt; // 实现一个 escapeEmbedJSON() 函数，对内联 JSON 进行转义 var initData = \u0026lt;%= escapeEmbedJSON(data.toJSON()) %\u0026gt; \u0026lt;/script\u0026gt; 预防 DOM 型 XSS 攻击 # 在使用 .innerHTML、.outerHTML、document.write() 时要特别小心，不要把不可信的数据作为 HTML 插到页面上， 而应尽量使用 .textContent、.setAttribute() 等。\n如果用 Vue/React 技术栈，并且不使用 v-html/dangerouslySetInnerHTML 功能， 就在前端 render 阶段避免 innerHTML、outerHTML 的 XSS 隐患。\nDOM 中的内联事件监听器，如 location、onclick、onerror、onload、onmouseover 等， \u0026lt;a\u0026gt; 标签的 href 属性， JavaScript 的 eval()、setTimeout()、setInterval() 等， 都能把字符串作为代码运行。\n\u0026lt;!-- 内联事件监听器中包含恶意代码 --\u0026gt; ![](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/3e724ce0.data:image/png,) \u0026lt;!-- 链接内包含恶意代码 --\u0026gt; \u0026lt;a href=\u0026#34;UNTRUSTED\u0026#34;\u0026gt;1\u0026lt;/a\u0026gt; \u0026lt;script\u0026gt; // setTimeout()/setInterval() 中调用恶意代码 setTimeout(\u0026#34;UNTRUSTED\u0026#34;); setInterval(\u0026#34;UNTRUSTED\u0026#34;); // location 调用恶意代码 location.href = \u0026#34;UNTRUSTED\u0026#34;; // eval() 中调用恶意代码 eval(\u0026#34;UNTRUSTED\u0026#34;); \u0026lt;/script\u0026gt; Content Security Policy # 严格的 CSP 在 XSS 的防范中可以起到以下的作用：\n禁止加载外域代码，防止复杂的攻击逻辑。 禁止外域提交，网站被攻击后，用户的数据不会泄露到外域。 禁止内联脚本执行（规则较严格，目前发现 GitHub 使用）。 禁止未授权的脚本执行（新特性，Google Map 移动版在使用）。 合理使用上报可以及时发现 XSS，利于尽快修复问题。 输入内容长度控制 # 对于不受信任的输入，都应该限定一个合理的长度。 虽然无法完全防止 XSS 发生，但可以增加 XSS 攻击的难度。\n其他安全措施 # HTTP-only Cookie: 禁止 JavaScript 读取某些敏感 Cookie，攻击者完成 XSS 注入后也无法窃取此 Cookie。 验证码：防止脚本冒充用户提交危险操作。 XSS 的检测 # jaVasCript:/*-/*`/*\\`/*\u0026#39;/*\u0026#34;/**/(/* */oNcliCk=alert() )//%0D%0A%0d%0a//\u0026lt;/stYle/\u0026lt;/titLe/\u0026lt;/teXtarEa/\u0026lt;/scRipt/--!\u0026gt;\\x3csVg/\u0026lt;sVg/oNloAd=alert()//\u0026gt;\\x3e 只要在网站的各输入框中提交这个字符串，或者把它拼接到 URL 参数上，就可以进行检测了。\n能够检测到存在于 HTML 属性、HTML 文字内容、HTML 注释、跳转链接、内联 JavaScript 字符串、内联 CSS 样式表等多种上下文中的 XSS 漏洞， 也能检测 eval()、setTimeout()、setInterval()、Function()、innerHTML、document.write() 等 DOM 型 XSS 漏洞， 并且能绕过一些 XSS 过滤器。\n自动扫描工具 # Arachni Mozilla HTTP Observatory w3af 参考 # 在学习 XSS 前应该学习什么？ 前端安全系列（一）：如何防止 XSS 攻击？ "},{"id":282,"href":"/note-cs/docs/domain/cc/cn/","title":"云原生","section":"3.1 云计算","content":" Cloud Native 云原生 # 什么是云原生 # 云原生定义 # 2018 年 CNCF 更新了云原生的定义。\n这是新定义中描述的代表技术，其中容器和微服务两项在不同时期的不同定义中都有出现，\n而服务网格这个在 2017 年才开始被社区接纳的新热点技术被非常醒目的列出来，和微服务并列，而不是我们通常认为的服务网格只是微服务在实施时的一种新的方式。\nCloud Native 翻译为云原生，是 Matt Stine 提出的一个概念，它是一个思想的集合，\n包括 DevOps、 持续交付（Continuous Delivery）、微服务（MicroServices）、敏捷基础设施（Agile Infrastructure）、康威定律（Conways Law）等，以及根据商业能力对公司进行重组。\nCloud Native 既包含\n技术（微服务，敏捷基础设施）， 也包含管理（DevOps，持续交付，康威定律，重组等）。 Cloud Native 也可以说是一系列 Cloud 技术、企业管理方法的集合。\n参考：\nCNCF Cloud Native Definition v1.0 云原生代表技术 # 云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。\n不可变基础设施 # 在传统的可变服务器基础架构中，服务器会不断更新和修改。\n使用此类基础架构的工程师和管理员可以通过 SSH 连接到他们的服务器，手动升级或降级软件包，逐个服务器地调整配置文件，以及将新代码直接部署到现有服务器上。\n换句话说，这些服务器是可变的；它们可以在创建后进行更改。\n不可变基础架构的好处包括基础架构中更高的一致性和可靠性，以及更简单，更可预测的部署过程。\n它可以缓解或完全防止可变基础架构中常见的问题，例如配置漂移和雪花服务器。\n宠物与牛群 # pets 是独一无二，无法模仿，失去一个可能是毁灭性的。\n牛群中的众多群体中没有一个人是独一无二或不可或缺的。\n雪花服务器与凤凰服务器 # snowflakes 服务器类似于宠物。它们是手工管理的服务器，经常更新和调整到位，从而形成独特的环境。\nPhoenix 服务器与牛类似。它们是始终从头开始构建的服务器，并且易于通过自动化过程重新创建（或 “从灰烬中升起”）。\n参考：\n什么是不可变的基础设施？ Tutum # tutum (now Docker)\n参考：\n如何更好地使用容器技术实现不可变基础设施 云原生应用 # 理想的云原生应用应该是这个样子：业务需求的实现占主体，只有少量的非业务需求相关的功能。\n参考：\n未来已来：云原生 Cloud Native 梳理后端架构演化史，回顾后端架构发展历程； 回顾云服务发展历程，探讨云原生概念； 梳理云原生实现方案 Service Mesh 的发展历程； 介绍 Service Mesh 的代表 Istio 的亮眼功能； 畅谈云原生（上）：云原生应用应该是什么样子？ 云原生与无服务器架构是云计算的未来吗？—— 云计算的演进 Service Mesh vs Serverless # Service Mesh 技术和 Serverless 技术是工作在不同纬度的两个技术：\nService Mesh 技术的关注点在于服务间通讯，其目标是剥离客户端 SDK，为应用减负，提供的能力主要包括安全性、路由、策略执行、流量管理等。 Serverless 技术的关注点在于服务运维，目标是客户无需关注服务运维，提供服务实例的自动伸缩，以及按照实际使用付费。 理论上 Service Mesh 技术和 Serverless 技术并没有冲突的地方，可以结合使用。事实上目前业界也开始出现这个趋势，而融合的方式有两种：\n在 Serverless 中引入 Service Mesh # 典型如 Knative 项目和 Knative 的 Google Cloud 托管版本 Google Cloud Run，通过引入对容器的支持和使用 Istio，Knative 将 Serverless 的支持扩展到 Function 之外，在极大的扩展 Serverless 适用范围的前提下，也将服务间通讯的能力引入到 Serverless。\n在 Service Mesh 中引入 Serverless # 典型如 Google Traffic Director 产品，在提供 Service Mesh 各种能力的同时，支持按照流量自动伸缩服务的实例数量，从而融入了部分 Serverless 的特性。\n对于 Serverless 和 Service Mesh 的结合，我们展望未来形态：\n未来应该会出现一种新型服务模式，Serverless 和 Service Mesh 合二为一。只要将服务部署上来，就自动可以得到 Service Mesh 的服务间通讯能力和 Serverless 的无服务器运维。\nService Mesh 发展趋势：云原生中流砥柱（下）\n"},{"id":283,"href":"/note-cs/docs/direction/se/design-pattern/creational/","title":"创建型","section":"2.1.1 设计模式","content":" 创建型模式 # "},{"id":284,"href":"/note-cs/docs/direction/se/design-pattern/principle/srp/","title":"单一职责原则","section":"设计原则","content":" 单一职责原则 # 就一个类而言，应该仅有一个引起它变化的原因。\n"},{"id":285,"href":"/note-cs/docs/direction/se/arch/principle/","title":"原则","section":"2.1.2 架构设计","content":" 架构设计原则 # BASE 是追求 CAP 的可用性 (A) ACID 是追求 CAP 的一致性 (C) "},{"id":286,"href":"/note-cs/docs/domain/cc/istio/basic/quick/install/","title":"安装","section":"1.1 快速上手","content":" Istio 安装 # 快速安装（适合新人） # Download and install Istio Deploy the sample application Open the application to outside traffic View the dashboard 使用 Istioctl 进行安装 # 下载 Istio release # [完成平台设置](platform-specific setup) # Check the Requirements for Pods and Services # Install Istio using the default profile # export INGRESS_HOST=$(kubectl get po -l istio=ingressgateway -n istio-system -o jsonpath=\u0026#39;{.items[0].status.hostIP}\u0026#39;) export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;http2\u0026#34;)].nodePort}\u0026#39;) export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;https\u0026#34;)].nodePort}\u0026#39;) export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT echo http://$GATEWAY_URL/productpage "},{"id":287,"href":"/note-cs/docs/direction/be/db/redis/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # 注意点 # 用 SET, 别用 SETNX, SETEX, PSETEX # Since the SET command options can replace SETNX, SETEX, PSETEX, it is possible that in future versions of Redis these three commands will be deprecated and finally removed.\n"},{"id":288,"href":"/note-cs/docs/direction/embedded/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":289,"href":"/note-cs/docs/direction/security/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":290,"href":"/note-cs/docs/direction/se/design-pattern/creational/abstract-factory/","title":"抽象工厂","section":"创建型","content":" 抽象工厂模式 # Abstract Factory Pattern\n提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类，具体的工厂负责实现具体的产品实例。\n解析\n对产品进一步分类：抽象产品族 -\u0026gt; 抽象产品 -\u0026gt; 具体产品 每一个具体工厂，通过不同的工厂方法，可以实例化某 一类 产品族的多个具体产品 缺点\n对于新的产品族符合开闭原则，对于新的产品不符合开闭原则，这一特性称为 开闭原则的倾斜性 。 抽象工厂接口中已经确定了可以被创建的产品集合，如果需要添加新产品，此时就必须去修改抽象工厂的接口，违反开闭原则。 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":291,"href":"/note-cs/docs/basic/os/type/","title":"操作系统类型","section":"1.2 操作系统","content":" 操作系统类型 # "},{"id":292,"href":"/note-cs/docs/direction/se/arch/scene/circuit-breaker/","title":"熔断","section":"场景","content":" 熔断 # 断路器\n进入熔断状态后，后续对该服务接口的调用不再经过网络，直接执行本地的默认方法，达到服务降级的效果。\n参考 # "},{"id":293,"href":"/note-cs/docs/basic/pl/ruby/advanced/frame/rainls/version/","title":"版本","section":"Ruby on Rails","content":" 版本 # 历史版本 # v6.0 # v5.0 # v5.2 # v4.0 # v3.0 # v2.0 # "},{"id":294,"href":"/note-cs/docs/basic/os/type/android/basic/spec/","title":"编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":295,"href":"/note-cs/docs/basic/os/type/ios/basic/spec/","title":"编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":296,"href":"/note-cs/docs/basic/os/type/unix/basic/spec/","title":"编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":297,"href":"/note-cs/docs/basic/os/type/windows/basic/spec/","title":"编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":298,"href":"/note-cs/docs/study/skill/stream-media/onvif/discovery/","title":"设备发现","section":"ONVIF","content":" 设备发现 # 我们传统的 Web Services 服务调用的模式都是这样的：客户端在设计时就预先知道目标服务的地址（IP 地址或者域名），客户端基于这个地址进行服务调用。\n那如果客户端预先不知道目标服务的地址该怎么办？\nWS-Discovery（全称为 Web Services Dynamic Discovery）标准就是用于解决该问题的，遵循该标准，客户端预先不知道目标服务地址的情况下，可以动态地探测到可用的目标服务，以便进行服务调用。这个过程就是「设备发现」的过程。\nWS-Discovery 模式 # WS-Discovery 定义了两种模式：Ad hoc 模式和 Managed 模式。\nAd hoc 模式 # Ad hoc 模式：客户端以多播 (multicast) 的形式往多播组 (multicast group) 发送一个 Probe（探测）消息搜寻目标服务，在该探测消息中，包含相应的搜寻条件。如果目标服务满足该条件，则直接将响应 ProbeMatch 消息（服务自身相关的信息，包括地址）回复给客户端。 Message Exchanges in an ad hoc mode. Message exchanges in an ad hoc mode in the presence of a Discovery Proxy. Managed 模式 # Managed 模式：即代理模式。Ad hoc 模式有个局限性，只能局限于一个较小的网络。Managed 模式就是为了解决这个问题的，在 Managed 模式下，一个维护所有可用目标服务的中心发现代理（Discovery Proxy）被建立起来，客户端只需要将探测消息发送到该发现代理就可以得到相应的目标服务信息。 Message exchanges in a managed mode. 官方技术规范：http://docs.oasis-open.org/ws-dd/discovery/1.1/os/wsdd-discovery-1.1-spec-os.html\n传输方式 # TCP/IP 有三种传输方式：单播 (Unicast)、多播 (Multicast) 和广播 (Broadcast)，在 IPv6 领域还有另一种方式：任播 (Anycast)。\n单播 Unicast # 单播 (Unicast)：一对一，双向通信，目的地址是对方主机地址。网络上绝大部分的数据都是以单播的形式传输的。如收发邮件、浏览网页等。\n多播 Multicast # 多播 (Multicast)：也叫组播，一对多，单向通信，目的地址是多播地址，主机可以通过 IGMP 协议请求加入或退出某个多播组 (multicast group)，数据只会转发给有需要（已加入组）的主机，不影响其他不需要（未加入组）的主机。如网上视频会议、网上视频点播、IPTV 等。\n多播地址（Multicast Address）有很多，各个行业都不一样，IPC 摄像头用的是 239.255.255.250（端口 3702）。\n多播地址的范围和分类可以见官方 IANA（互联网地址分配机构） 的说明：IPv4 Multicast Address Space Registry。\nWS-Discovery 协议用到了多播。\n广播 Broadcast # 广播 (Broadcast)：一对所有，单向通信，目的地址是广播地址，整个网络中所有主机均可以收到（不管你是否需要），如 ARP 地址解析、GARP 数据包等。广播会被限制在局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。\n参考：单播、多播（组播）和广播的区别\nIPC 搜索实现 # 实现 socket 编程（UDP），通过 sendto 往多播地址发送探测消息（Probe），再使用 recvfrom 接收 IPC 的应答消息（ProbeMatch）\n组播 IP 地址 # 组播也是一种 IP 包，也有源 IP 地址，目的 IP 地址，\n源 IP 地址为组播源的服务器 IP 地址， 目的地址为一个特殊的 IP 地址， 它位于 224.0.0.0 - 239.255.255.255 中， 由于 224.0.0.0/24 用于本地链路，即一跳的组播， 239.0.0.0/8 为私有组播地址， 所以实际的可用于在互联网上组播地址是 225.0.0.0/8 - 238.0.0.0/8 参考：\n组播 IP 地址到底是谁的 IP？ "},{"id":299,"href":"/note-cs/docs/basic/pl/shell/grammer/","title":"语法","section":"Shell","content":" 语法 # 符号 # ${} # $* 将所有的引用变量视为一个整体 $* # $@ 则仍旧保留每个引用变量的区段观念 # item=$1, list=\u0026#34;${@:2}\u0026#34; $@ "},{"id":300,"href":"/note-cs/docs/domain/cc/edge/","title":"边缘计算","section":"3.1 云计算","content":" 边缘计算 # 边缘计算的业务本质是云计算在数据中心之外边缘节点的延伸和演进， 以“边云协同”和“边缘智能”为核心能力发展方向；\n软件平台需要考虑导入云理念、云架构、云技术，提供端到端实时和协同式智能、可信赖、可动态重置等能力；\n硬件平台需要考虑异构计算能力，如鲲鹏、昇腾、ARM、X86、GPU、NPU、FPGA 等。\n边缘计算系统的落地形态 # 边缘计算产业联盟（ECC）将边缘计算系统的落地形态归纳为以下三种：\n云边缘 边缘云 边缘网关 云边缘 # 云边缘形态的边缘计算，是云服务在边缘侧的延伸，逻辑上仍是云服务， 主要的能力提供依赖于云服务或需要与云服务紧密协同。\n主要应用在公有云场景，如华为云提供的 IEF 解决方案、AWS 提供的 Greengrass 解决方案等均属于此类。\nIntelligent EdgeFabric 智能边缘平台\n边缘云 # 边缘云形态的边缘计算，是在边缘侧构建中小规模云服务能力， 边缘服务能力主要由边缘云提供；\n边缘云的管理调度能力由部署在中心云的系统完成。 如运营商 MEC、CDN 等均属于此类。\n边缘网关 # 边缘网关形态的边缘计算，以云化技术与能力重构原有嵌入式网关系统， 边缘网关在边缘侧提供协议/接口转换、边缘计算等能力， 部署在云侧的控制器提供边缘节点的资源调度、应用管理与业务编排等能力。\n边缘网关主要应用在工业联网和车联网等场景中。\n边缘计算的 CROSS 价值 # Connection # 联接的海量(Connection)\n网络是系统互联与数据采集传输的基石。 伴随联接设备数量的剧增，网络灵活扩展、低成本运维和可靠性保障面临巨大挑战。\nReal-time # 业务的实时性(Real-time)\n工业系统检测、控制、执行，新兴的 VR/AR 等应用的实时性高， 部分场景实时性要求在 10ms 以内甚至更低，如果数据分析和处理全部在云端实现，难以满足业务的实时性要求，严重影响终端客户的业务体验。\nOptimization # 数据的优化(Optimization)\n当前工业现场与物联网末端存在大量的多样化异构数据，需要通过数据优化实现数据的聚合、数据的统一呈现与开放，以灵活高效地服务于边缘应用的智能。\nSmart # 应用的智能性(Smart)\n业务流程优化、运维自动化与业务创新驱动应用走向智能，边缘侧智能能够带来显著的效率与成本优势。\nSecurity # 安全与隐私保护(Security)\n安全跨越云计算和边缘计算之间的纵深，需要实施端到端防护。 网络边缘侧由于更贴近万物互联的设备，访问控制与威胁防护的广度和难度因此大幅提升。 边缘侧安全主要包含设备安全、网络安全、数据安全与应用安全。 此外，关键数据的完整性、保密性，大量生产或人身隐私数据的保护也是安全领域需要重点关注的内容。\n边缘计算在网络中的位置 # 为实现边缘计算，需要在更底层的网络节点增加计算和转发能力，运营商组网结构将逐步演进，边缘计算能力持续提升。\n边缘计算节点部署方式 # MEC 网络的四大挑战 # 现场 MEC # 现场 MEC（部署在企业园区）是 5G MEC 带来的一个新应用场景\n5G MEC 位于企业园区机房里面，一般为运营商代建和代维。\n企业借助 5G MEC 系统进行生产控制、远程监控、物流管理和智慧安防等生产活动。\n很多生产业务对延迟有严格要求， 如远程塔吊控制信息流的端到端延迟要小于 18ms， 即生产设备（塔吊等）通过无线基站，IP RAN 网络，5G MEC 系统到企业应用系统（远程控制）的端到端通信要保证低延迟。 对运营商网络的要求是，企业园区内的 5G 基站和 5G MEC 系统之间的网络，以及 5G MEC 到企业网的连接都要保证低时延。\n现场 MEC 场景对运营商的接入网提出了新的挑战，需要接入网提供低延迟 SLA 保证和数据不出园区。\n5G 核心网下移 # UPF 随 MEC 下移，带动 UPF 相关业务端口下移（如 N4，N6，N9, 5GC OAM 等接口）到 5G 移动承载网。\n4G 核心网是集中部署在省或国家骨干网上， 4G 核心网网元间接口是由骨干网提供 VPN 来互通的，和 4G 移动承载网（IP RAN）没有关系。\n5G UPF 业务接口对外可靠通信是 5G MEC 对移动承载网（IP RAN）的新要求。 有些运营商采用 5GC 控制面集中到大区域的部署方案，这导致一些业务接口（如 N4 和 5GC OAM 接口）通信需要跨越移动承载网和骨干网两个网段。 由于 UPF 的大量分布式部署，以及 UPF 业务接口互通关系的复杂性， 增加了 5G 移动承载网的业务流量模型复杂度和多点通信的网络覆盖范围（基本上是全网范围）， 在 4G 时代的 L2+L3 网络设计是在汇聚层以上提供多点通信能力的。 同时，一些业务接口有传输延迟要求，如 N6，N9 这样的数据接口，这需要承载网提供 SLA 保证。\n5G 核心网下移使无线核心网承载从骨干网延伸到移动承载网， 对运营商 5G MEC 移动承载网络提出了支持复杂多点通信和 SLA 保证的新挑战。\n边云协同 # 5G MEC 包括下沉的 5G 核心网网元 UPF，和（云）计算应用。\n5G MEC 的 UPF 需要和中心云里 5G 核心网的控制面和管理应用系统通信\nMEC 的无缝 FMC 业务 # MEC 连接设备和应用系统的接入方式是多样的，可以是 5G 接入，也可以是固网接入（包括 xPON，专线，WiFi 等），通信目标是连接所有相关应用部件，共同提供一个完整的 MEC 应用，即提供无缝的 FMC（固移融合）业务应用。\nMEC 的接入网就可能包括移动承载网和固定承载网，需要连接两个城域网网络平面。\n同时，MEC 和中心云（5GC，运营商云，第三方云）及相关业务云（可能部署在固网 MAN 上）间的通信， 有些会通过移动承载网，有些会通过固定承载网。 MEC 网络不局限于移动承载网，MEC 网络连接可能会涉及移动承载和固网承载两个城域网平面，以及 IP 骨干网。\nMEC 对网络提出了 FMC 通信新挑战，特别对于拥有移动承载城域网和固定承载城域网双平面的运营商， 在网络架构和网络互通方面都提出了新挑战。 中国三大运营商都有两个城域网平面。\n运营商网络的边缘计算破局关键点 # ECNI 的边缘计算网络模型 # 边缘计算产业联盟 ECC 在 2019 年和网络 5.0 联合成立了边缘计算网络基础设施联合工作组（ECNI）， 是业界第一个聚焦边缘计算网络的产业组织。\n2019 年 11 月，ECNI 发布了“运营商边缘计算网络技术白皮书”，是业界首个有关运营商边缘计算网络的白皮书。 此白皮书提出了一个新的边缘计算网络抽象模型， 将边缘计算网络分为三个逻辑网段来描述\nECA（Edge Computing Access，边缘计算接入网络）\n从用户系统到 MEC 所经过的网络基础设施；\nECN（Edge Computing Network，边缘计算内部网络）\nMEC 内部网络基础设施\nECI（Edge Computing Interconnect，边缘计算互联网络）\n从 MEC 到云计算系统（如公有云、私有云、通信云、用户自建云等）、其它 MEC、各类数据中心所经过的网络基础设施；\nMEC 在物理网络中的位置不同，ECA 和 ECI 在物理网络中的映射也不一样；ECI 可能跨运营商多个网段。因此，ECA/ECN/ECI 网络模式能更好地描述复杂的 MEC 网络和多样性物理网络间的关系，本文后续都会采用该抽象模型来表述 MEC 网络问题。\nECA：最短路径 # 运营商应该为从基站到 MEC UPF 的 N3 业务流提供最短传输路径，特别是在现场 MEC 场景， N3 业务流应该通过在园区里的移动承载网路由器直接把业务流转发给 MEC UPF，而不应该让 N3 业务流在运营商的网络中绕行。\nECA 和 ECI：低延迟切片 # ECA 切片：完整的接入网切片系统包括无线基站、移动承载网（基站到 EC 间）和 UPF 系统，即企业业务流到 MEC 所经过的所有网元，涉及 5G 无线网、网络和 5G 核心网。ECA 切片是基站到 MEC 间的 IP 网络切片。\nECI 切片：MEC 系统和企业网、中心云和其它 MEC 系统间，由于业务需要保证 SLA 和安全可靠，需要切片网络来进行互连，有可能跨多网段。\nECI：灵活多点通信 # ECI 网络需要支持 5G MEC 和 5G 核心网（N4，OAM）、其它 MEC 系统（N6，N9）、互联网出口（N6）、锚点 UPF（N9）、运营商云、企业网、第三方云（OTT）等进行业务通信。\nECN：集成网络架构 # 运营商网和企业网：MEC 安全和互通 # 运营商角度，5G MEC 里面有非运营商的应用和网络连接，如 MEC 直接和企业网互通，不是电信安全域；同时 MEC 改变了原来移动承载网 IP RAN 的业务承载封闭性。企业角度，业务数据和业务应用经过外网和外部 IT 系统，即经过了企业非安全区，并且企业网增加了和运营商网络的互通点。\n网络支持云边协同 # 5G MEC 网络需要支持 5G UPF 的自动部署和在线扩缩容，比如 UPF VNF 增加 VM 数量来提高性能，MEC 网络能动态接受业务需求，自动下发网络配置，保证 UPF 的快速在线扩容，即网络支持云边协同。在 MEP 平台上部署的边缘计算应用，如果和中心云相关，也需要边云协同通信。另外，按业务要求快速打通云边间 VPN 通道是支持云边协同的基本通信需求。\n参考 # [pdf]5g mec ip 网络白皮书 - huawei carrier "},{"id":301,"href":"/note-cs/docs/direction/se/design-pattern/structural/adapter/","title":"适配器","section":"架构型","content":" 适配器模式 # Adapter\n适配器 Adapter 继承自 Adaptee，同时又实现了目标(Target)接口。\npublic interface Target { // 这是源类Adapteee没有的方法 public void Request(); } public class Adaptee { public void SpecificRequest() { } } // 适配器Adapter继承自Adaptee，同时又实现了目标(Target)接口。 public class Adapter extends Adaptee implements Target { // 目标接口要求调用Request()这个方法名，但源类Adaptee没有方法Request() // 因此适配器补充上这个方法名 // 但实际上Request()只是调用源类Adaptee的SpecificRequest()方法的内容 // 所以适配器只是将SpecificRequest()方法作了一层封装，封装成Target可以调用的Request()而已 @Override public void Request() { this.SpecificRequest(); } } public class AdapterPattern { public static void main(String[] args){ Target mAdapter = new Adapter()； mAdapter.Request(); } } 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":302,"href":"/note-cs/docs/study/skill/stream-media/communication/","title":"通信技术","section":"4.5 流媒体","content":" 通信技术 # 通信技术发展 # 1G # 现代移动通信的发展史可追溯到上个世纪 70 年代，贝尔实验室突破性的提出了蜂窝网络概念。\n所谓蜂窝网络，就是将网络划分为若干个相邻的小区，整体形状酷似蜂窝，以实现频率复用，提升系统容量。\n1G 时代作为移动通信开天辟地的时代，群雄逐鹿，山头林立，通信标准也是五花八门。\n尽管 1G 标准各式各样，但 1G 时代的王者非摩托罗拉莫属。\n摩托罗拉不仅发明了第一步模拟移动电话大哥大，而且还是 AMPS 系统的主要设备供应商。\n2G：GSM 与 CDMA 之争 # 1G 时代，以 AMPS 和 TACS 为代表的模拟移动通信系统取得了巨大成功， 但由于采用落后的模拟和频分复用（FDMA）技术，存在容量有限、系统太多、系统不兼容、通话质量差、易被窃听、设备昂贵、无法全球漫游等众多缺点。\n随着人们对移动通信的要求越来越高，业界提出向 2G 数字时代发展，以代替 1G 模拟通信。\n2G 时代主要采用数字时分多址（TDMA）和码分多址（CDMA）两种技术，分别对应 GSM 和 CDMA 系统，这是一场由美国和欧洲为代表的两大利益集团之间的竞争。\n如上所述，以 AMPS 和 TACS 为代表 1G 时代几乎被美国垄断，也意味着美国掌握了标准话语权和产业主动权。\n进入 2G 时代，欧洲不甘落后于美国，考虑到欧盟国家太小，单打独斗难以与美国抗衡，于是吸取了 1G 时代各自为政的失败教训，于是欧盟联合起来成立了 GSM，以快速形成规模向全球推广，在 2G 时代占据主导优势。\n2G 时代，欧洲 GSM 快速领先，促进了欧洲无线产业的崛起，也为欧洲带来了显著的经济利益。诺基亚和爱立信是首当其冲的受益者，在 2G 时代飞速发展成为全球领先的通信设备商和手机厂商。1993 年，爱立信占全球数字蜂窝设备市场的 60％，诺基亚一跃成为全球第二大手机供应商。2000 年，诺基亚的出口额占芬兰商品和服务总额的 24％。\n美国输了，输掉的不是技术，而是速度与规模，也输掉了一个时代。\n这也间接影响了摩托罗拉的竞争力，当数字移动电话渐渐取代模拟移动电话之时，摩托罗拉同样错估了模拟手机的寿命，也错过了 2G 数字时代。\n1997 年，摩托罗拉终于走下神坛，其全球移动电话市场份额从 1997 年的 50% 暴跌到 17%。持续了 20 年辉煌的摩托罗拉终于被来自欧洲的诺基亚击垮。\n时分多址（TDMA） # 欧洲 - 时分多址（TDMA） - GSM\n码分多址（CDMA） # 美国 - 码分多址（CDMA） - CDMA\nCDMA，即码分多址，它通过不同的扩频码来实现多用户在同一时间同一频率上共享。从技术上讲，CDMA 比 TDMA 更具优势。\n3G：鼎足三分 # 3G 时代主要有 WCDMA、CDMA2000、TD-SCDMA 三种标准。\n欧洲 + 日本 - 3GPP - WCDMA 美国 + 韩国 - 3GPP2 - CDMA2000 中国 - TD-SCDMA 欧洲与日本等原推行 GSM 标准的国家联合起来成立了 3GPP 组织 (3rd Generation Partnership Project)，负责制定全球第三代通信标准。\n随后，3GPP 小心翼翼地参考 CDMA 技术，以尽量绕过高通的专利，开发出了原理类似的 WCDMA。\n高通也赶紧不落人后地与韩国联合组成 3GPP2 (3rd Generation Partnership Project 2) 与 3GPP 抗衡，推出了 CDMA2000。\n既然你们都有一套自己的标准，当然，咱们中国也不能落于人后，也搞了一个 TD-SCDMA。\n也就是，3G 时代形成了欧、美、中三足鼎立的格局，谁也不服谁。\n但真正的赢家是谁？从某种角度讲，最后的赢家既不是欧洲，也不是美国，而是视野之外的日本。\n4G：LTE 一统江湖 # WiMax # 是基于 IEEE 802.16 标准集的一系列无线通信标准。WiMax 于 2001 年 6 月成立，旨在促进该标准的一致性和互操作性。\nWiMax 采用 OFDM+MIMO 技术，解决了多径干扰，提升了频谱效率，大幅地增加系统吞吐量及传送距离。今天的 4G LTE 也采用了这两大关键技术。\n自 3GPP 首版 4G LTE 标准于 2008 年 12 月完成且于 2009 年 12 月全球首商用成功后，全球多数移动运营商果断的选择了不投资 WiMax，而是静候 LTE 的到来。\nWiMax 失败了，尽管超前于 LTE，但超前一步的往往是烈士。\nLTE # LTE 的全称叫 Long Term Evolution，即长期演进，我不知道当时为何取这样的名字，但今天看来，仿佛是 3GPP 在向 WiMax 联盟隔空喊话：喂，兄弟，我们是长期演进的哦，你行不？\n于是乎，自 2008 年 12 月前后，已感到前途无望的 WiMax 阵营们纷纷退出，开始转向 LTE。\n经历了无数波折，在 4G 时代，LTE 标准终于一统江湖。\n5G # 5G 的优势：\n速率方面：从 4G 的 100Mbps 为单位，5G 可高达 10Gps，比 4G 快达 100 倍，轻松看 3D 影片或 4K 电影； 容量与能耗方面：为了物联网 (IoT)、智慧家庭等应用，5G 网络将能容纳更多设备连接、同时维持低功耗的续航能力； 低时延方面：工业 4.0 智慧工厂、车联网、远程医疗等应用，都必须超低时延。 回顾移动通信的发展史，从生态规模来看，美国在 1G 时代领先，但从 2G 到 3G，美国整整落后了两个时代，4G 赶超机会本来渺茫，但随着智能手机的横空出世，美国迎来了弯道超车的转折点。\n苹果推出了 IOS，Google 推出了安卓操作系统，如今全球大部分智能手机都运行于 iOS 和安卓系统。\niOS 和安卓系统打败了 2G 时代的诺基亚，也彻底打败了 3G 时代的日本 i-mode 模式。诺基亚手机没落了，日本通讯产业链全线败退，NEC、东芝、三洋退出手机领域，索尼、夏普、京瓷、松下市场份额大幅下滑，留给 NEC 和富士通等电信设备的市场也只是极少的份额。\n美国花了两个时代一路追赶，有过深刻的教训，也尝到了甜头，现在 5G 来了，当然不甘错过这次大好机遇，他们已多次表示要争夺全球 5G 领导地位。\n美国认为，5G 时代是建立在无线基础设施上的一次史无前例的创新时代，5G 将连接工厂、汽车、无人机等万物，并在万物互联的基础上加速机器学习和人工智能部署。谁能领导 5G，谁就站在了未来的信息时代的制高点。\n然鹅，朗讯、摩托罗拉、北电等美系设备商已全军覆灭，美国拿什么领导 5G？\n华为在 LTE 市场份额上早已全球第一，中国企业早已加大研发 5G。美国在逐渐掉队，而中国正在引领 5G。\n尽管美国也有高通、思科等通信巨头，但他们只提供芯片和路由器，并不提供无线设备。\n6G # 参考：\nIM 开发者的零基础通信技术入门 (五)：1G 到 5G，30 年移动通信技术演进史 "},{"id":303,"href":"/note-cs/docs/study/course/basic/pl/go/gobyexample/","title":"通过例子学 Golang","section":"go","content":" 通过例子学 Golang # mmcgrana/gobyexample 点击阅读：Go by Example\n中文翻译 # gobyexample-cn/gobyexample 点击阅读：通过例子学 Golang\n学习进度 # Hello World 值 变量 常量 For 循环 If/Else 分支 Switch 分支结构 数组 切片 Map Range 遍历 函数 多返回值 变参函数 闭包 递归 指针 结构体 方法 接口 错误处理 协程 通道 通道缓冲 通道同步 通道方向 通道选择器 超时处理 非阻塞通道操作 通道的关闭 通道遍历 Timer Ticker 工作池 WaitGroup 速率限制 原子计数器 互斥锁 状态协程 排序 使用函数自定义排序 Panic Defer 组合函数 字符串函数 字符串格式化 正则表达式 JSON XML 时间 时间戳 时间的格式化和解析 随机数 数字解析 URL 解析 SHA1 哈希 Base64 编码 读文件 写文件 行过滤器 文件路径 目录 临时文件和目录 单元测试 命令行参数 命令行标志 命令行子命令 环境变量 HTTP 客户端 HTTP 服务端 Context 生成进程 执行进程 信号 退出 "},{"id":304,"href":"/note-cs/docs/study/skill/type/mobi/","title":"mobi","section":"文档类型","content":" mobi # mobi vs azw3 # "},{"id":305,"href":"/note-cs/docs/domain/cc/others/paas/","title":"PaaS","section":"其他","content":" PaaS # "},{"id":306,"href":"/note-cs/docs/study/skill/type/azw3/","title":"azw3","section":"文档类型","content":" azw3 # azw3 vs azw # "},{"id":307,"href":"/note-cs/docs/domain/cc/others/saas/","title":"SaaS","section":"其他","content":" SaaS # "},{"id":308,"href":"/note-cs/docs/domain/cc/others/paas/gae/","title":"GAE","section":"PaaS","content":" Google App Engine # "},{"id":309,"href":"/note-cs/docs/study/book/basic/pl/go-advanced-programming/","title":"Go 语言高级编程","section":"5.1.5 编程语言","content":" Go 语言高级编程 # 作者 # 柴树杉 # 国内第一批的 Go 语言爱好者，Go 语言代码贡献者，CGO 资深用户。同时对 WebAssembly 技术有一定研究，著有《WebAssembly 标准入门》。Github 账号为 chai2010。\n曹春晖 # 在 Web 领域工作多年，开源爱好者。对大型网站系统的架构和相关工具的实现很感兴趣，并且有一些研究成果。目前在滴滴平台技术部工作。\n在线阅读 # chai2010/advanced-go-programming-book https://chai2010.cn/advanced-go-programming-book/\n参考 # "},{"id":310,"href":"/note-cs/docs/study/activity/istio-handbook/","title":"《Istio Handbook》写作","section":"4.4 学习活动","content":" 《Istio Handbook》写作 # 参考：\nservicemesher/istio-handbook "},{"id":311,"href":"/note-cs/docs/basic/pl/assembly/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":312,"href":"/note-cs/docs/basic/pl/erlang/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":313,"href":"/note-cs/docs/basic/pl/haskell/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":314,"href":"/note-cs/docs/basic/pl/lua/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":315,"href":"/note-cs/docs/basic/pl/r/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":316,"href":"/note-cs/docs/basic/pl/ruby/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":317,"href":"/note-cs/docs/basic/pl/swift/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":318,"href":"/note-cs/docs/basic/pl/zig/basic/grammar/keyword/","title":"1.1.2 关键字","section":"1.1 语法","content":" 关键字 # "},{"id":319,"href":"/note-cs/docs/basic/os/","title":"1.2 操作系统","section":"第一部分 基础","content":" 操作系统 # 教程 # 书籍 # Operating Systems - Three Easy Pieces - Remzi Arpaci-Dusseau 操作系统导论 remzi-arpacidusseau/ostep-projects How to write a simple operating system # This document shows you how to write and build your first operating system in x86 assembly language. It explains what you need, the fundamentals of the PC boot process and assembly language, and how to take it further. The resulting OS will be very small (fitting into a bootloader) and have very few features, but it\u0026rsquo;s a starting point for you to explore further.\nAfter you have read the guide, see the MikeOS project for a bigger x86 assembly language OS that you can explore to expand your skills.\nRoll your own toy UNIX-clone OS # "},{"id":320,"href":"/note-cs/docs/basic/pl/assembly/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":321,"href":"/note-cs/docs/basic/pl/erlang/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":322,"href":"/note-cs/docs/basic/pl/haskell/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":323,"href":"/note-cs/docs/basic/pl/lua/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":324,"href":"/note-cs/docs/basic/pl/r/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":325,"href":"/note-cs/docs/basic/pl/ruby/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":326,"href":"/note-cs/docs/basic/pl/swift/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":327,"href":"/note-cs/docs/basic/pl/zig/basic/std/","title":"1.2 标准库","section":"第一部分 基础入门","content":" 标准库 # "},{"id":328,"href":"/note-cs/docs/domain/cc/istio/basic/concept/","title":"1.2 概念","section":"第一部分 基础入门","content":" Istio 概念 # "},{"id":329,"href":"/note-cs/docs/basic/pl/shell/spec/","title":"1.3.2 编程规范","section":"Shell","content":" 编程规范 # "},{"id":330,"href":"/note-cs/docs/direction/se/arch/","title":"2.1.2 架构设计","section":"2.1 软件工程","content":" 架构设计 # "},{"id":331,"href":"/note-cs/docs/direction/be/","title":"2.2 后端","section":"第二部分 方向","content":" 后端开发 # 教程 # Back-End Developer Interview Questions # arialdomartini/Back-End-Developer-Interview-Questions 后端开发面试题 # monklof/Back-End-Developer-Interview-Questions 后端架构师技术图谱 # xingshaocheng/architect-awesome "},{"id":332,"href":"/note-cs/docs/domain/cc/istio/advanced/tool/","title":"2.2 工具","section":"第二部分 进阶实战","content":" 工具 # "},{"id":333,"href":"/note-cs/docs/basic/pl/assembly/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":334,"href":"/note-cs/docs/basic/pl/erlang/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":335,"href":"/note-cs/docs/basic/pl/haskell/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":336,"href":"/note-cs/docs/basic/pl/lua/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":337,"href":"/note-cs/docs/basic/pl/r/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":338,"href":"/note-cs/docs/basic/pl/ruby/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":339,"href":"/note-cs/docs/basic/pl/swift/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # raywenderlich/swift-algorithm-club # Algorithms and data structures in Swift, with explanations!\n"},{"id":340,"href":"/note-cs/docs/basic/pl/zig/advanced/algs/","title":"2.2 算法实现","section":"第二部分 进阶实战","content":" 算法实现 # "},{"id":341,"href":"/note-cs/docs/direction/be/db/redis/","title":"2.2.1.2 Redis","section":"2.2.1 数据库","content":" Redis # redis/redis "},{"id":342,"href":"/note-cs/docs/direction/fe/css/","title":"2.2.2 CSS","section":"2.3 前端","content":" CSS # "},{"id":343,"href":"/note-cs/docs/direction/be/mq/","title":"2.2.2 消息队列","section":"2.2 后端","content":" 消息队列 # ZeroMQ 和 RabbitMQ/Kafka 不同，它只是一个异步消息库，在套接字的基础上提供了类似于消息代理的机制。使用 ZeroMQ 的话，需要对自己的业务代码进行改造，不利于服务解耦。\nRabbitMQ 支持 AMQP（二进制），STOMP（文本），MQTT（二进制），HTTP（里面包装其他协议）等协议。Kafka 使用自己的协议。\nKafka 自身服务和消费者都需要依赖 Zookeeper。\nRabbitMQ 在有大量消息堆积的情况下性能会下降，Kafka 不会。毕竟 AMQP 设计的初衷不是用来持久化海量消息的，而 Kafka 一开始是用来处理海量日志的。\n在同步发送场景中，三个消息中间件的表现区分明显：\nKafka 的吞吐量高达 17.3w/s，不愧是高吞吐量消息中间件的行业老大。这主要取决于它的队列模式保证了写磁盘的过程是线性 IO。此时 broker 磁盘 IO 已达瓶颈。 RocketMQ 也表现不俗，吞吐量在 11.6w/s，磁盘 IO % util 已接近 100%。RocketMQ 的消息写入内存后即返回 ack，由单独的线程专门做刷盘的操作，所有的消息均是顺序写文件。 RabbitMQ 的吞吐量 5.95w/s，CPU 资源消耗较高。它支持 AMQP 协议，实现非常重量级，为了保证消息的可靠性在吞吐量上做了取舍。我们还做了 RabbitMQ 在消息持久化场景下的性能测试，吞吐量在 2.6w/s 左右。 在服务端处理同步发送的性能上，Kafka \u0026gt; RocketMQ \u0026gt; RabbitMQ。\n参考：\nKafka、RabbitMQ、RocketMQ 消息中间件的对比 —— 消息发送性能 常见消息队列实现 # apache/kafka # apache/rocketmq # 阿里 RocketMQ 是站在巨人的肩膀上（kafka）\nrabbitmq/rabbitmq-server # apache/activemq # ZeroMQ # zeromq/libzmq # ZeroMQ core engine in C++, implements ZMTP/3.1\nzeromq/jeromq # Pure Java ZeroMQ\nzeromq/netmq # A 100% native C# implementation of ZeroMQ for .NET\nzeromq/pyzmq # PyZMQ: Python bindings for zeromq\n参考 # RabbitMQ, ZeroMQ, Kafka 是一个层级的东西吗？ "},{"id":344,"href":"/note-cs/docs/direction/be/mq/rocketmq/","title":"2.2.2.2 RocketMQ","section":"2.2.2 消息队列","content":" RocketMQ # apache/rocketmq "},{"id":345,"href":"/note-cs/docs/direction/fe/frame/react/","title":"2.2.3.2 React","section":"2.2.3 框架","content":" React # "},{"id":346,"href":"/note-cs/docs/direction/be/distributed/paxos/","title":"2.2.4.2 Paxos","section":"2.2.4 分布式系统","content":" Paxos # Paxos 算法是分布式技术大师 Lamport 提出的，主要目的是通过这个算法，让参与分布式处理的每个参与者逐步达成一致意见。\nLamport 为了讲述这个算法，假想了一个叫做 Paxos 的希腊城邦进行选举的情景，这个算法也是因此而得名。 由于城邦的居民没有人愿意把全部时间和精力放在这种事情上，所以他们只能不定时的来参加提议，不定时来了解提议、投票进展，不定时的表达自己的投票意见。 Paxos 算法的目标就是让他们按照少数服从多数的方式，最终达成一致意见。\n算法过程 # 先明确哪个 “提议者” 是意见领袖有权提出提议，未来，“接受者” 们就主要处理这个 “提议者” 的提议了 选出的意见领袖提出提议，“接受者” 反馈意见。如果多数 “接受者” 接受了一个提议，那么提议就通过了 参考 # 如何浅显易懂地解说 Paxos 的算法？ "},{"id":347,"href":"/note-cs/docs/direction/be/microservices/rpc/grpc/","title":"2.2.5.1.2 gRPC","section":"2.2.5.1 RPC","content":" gRPC # grpc-go # grpc/grpc-go The Go language implementation of gRPC. HTTP/2 based RPC\ngrpc-web # grpc/grpc-web gRPC for Web Clients\n"},{"id":348,"href":"/note-cs/docs/direction/client/ios/","title":"2.4.2 iOS","section":"2.4 客户端","content":" iOS # "},{"id":349,"href":"/note-cs/docs/basic/pl/assembly/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":350,"href":"/note-cs/docs/basic/pl/erlang/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":351,"href":"/note-cs/docs/basic/pl/haskell/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":352,"href":"/note-cs/docs/basic/pl/lua/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":353,"href":"/note-cs/docs/basic/pl/r/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":354,"href":"/note-cs/docs/basic/pl/ruby/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":355,"href":"/note-cs/docs/basic/pl/swift/code/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":356,"href":"/note-cs/docs/basic/pl/zig/design/keyword/","title":"3.2 关键字","section":"第三部分 设计与实现","content":" 关键字 # "},{"id":357,"href":"/note-cs/docs/domain/bigdata/","title":"3.2 大数据","section":"第三部分 领域","content":" 大数据 # 教程 # 基础 # microsoft/Data-Science-For-Beginners 大数据全景图 # 点击查看原图：2020-Data-and-AI-Landscape-Matt-Turck-at-FirstMark-v1.pdf\n参考：\nResilience and Vibrancy: The 2020 Data \u0026amp; AI Landscape data-scientist-roadmap # MrMimic/data-scientist-roadmap I just found this data science skills roadmap, drew by Swami Chandrasekaran on his cool blog.\n"},{"id":358,"href":"/note-cs/docs/tool/linux/","title":"4.2 Linux","section":"第四部分 工具","content":" 开源镜像 # 清华大学开源软件镜像站 Ubuntu "},{"id":359,"href":"/note-cs/docs/study/book/","title":"4.2 读书","section":"第五部分 学习","content":" 读书 # 论文 # papers-we-love/papers-we-love # Papers from the computer science community to read and discuss.\n"},{"id":360,"href":"/note-cs/docs/basic/os/type/android/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":361,"href":"/note-cs/docs/basic/os/type/ios/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":362,"href":"/note-cs/docs/basic/os/type/macos/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":363,"href":"/note-cs/docs/basic/os/type/unix/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":364,"href":"/note-cs/docs/basic/os/type/windows/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":365,"href":"/note-cs/docs/basic/pl/assembly/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":366,"href":"/note-cs/docs/basic/pl/erlang/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":367,"href":"/note-cs/docs/basic/pl/haskell/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":368,"href":"/note-cs/docs/basic/pl/lua/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":369,"href":"/note-cs/docs/basic/pl/r/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":370,"href":"/note-cs/docs/basic/pl/ruby/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":371,"href":"/note-cs/docs/basic/pl/swift/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":372,"href":"/note-cs/docs/basic/pl/zig/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":373,"href":"/note-cs/docs/direction/be/db/mysql/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":374,"href":"/note-cs/docs/direction/be/db/postgresql/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":375,"href":"/note-cs/docs/direction/be/db/redis/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":376,"href":"/note-cs/docs/direction/be/platform/nodejs/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":377,"href":"/note-cs/docs/direction/client/android/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":378,"href":"/note-cs/docs/direction/client/ios/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":379,"href":"/note-cs/docs/direction/client/xiaochengxu/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":380,"href":"/note-cs/docs/direction/embedded/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":381,"href":"/note-cs/docs/direction/fe/frame/angular/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":382,"href":"/note-cs/docs/direction/fe/frame/react/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":383,"href":"/note-cs/docs/direction/fe/frame/vue/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":384,"href":"/note-cs/docs/direction/security/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":385,"href":"/note-cs/docs/domain/cc/istio/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" Istio 面试题 # 基础题 # 进阶题 # "},{"id":386,"href":"/note-cs/docs/tool/linux/centos/","title":"4.2.2 CentOS","section":"4.2 Linux","content":" CentOS # "},{"id":387,"href":"/note-cs/docs/study/skill/stream-media/communication/4g/","title":"4G","section":"通信技术","content":" 4G # "},{"id":388,"href":"/note-cs/docs/study/book/basic/os/","title":"5.1.2 操作系统","section":"5.1 计算机基础","content":" 操作系统 # "},{"id":389,"href":"/note-cs/docs/study/book/be/","title":"5.2 后端","section":"4.2 读书","content":" 后端 # "},{"id":390,"href":"/note-cs/docs/study/skill/stream-media/communication/5g/","title":"5G","section":"通信技术","content":" 5G # 5G 速度 # 世界上最快的 4G 网速（挪威，63.13Mbps）\n最快的宽带网速（新加坡，189Mbps）\n2019 年 1 月 24 日，华为发布业界标杆 5G 多模终端芯片巴龙 5000\n在 5G 峰值下载速率是 4G LTE 可体验速率的 10 倍\n5G 应用场景 # 国际电信联盟无线电通信局（ITU-R）定义了 5G 的三大典型应用场景为：\n增强型移动宽带（eMBB） 超可靠低时延通信（uRLLC） 海量大规模连接物联网（mMTC） 增强型移动宽带（eMBB） # eMBB 主要面向虚拟现实（VR）/ 增强现实（AR）、在线 4K 视频等高带宽需求业务\n超可靠低时延通信（uRLLC） # mMTC 主要面向智慧城市、智能交通等高连接密度需求的业务\n海量大规模连接物联网（mMTC） # uRLLC 主要面向车联网、无人驾驶、无人机等时延敏感的业务。\n5G 架构 # 5G 核心网采用控制面（SMF：Session Management Function）和用户面 UPF 分离的 CUPS（Control and User Plane Separation ）架构\n5G 控制面集中部署，一个控制面（SMF）可以同时管理很多个 UPF 而不影响 5G 核心网的性能； 5G 用户面分散部署，UPF 可以按需灵活分布部署，部署到网络边缘支持边缘计算。\nUE 的不同业务，可以引导到本地 UPF（比如企业应用），或直接引导到锚点 UPF（普通的上网业务）， 中间可以动态插入 UL CL 进行按需动态分流。\n因此，在企业园区里面的基站，是可以同时支持本地企业应用和个人普通上网应用。\nUL CL (Uplink Classifier 上行链路分类器) SMF # Session Management Function\nUPF # 5G 用户面 UPF（User Plane Function）的下沉和灵活部署实现了数据流量本地卸载。\nCUPS # MEP # 5G MEC 给运营商进入垂直行业带来了新的业务场景和商业模式。 运营商一般是用代建代维方式， 将 5G MEC 部署到企业园区，提供边缘云计算服务， 包括 IaaS，PaaS（即 MEP 平台），以及 SaaS（结合运营商的云计算服务）等更多的增值服务，\n收益从管道转向软件和服务。\n这样，运营商能深入垂直行业的 ICT 系统及应用领域，更好地为企业数字化、网络化和智能化提供全套的 ICT 服务和云计算应用，提供的业务比传统的企业专线业务，更深入全面和有客户粘性。 这就是为什么运营商都在积极拓展 5G MEC 企业业务的原因，得 5G MEC 服务者得企业客户。\nETSI # 欧洲电信标准研究所（ETSI）在 2014 年成立 MEC 工业专业组，关注运营商边缘计算的标准和工业使能， 并且在 2016 年，将 MEC 的定义从移动边缘计算（Mobile Edge Computing）改为外延更广的多接入边缘计算（Multi-Access Edge Computing）； 在运营商领域，MEC 一般被用来指代边缘计算系统。 在 5G 时代，MEC 是运营商助力垂直行业数字化和智能化的新应用模式。\n5G 技术 # 5G 承载网 # 在无线侧有大量新技术实现对不同应用场景的支撑，但传输网络侧，硬件技术提升有限的情况下，需要对网络架构进行革新。\n5G 承载整体要求 # 5G 承载组网架构 # 多样化网络需求 # 边缘计算技术就是解决不同应用带来的多样化网络需求的核心技术之一\n在靠近接入网的机房增加计算能力，将能够\n大幅降低业务时延 减少对传输网的带宽压力降低传输成本 进一步提高内容分发效率提升用户体验 传统网络结构中，信息的处理主要位于核心网的数据中心机房内，所有信息必须从网络边缘传输到核心网进行处理之后再返回网络边缘。\n5G 时代，传输网架构中引入边缘计算技术，在靠近接入侧的边缘机房部署网关、服务器等设备，增加计算能力，将低时延业务、局域性数据、低价值量数据等数据在边缘机房进行处理和传输，不需要通过传输网返回核心网，进而降低时延、减少回传压力、提升用户体验。\n5G 应用 # 底层网络进步带来应用和商业模式的升级\n4G vs 5G # 4G 核心网是集中部署模式，一般是一个省（或大区）部署一个 4G 核心网， 所以 4G 承载网的流量模型是南北向为主， 运营商倾向于采用比较简单的接入网设计， 如很多运营商采用 L2（VPN）+L3（VPN）组网模式，即接入网采用相对简单的 L2 VPN 网络。\n在 4G 时代，这些无线核心网流量是在 IP 骨干网上而不是在移动承载网上来承载的。\n5G 核心网是 CUPS 架构， 控制面集中部署，一般是一个省或一个大区部署一个， 而 UPF 是分布式部署的，一般一个城市会部署一个锚点 UPF（Anchor UPF）和很多 MEC UPF。\n5G MEC 经常连接到接入网（如现场 MEC），增加了对 5G 移动承载网接入网的功能要求\n5G MEC 网络需要一个功能更强大、支持企业业务的网络架构和方案，不能是 4G 现有移动承载网架构的简单带宽升级。\n"},{"id":391,"href":"/note-cs/docs/study/course/basic/os/","title":"6.1.2 操作系统","section":"6.1 计算机基础","content":" 操作系统 # "},{"id":392,"href":"/note-cs/docs/study/course/be/","title":"6.2 后端","section":"4.3 课程","content":" 后端 # "},{"id":393,"href":"/note-cs/docs/direction/se/arch/principle/acid/","title":"ACID","section":"原则","content":" ACID # In computer science, ACID (atomicity, consistency, isolation, durability) is a set of properties of database transactions intended to guarantee validity even in the event of errors, power failures, etc. In the context of databases, a sequence of database operations that satisfies the ACID properties (and these can be perceived as a single logical operation on the data) is called a transaction.\nACID 是追求 CAP (Consistency, Availability, Partition tolerance) 的一致性 (C)\nACID，是指数据库管理系统（DBMS）在写入或更新资料的过程中，为保证事务（transaction）是正确可靠的，所必须具备的四个特性：\n原子性（Atomicity 又称不可分割性） 一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即事务不可分割。 一致性（Consistency） 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。 隔离性（Isolation，又称独立性） 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、已提交读（read committed）、可重复读（repeatable read）和可串行化（Serializable）。 可串行化（Serializable）: 不会发生幻读 持久性（Durability） 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。这就意味着 DB 必须在数据写入磁盘成功后才能返回提交成功。常见策略就是事务提交前先确保 WAL(write ahead log)预写日志成功，再定期把磁盘的 btree 中的脏页数据写入磁盘 btree pag "},{"id":394,"href":"/note-cs/docs/domain/ai/agent/","title":"Agent","section":"3.3 人工智能","content":" Agent # 这是一个关于 [[ml]] 的测试。\n任务调度：\nagronholm/apscheduler celery/celery apache/airflow PrefectHQ/prefect "},{"id":395,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/ambassador/","title":"Ambassador","section":"Ingress Controller","content":" Ambassador # datawire/ambassador Open source Kubernetes-native API gateway for microservices built on the Envoy Proxy\n"},{"id":396,"href":"/note-cs/docs/domain/cc/istio/basic/concept/api-resources/","title":"API Resources","section":"1.2 概念","content":" Istio API Resources # kubectl api-resources\n1.6.5 25 个 Istio CRD： - adapter - [attributemanifest](https://istio.io/latest/docs/reference/config/policy-and-telemetry/istio.policy.v1beta1/#AttributeManifest) - describes a set of Attributes produced by some component of an Istio deployment. - handler - HTTPAPISpecBinding - HTTPAPISpec - instance - QuotaSpecBinding - QuotaSpec - rule - template - [IstioOperator](https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/#IstioOperatorSpec) - defines the desired installed state of Istio components - [DestinationRule](https://istio.io/latest/docs/reference/config/networking/destination-rule/) - defines policies that apply to traffic intended for a service after routing has occurred. - [EnvoyFilter](https://istio.io/latest/docs/reference/config/networking/envoy-filter/) - provides a mechanism to customize the Envoy configuration generated by Istio Pilot. - [Gateway](https://istio.io/latest/docs/reference/config/networking/gateway/) - describes a load balancer operating at the edge of the mesh receiving incoming or outgoing HTTP/TCP connections. - ServiceEntry - Sidecar - [VirtualService](https://istio.io/latest/docs/reference/config/networking/virtual-service/) - Configuration affecting traffic routing. - [WorkloadEntry](https://istio.io/latest/docs/reference/config/networking/workload-entry/) - enables operators to describe the properties of a single non-Kubernetes workload such as a VM or a bare metal server as it is onboarded into the mesh. - ClusterRbacConfig - RbacConfig - ServiceRoleBinding - ServiceRole - AuthorizationPolicy - PeerAuthentication - RequestAuthentication --- 相比于 1.4.6 - 多了 - IstioOperator - WorkloadEntry - 少了 - MeshPolicy - Policy | NAME | SHORTNAMES | APIGROUP | NAMESPACED | KIND | 定义代码 | 备注 | | ------------------------------- | ---------- | ---------------------------- | ---------- | ------------------------------ | -------- | ---- | | bindings | | | true | Binding | | | | componentstatuses | cs | | false | ComponentStatus | | | | configmaps | cm | | true | ConfigMap | | | | endpoints | ep | | true | Endpoints | | | | events | ev | | true | Event | | | | limitranges | limits | | true | LimitRange | | | | namespaces | ns | | false | Namespace | | | | nodes | no | | false | Node | | | | persistentvolumeclaims | pvc | | true | PersistentVolumeClaim | | | | persistentvolumes | pv | | false | PersistentVolume | | | | pods | po | | true | Pod | | | | podtemplates | | | true | PodTemplate | | | | replicationcontrollers | rc | | true | ReplicationController | | | | resourcequotas | quota | | true | ResourceQuota | | | | secrets | | | true | Secret | | | | serviceaccounts | sa | | true | ServiceAccount | | | | services | svc | | true | Service | | | | mutatingwebhookconfigurations | | admissionregistration.k8s.io | false | MutatingWebhookConfiguration | | | | validatingwebhookconfigurations | | admissionregistration.k8s.io | false | ValidatingWebhookConfiguration | | | | customresourcedefinitions | crd,crds | apiextensions.k8s.io | false | CustomResourceDefinition | | | | apiservices | | apiregistration.k8s.io | false | APIService | | | | controllerrevisions | | apps | true | ControllerRevision | | | | daemonsets | ds | apps | true | DaemonSet | | | | deployments | deploy | apps | true | Deployment | | | | replicasets | rs | apps | true | ReplicaSet | | | | statefulsets | sts | apps | true | StatefulSet | | | | tokenreviews | | authentication.k8s.io | false | TokenReview | | | | localsubjectaccessreviews | | authorization.k8s.io | true | LocalSubjectAccessReview | | | | selfsubjectaccessreviews | | authorization.k8s.io | false | SelfSubjectAccessReview | | | | selfsubjectrulesreviews | | authorization.k8s.io | false | SelfSubjectRulesReview | | | | subjectaccessreviews | | authorization.k8s.io | false | SubjectAccessReview | | | | horizontalpodautoscalers | hpa | autoscaling | true | HorizontalPodAutoscaler | | | | cronjobs | cj | batch | true | CronJob | | | | jobs | | batch | true | Job | | | | certificatesigningrequests | csr | certificates.k8s.io | false | CertificateSigningRequest | | | | adapters | | config.istio.io | true | adapter | | | | attributemanifests | | config.istio.io | true | attributemanifest | | | | handlers | | config.istio.io | true | handler | | | | httpapispecbindings | | config.istio.io | true | HTTPAPISpecBinding | | | | httpapispecs | | config.istio.io | true | HTTPAPISpec | | | | instances | | config.istio.io | true | instance | | | | quotaspecbindings | | config.istio.io | true | QuotaSpecBinding | | | | quotaspecs | | config.istio.io | true | QuotaSpec | | | | rules | | config.istio.io | true | rule | | | | templates | | config.istio.io | true | template | | | | leases | | coordination.k8s.io | true | Lease | | | | endpointslices | | discovery.k8s.io | true | EndpointSlice | | | | events | ev | events.k8s.io | true | Event | | | | ingresses | ing | extensions | true | Ingress | | | | istiooperators | iop | install.istio.io | true | IstioOperator | | | | destinationrules | dr | networking.istio.io | true | DestinationRule | | | | envoyfilters | | networking.istio.io | true | EnvoyFilter | | | | gateways | gw | networking.istio.io | true | Gateway | | | | serviceentries | se | networking.istio.io | true | ServiceEntry | | | | sidecars | | networking.istio.io | true | Sidecar | | | | virtualservices | vs | networking.istio.io | true | VirtualService | | | | workloadentries | we | networking.istio.io | true | WorkloadEntry | | | | ingressclasses | | networking.k8s.io | false | IngressClass | | | | ingresses | ing | networking.k8s.io | true | Ingress | | | | networkpolicies | netpol | networking.k8s.io | true | NetworkPolicy | | | | runtimeclasses | | node.k8s.io | false | RuntimeClass | | | | poddisruptionbudgets | pdb | policy | true | PodDisruptionBudget | | | | podsecuritypolicies | psp | policy | false | PodSecurityPolicy | | | | clusterrolebindings | | rbac.authorization.k8s.io | false | ClusterRoleBinding | | | | clusterroles | | rbac.authorization.k8s.io | false | ClusterRole | | | | rolebindings | | rbac.authorization.k8s.io | true | RoleBinding | | | | roles | | rbac.authorization.k8s.io | true | Role | | | | clusterrbacconfigs | | rbac.istio.io | false | ClusterRbacConfig | | | | rbacconfigs | | rbac.istio.io | true | RbacConfig | | | | servicerolebindings | | rbac.istio.io | true | ServiceRoleBinding | | | | serviceroles | | rbac.istio.io | true | ServiceRole | | | | priorityclasses | pc | scheduling.k8s.io | false | PriorityClass | | | | authorizationpolicies | | security.istio.io | true | AuthorizationPolicy | | | | peerauthentications | pa | security.istio.io | true | PeerAuthentication | | | | requestauthentications | ra | security.istio.io | true | RequestAuthentication | | | | csidrivers | | storage.k8s.io | false | CSIDriver | | | | csinodes | | storage.k8s.io | false | CSINode | | | | storageclasses | sc | storage.k8s.io | false | StorageClass | | | | volumeattachments | | storage.k8s.io | false | VolumeAttachment | | | 1.4.6 25 个 Istio CRD： - MeshPolicy - Policy - adapter - attributemanifest - handler - HTTPAPISpecBinding - HTTPAPISpec - instance - QuotaSpecBinding - QuotaSpec - rule - template - DestinationRule - EnvoyFilter - Gateway - ServiceEntry - Sidecar - VirtualService - ClusterRbacConfig - RbacConfig - ServiceRoleBinding - ServiceRole - AuthorizationPolicy - PeerAuthentication - RequestAuthentication | NAME | SHORTNAMES | APIGROUP | NAMESPACED | KIND | 定义代码 | 备注 | | ------------------------------- | ---------- | ---------------------------- | ---------- | ------------------------------ | -------- | ---- | | bindings | | | true | Binding | | | | componentstatuses | cs | | false | ComponentStatus | | | | configmaps | cm | | true | ConfigMap | | | | endpoints | ep | | true | Endpoints | | | | events | ev | | true | Event | | | | limitranges | limits | | true | LimitRange | | | | namespaces | ns | | false | Namespace | | | | nodes | no | | false | Node | | | | persistentvolumeclaims | pvc | | true | PersistentVolumeClaim | | | | persistentvolumes | pv | | false | PersistentVolume | | | | pods | po | | true | Pod | | | | podtemplates | | | true | PodTemplate | | | | replicationcontrollers | rc | | true | ReplicationController | | | | resourcequotas | quota | | true | ResourceQuota | | | | secrets | | | true | Secret | | | | serviceaccounts | sa | | true | ServiceAccount | | | | services | svc | | true | Service | | | | mutatingwebhookconfigurations | | admissionregistration.k8s.io | false | MutatingWebhookConfiguration | | | | validatingwebhookconfigurations | | admissionregistration.k8s.io | false | ValidatingWebhookConfiguration | | | | customresourcedefinitions | crd, crds | apiextensions.k8s.io | false | CustomResourceDefinition | | | | apiservices | | apiregistration.k8s.io | false | APIService | | | | controllerrevisions | | apps | true | ControllerRevision | | | | daemonsets | ds | apps | true | DaemonSet | | | | deployments | deploy | apps | true | Deployment | | | | replicasets | rs | apps | true | ReplicaSet | | | | statefulsets | sts | apps | true | StatefulSet | | | | meshpolicies | | authentication.istio.io | false | MeshPolicy | | | | policies | | authentication.istio.io | true | Policy | | | | tokenreviews | | authentication.k8s.io | false | TokenReview | | | | localsubjectaccessreviews | | authorization.k8s.io | true | LocalSubjectAccessReview | | | | selfsubjectaccessreviews | | authorization.k8s.io | false | SelfSubjectAccessReview | | | | selfsubjectrulesreviews | | authorization.k8s.io | false | SelfSubjectRulesReview | | | | subjectaccessreviews | | authorization.k8s.io | false | SubjectAccessReview | | | | horizontalpodautoscalers | hpa | autoscaling | true | HorizontalPodAutoscaler | | | | cronjobs | cj | batch | true | CronJob | | | | jobs | | batch | true | Job | | | | certificatesigningrequests | csr | certificates.k8s.io | false | CertificateSigningRequest | | | | stacks | | compose.docker.com | true | Stack | | | | adapters | | config.istio.io | true | adapter | | | | attributemanifests | | config.istio.io | true | attributemanifest | | | | handlers | | config.istio.io | true | handler | | | | httpapispecbindings | | config.istio.io | true | HTTPAPISpecBinding | | | | httpapispecs | | config.istio.io | true | HTTPAPISpec | | | | instances | | config.istio.io | true | instance | | | | quotaspecbindings | | config.istio.io | true | QuotaSpecBinding | | | | quotaspecs | | config.istio.io | true | QuotaSpec | | | | rules | | config.istio.io | true | rule | | | | templates | | config.istio.io | true | template | | | | leases | | coordination.k8s.io | true | Lease | | | | events | ev | events.k8s.io | true | Event | | | | daemonsets | ds | extensions | true | DaemonSet | | | | deployments | deploy | extensions | true | Deployment | | | | ingresses | ing | extensions | true | Ingress | | | | networkpolicies | netpol | extensions | true | NetworkPolicy | | | | podsecuritypolicies | psp | extensions | false | PodSecurityPolicy | | | | replicasets | rs | extensions | true | ReplicaSet | | | | destinationrules | dr | networking.istio.io | true | DestinationRule | | | | envoyfilters | | networking.istio.io | true | EnvoyFilter | | | | gateways | gw | networking.istio.io | true | Gateway | | | | serviceentries | se | networking.istio.io | true | ServiceEntry | | | | sidecars | | networking.istio.io | true | Sidecar | | | | virtualservices | vs | networking.istio.io | true | VirtualService | | | | ingresses | ing | networking.k8s.io | true | Ingress | | | | networkpolicies | netpol | networking.k8s.io | true | NetworkPolicy | | | | runtimeclasses | | node.k8s.io | false | RuntimeClass | | | | poddisruptionbudgets | pdb | policy | true | PodDisruptionBudget | | | | podsecuritypolicies | psp | policy | false | PodSecurityPolicy | | | | clusterrolebindings | | rbac.authorization.k8s.io | false | ClusterRoleBinding | | | | clusterroles | | rbac.authorization.k8s.io | false | ClusterRole | | | | rolebindings | | rbac.authorization.k8s.io | true | RoleBinding | | | | roles | | rbac.authorization.k8s.io | true | Role | | | | clusterrbacconfigs | | rbac.istio.io | false | ClusterRbacConfig | | | | rbacconfigs | | rbac.istio.io | true | RbacConfig | | | | servicerolebindings | | rbac.istio.io | true | ServiceRoleBinding | | | | serviceroles | | rbac.istio.io | true | ServiceRole | | | | priorityclasses | pc | scheduling.k8s.io | false | PriorityClass | | | | authorizationpolicies | | security.istio.io | true | AuthorizationPolicy | | | | peerauthentications | | security.istio.io | true | PeerAuthentication | | | | requestauthentications | | security.istio.io | true | RequestAuthentication | | | | csidrivers | | storage.k8s.io | false | CSIDriver | | | | csinodes | | storage.k8s.io | false | CSINode | | | | storageclasses | sc | storage.k8s.io | false | StorageClass | | | | volumeattachments | | storage.k8s.io | false | VolumeAttachment | | | VirtualService # metadata name spec hosts http match (Request Routing, 配置请求路由) headers end-user exact port uri prefix fault (Fault Injection, 故障注入) delay (延迟故障) percentage fixedDelay abort (abort 故障) percentage httpStatus route destination host subset port number weight (Traffic Shifting, 流量转移) timeout (Request Timeouts, 设置请求超时) retries attempts perTryTimeout tcp route destination weight (TCP Traffic Shifting, TCP 流量转移) DestinationRule # spec: host trafficPolicy connectionPool tcp maxConnections http http1MaxPendingRequests (HTTP 请求的最大排队数量) maxRequestsPerConnection (一个连接内最大请求数，如果为 1，表示禁用 keep alive) outlierDetection consecutiveErrors interval baseEjectionTime maxEjectionPercent loadBalancer simple subsets name labels version trafficPolicy (Circuit breakers, 熔断器) loadBalancer simple connectionPool tcp maxConnections Gateway # spec selector app servers port name number protocol hosts tls ServiceEntry # spec hosts ports location resolution ServiceAccount # metadata name spec handler # metadata name namespace spec compiledAdapter params quotas name maxAmount validDuration overrides dimensions destination maxAmount validDuration instance # "},{"id":397,"href":"/note-cs/docs/study/skill/stream-media/lorawan/chirpstack/application/","title":"Application","section":"ChirpStack","content":" ChirpStack Application Server # ChirpStack Application Server is an open-source LoRaWAN application-server. https://www.chirpstack.io\n数据库 # Schema Name Type Owner public application table chirpstack_as public application_id_seq sequence chirpstack_as public code_migration table chirpstack_as public device table chirpstack_as public device_activation table chirpstack_as public device_activation_id_seq sequence chirpstack_as public device_keys table chirpstack_as public device_multicast_group table chirpstack_as public device_profile table chirpstack_as public fuota_deployment table chirpstack_as public fuota_deployment_device table chirpstack_as public gateway table chirpstack_as public gateway_ping table chirpstack_as public gateway_ping_id_seq sequence chirpstack_as public gateway_ping_rx table chirpstack_as public gateway_ping_rx_id_seq sequence chirpstack_as public gateway_profile table chirpstack_as public gorp_migrations table chirpstack_as public integration table chirpstack_as public integration_id_seq sequence chirpstack_as public multicast_group table chirpstack_as public network_server table chirpstack_as public network_server_id_seq sequence chirpstack_as public organization table chirpstack_as public organization_id_seq sequence chirpstack_as public organization_user table chirpstack_as public organization_user_id_seq sequence chirpstack_as public remote_fragmentation_session table chirpstack_as public remote_multicast_class_c_session table chirpstack_as public remote_multicast_setup table chirpstack_as public service_profile table chirpstack_as public user table chirpstack_as public user_id_seq sequence chirpstack_as (33 rows)\n"},{"id":398,"href":"/note-cs/docs/direction/se/arch/principle/base/","title":"BASE","section":"原则","content":" BASE # Basically Available, Soft state, Eventual consistency\nBASE 理论是 CAP 理论中的 AP 的延伸，是对互联网大规模分布式系统的实践总结，强调可用性。\n基本可用 # 流量削峰 在不同的时间，出售不同区域的票，将访问请求错开，削弱请求峰值 延迟响应 在春运期间，自己提交的购票请求，往往会在队列中排队等待处理，可能几分钟或十几分钟后，系统才开始处理，然后响应处理结果 体验降级 比如用小图片来替代原始图片，通过降低图片的清晰度和大小，提升系统的处理能力。 过载保护 把接收到的请求放在指定的队列中排队处理，如果请求等待时间超时了（假设是 100ms），这个时候直接拒绝超时请求；再比如队列满了之后，就清除队列中一定数量的排队请求，保护系统不过载，实现系统的基本可用。 最终的一致 # 读时修复：在读取数据时，检测数据的不一致，进行修复。 比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。 写时修复：在写入数据，检测数据的不一致时，进行修复。 比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败就将数据缓存下来，然后定时重传，修复数据的不一致性。 写时修复不需要做数据一致性对比，性能消耗比较低，对系统运行影响也不大，推荐在实现最终一致性时优先实现这种方式。 异步修复：这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。 "},{"id":399,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/xds/cds/","title":"CDS","section":"xDS","content":" CDS # "},{"id":400,"href":"/note-cs/docs/tool/macos/claude-code/","title":"Claude Code","section":"4.1 MacOS","content":" Claude Code # anthropics/claude-code npm install -g @anthropic-ai/claude-code "},{"id":401,"href":"/note-cs/docs/tool/linux/ubuntu/codex/","title":"Codex CLI","section":"4.2.1 Ubuntu","content":" Codex CLI # openai/codex ubuntu server 使用 codex cli # ssh config 配置代理 # vim ~/.ssh/config\nHost hhht-211 HostName 1.180.13.251 User root IdentityFile ~/.ssh/id_rsa Port 211 # 代理 RemoteForward 127.0.0.1:1080 127.0.0.1:1080 本地电脑的 127.0.0.1:1080 有 http 代理，可以科学上网（访问 openai codex）\n部署配置 # ssh 登录远程服务器\n# apt update # apt install npm -y npm i -g @openai/codex cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.bashrc alias codex=\u0026#39;http_proxy=http://127.0.0.1:1080 https_proxy=http://127.0.0.1:1080 codex\u0026#39; EOF . ~/.bashrc vscode ssh remote 使用 codex 插件 # cd \u0026#34;$(dirname \u0026#34;$(which codex)\u0026#34;)\u0026#34; # 首次已备份过就不会再动；若没备份过会备份 [ -f codex.real ] || mv codex codex.real cat \u0026gt; codex \u0026lt;\u0026lt;\u0026#39;SH\u0026#39; #!/usr/bin/env bash # —— HTTP 代理在 127.0.0.1:1080 —— # 同时设置大/小写 + ALL_PROXY，最大兼容性（HTTPS 也会通过 HTTP CONNECT） export HTTP_PROXY=\u0026#34;http://127.0.0.1:1080\u0026#34; export HTTPS_PROXY=\u0026#34;http://127.0.0.1:1080\u0026#34; export ALL_PROXY=\u0026#34;http://127.0.0.1:1080\u0026#34; export http_proxy=\u0026#34;${HTTP_PROXY}\u0026#34; export https_proxy=\u0026#34;${HTTPS_PROXY}\u0026#34; export all_proxy=\u0026#34;${ALL_PROXY}\u0026#34; # 不走代理的直连目标 export NO_PROXY=\u0026#34;localhost,127.0.0.1,::1\u0026#34; export no_proxy=\u0026#34;${NO_PROXY}\u0026#34; exec \u0026#34;$(dirname \u0026#34;$0\u0026#34;)/codex.real\u0026#34; \u0026#34;$@\u0026#34; SH chmod +x codex "},{"id":402,"href":"/note-cs/docs/tool/macos/codex/","title":"Codex CLI","section":"4.1 MacOS","content":" Codex CLI # openai/codex npm i -g @openai/codex codex 使用 glm # cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; ~/.codex/config.toml # 默认配置（使用OpenAI模型） model = \u0026#34;gpt-5-codex\u0026#34; # 全局GLM模型提供商定义（新增这部分） [model_providers.glm] name = \u0026#34;zhipu\u0026#34; base_url = \u0026#34;https://open.bigmodel.cn/api/coding/paas/v4\u0026#34; env_key = \u0026#34;GLM_API_KEY\u0026#34; # 定义GLM配置档（您已有的配置） [profiles.glm] model = \u0026#34;glm-4.6\u0026#34; model_provider = \u0026#34;glm\u0026#34; EOF # https://bigmodel.cn/usercenter/proj-mgmt/apikeys cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc export GLM_API_KEY=\u0026#34;你的 glm key\u0026#34; alias codex-glm=\u0026#34;codex --profile glm\u0026#34; EOF zsh "},{"id":403,"href":"/note-cs/docs/basic/os/cpu/","title":"CPU","section":"1.2 操作系统","content":" CPU # L1 Cache # Intel Core i7 的组织结构：\n"},{"id":404,"href":"/note-cs/docs/direction/security/basic/csrf/","title":"CSRF","section":"第一部分 基础入门","content":" CSRF # 参考 # 前端安全系列（二）：如何防止 CSRF 攻击？ "},{"id":405,"href":"/note-cs/docs/direction/be/search/elasticsearch/","title":"Elasticsearch","section":"搜索引擎","content":" Elasticsearch # Open Source, Distributed, RESTful Search Engine https://www.elastic.co/products/elasticsearch\n"},{"id":406,"href":"/note-cs/docs/direction/be/frame/python/flask/","title":"flask","section":"Python 框架","content":" flask # 教程 # realpython/discover-flask # Full Stack Web Development with Flask.\nPart Title Git Tag 1 Setting Up a Static Site (blog post) part1 2 Creating a login page (blog post) part2 3 User Authentication part3 4 Template Inheritance part4 5 Databases part5 6 List Comprehensions N/A 7 Unit Tests part7 8 Deploying to Heroku part8 9 SQLAlchemy part9 10 Configuration part10 11 Secret Key part11 12 Heroku Configuration Settings part12 13 Heroku Postgres Setup part13 14 Local PostgreSQL Setup part14 15 Managing Database Migrations part15 16 Database Downgrades with Flask-Migrate/Alembic part16 17 Virtualenvwrapper part17 18 Password Hashing part18 19 Blueprints part19 20 Blueprints Redux part20 21 User Authentication (part 2) part21 22 Unit Testing with Flask-Testing part22 23 Session Management with Flask-Login part23 24 Testing User Login and Logout part24 25 User Registration (functionality and unit tests) part25 26 Finalize Messaging System part26 27 Test Coverage with coverage.py part27 28 Flask Testing! part28 29 Flask Testing (increase test coverage) part29 30 Continuous Integration part30 "},{"id":407,"href":"/note-cs/docs/basic/pl/ruby/basic/others/gem/","title":"gem","section":"1.4 其他","content":" RubyGems # 安装 # ruby setup.rb\n参考：https://rubygems.org/pages/download\nRubyGems installed the following executables: /opt/homebrew/Cellar/ruby/3.2.2/bin/gem /opt/homebrew/Cellar/ruby/3.2.2/bin/bundle /opt/homebrew/Cellar/ruby/3.2.2/bin/bundler Ruby Interactive (ri) documentation was installed. ri is kind of like man pages for Ruby libraries. You may access it like this: ri Classname ri Classname.class_method ri Classname#instance_method "},{"id":408,"href":"/note-cs/docs/tool/macos/gemini-cli/","title":"Gemini CLI","section":"4.1 MacOS","content":" Gemini CLI # google-gemini/gemini-cli gemini cli 使用 glm # git clone https://github.com/heartyguy/gemini-cli cd gemini-cli git checkout feature/openrouter-support "},{"id":409,"href":"/note-cs/docs/study/skill/stream-media/stream-media/h264/","title":"H264","section":"流媒体技术","content":" H264 # H.264，又称为 MPEG-4 第 10 部分，高级视频编码（英语： MPEG-4 Part 10, Advanced Video Coding ，缩写为 MPEG-4 AVC）是一种面向块，基于运动补偿的视频编码标准（英语：Advanced Video Coding） 。\nAVC 和 XviD 都属于 MPEG-4 编码，但由于 AVC 属于 MPEG-4 Part 10，在技术特性上比属于 MPEG-4 Part2 的 XviD 要先进。\n它和 ITU-T H.264 标准是一致的，故又称为 H.264。\n裸流 # H.264 原始码流（又称为 “裸流”）是由一个一个的 NALU 组成的。\nH264 码流可以分为两层\nVCL 层 NAL 层（Network abstraction layer, 叫网络抽象层），保存了 H264 相关的参数信息和图像信息 NAL 层由多个单元 NALU 组成 NALU # NALU (NAL Units) 组成\nNALU 头（00 00 00 01 或者 00 00 01） sps (序列参数集) pps (图像参数集合) slice sei IDR 帧 I 帧（在图像运动变化较少时，I 帧后面是 7 个 P 帧，如果图像运动变化大时，一个序列就短了，I 帧后面可能是 3 个或者 4 个 P 帧） P 帧 B 帧等数据。 一个完整的 NALU 单元结构图\n参考：\nH.264 码流结构 (H.264 Data Structure) 其他 # ITU-T # 国际电信联盟电信标准化部门（英语： ITU Telecommunication Standardization Sector，缩写 ITU-T ）是国际电信联盟管理下的专门制定远程通信相关国际标准的组织。该机构创建于 1993 年，前身是国际电报电话咨询委员会（法语： Comité Consultatif International Téléphonique et Télégraphique，英语：International Telegraph and Telephone Consultative Committee，缩写：CCITT ），总部设在瑞士日内瓦。\n由 ITU-T 指定的国际标准通常被称为 “建议书”（Recommendations），ITU-T 的各种建议书的分类由一个首字母来代表，称为系列，每个系列的建议书除了分类字母以外还有一个编号，例如 “V.90”。\n"},{"id":410,"href":"/note-cs/docs/domain/cc/others/paas/heroku/","title":"Heroku","section":"PaaS","content":" Heroku # "},{"id":411,"href":"/note-cs/docs/study/skill/stream-media/stream-media/hls/","title":"HLS","section":"流媒体技术","content":" HLS # HTTP Live Streaming\n"},{"id":412,"href":"/note-cs/docs/study/skill/stream-media/stream-media/http-flv/","title":"HTTP FLV","section":"流媒体技术","content":" HTTP FLV # Bilibili/flv.js # HTML5 FLV Player\n"},{"id":413,"href":"/note-cs/docs/direction/be/frame/java/","title":"Java 框架","section":"2.2.3 后端框架","content":" Java 框架 # "},{"id":414,"href":"/note-cs/docs/direction/be/auth/jwt/","title":"JWT","section":"认证与授权","content":" JWT # JSON Web Tokens\n背景 # JWT 原理 # JWT 结构 # JWT 由 Header, Payload, Signature 三部分组成\nconst token = base64urlEncoding(header) + '.' + base64urlEncoding(payload) + '.' + base64urlEncoding(signature)\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dnZWRJbkFzIjoiYWRtaW4iLCJpYXQiOjE0MjI3Nzk2Mzh9.gzSraSYS8EXBxLN_oWnFSRgCzcmJmMjLiuyu5CSpyHI\nHeader\n{ \u0026#34;alg\u0026#34; : \u0026#34;HS256\u0026#34;, \u0026#34;typ\u0026#34; : \u0026#34;JWT\u0026#34; } Payload\n{ \u0026#34;loggedInAs\u0026#34; : \u0026#34;admin\u0026#34;, \u0026#34;iat\u0026#34; : 1422779638 } Signature\nHMAC-SHA256( base64urlEncoding(header) + \u0026#39;.\u0026#39; + base64urlEncoding(payload), secret ) Authorization: Bearer eyJhbGci...\u0026lt;snip\u0026gt;...yu5CSpyHI\nJWT 优缺点 # 优点 # JWT 把数据存储在客户端，服务端不需要存储 缺点 # JWT 的 Token 无法主动失效 JWT 适用场景 # 参考 # 阮一峰：JSON Web Token 入门教程 "},{"id":415,"href":"/note-cs/docs/direction/be/frame/php/laravel/","title":"Laravel","section":"PHP 框架","content":" Laravel # "},{"id":416,"href":"/note-cs/docs/direction/be/db/redis/source/type/list/","title":"List 实现","section":"类型实现","content":" Redis List 类型实现 # 参考 # 5 种基本数据结构 "},{"id":417,"href":"/note-cs/docs/direction/be/search/lucene/","title":"Lucene","section":"搜索引擎","content":" Lucene # https://lucene.apache.org/\napache/lucene-solr # Apache Lucene is a high-performance, full featured text search engine library written in Java.\nApache Solr is an enterprise search platform written using Apache Lucene. Major features include full-text search, index replication and sharding, and result faceting and highlighting.\n教程 # zzboy/lucene # lucene 技术细节\n"},{"id":418,"href":"/note-cs/docs/basic/os/type/macos/basic/version/","title":"macOS 版本","section":"第一部分 基础入门","content":" macOS 版本 # 参考：macOS wikipedia\nmacOS 13: Ventura # 2022 年\nmacOS 12: Monterey # 2021 年 10 月 25 日\nmacOS 11: Big Sur # 2020 年 11 月 12 日\nmacOS 10.15: Catalina # 2019 年 10 月 7 日\nmacOS 10.14: Mojave # 2018 年 9 月 25 日\nmacOS 10.13: High Sierra # 2017 年 9 月 25 日\nmacOS 10.12: Sierra # 2016 年 9 月 20 日\nOS X 10.11: El Capitan # 2015 年 9 月 30 日\nOS X 10.10: Yosemite # 2014 年 10 月 16 日\nOS X 10.9: Mavericks # 2013 年 10 月 22 日\nOS X 10.8: Mountain Lion # 2012 年 7 月 25 日\nMac OS X 10.7: Lion # 2011 年 7 月 20 日\nMac OS X 10.6: Snow Leopard # 2009 年 8 月 28 日\nMac OS X 10.5: Leopard # 2007 年 10 月 26 日\nMac OS X 10.4: Tiger # 2005 年 4 月 29 日\nMac OS X 10.3: Panther # 2003 年 10 月 24 日\nMac OS X 10.2: Jaguar # 2002 年 8 月 24 日\nMac OS X 10.1: Puma # 2001 年 9 月 25 日\nMac OS X 10.0: Cheetah # 2001 年 3 月 24 日\nMac OS X Server 1.0: Hera # 1999 年 3 月 16 日\n"},{"id":419,"href":"/note-cs/docs/domain/ai/mcp/","title":"MCP","section":"3.3 人工智能","content":" MCP # MCP 遵循客户端-服务器架构，其中：\n主机(Host) 是 LLM 应用程序（如 Claude Desktop 、智能体 或 IDE），它们发起连接 客户端(client) 与服务器保持一对一的连接，位于主机应用程序内部 服务器(server) 为客户端提供上下文、工具和提示 MCP Client 在调用 MCP Server 之前必须先初始化，后续才可以调用 MCP Server 提供的工具、提示词和资源，接收 MCP Server 的通知：\n初始化之后，Client-Server 之间的通讯支持以下模式：\nRequest-Response（请求-响应）：客户端或服务器发送请求，另一方响应 Notifications （通知）：任一方发送单向消息 "},{"id":420,"href":"/note-cs/docs/study/skill/stream-media/stream-media/mpeg/","title":"MPEG","section":"流媒体技术","content":" MPEG # MPEG-1：第一个官方的视讯音频压缩标准，随后在 Video CD 中被采用，其中的音频压缩的第三级（MPEG-1 Layer 3）简称 MP3，成为比较流行的音频压缩格式。 MPEG-2：广播质量的视讯、音频和传输协议。被用于无线 数字电视 - ATSC、DVB 以及 ISDB、数字卫星电视（例如 DirecTV）、数字 有线电视信号，以及 DVD 视频光盘技术中。 MPEG-3：原本目标是为 高清晰度电视（ HDTV）设计，随后发现 MPEG-2 已足够 HDTV 应用，故 MPEG-3 的研发便中止。 MPEG-4：2003 年发布的视讯压缩标准，主要是扩展 MPEG-1、MPEG-2 等标准以支持视频／音频对象（video/audio \u0026ldquo;objects\u0026rdquo;）的编码、3D 内容、低比特率编码（low bitrate encoding）和 数字版权管理（Digital Rights Management），其中第 10 部分由 ISO/IEC 和 ITU-T 联合发布，称为 H.264/MPEG-4 Part 10。 MPEG-7：MPEG-7 并不是一个视讯压缩标准，它是一个多媒体内容的描述标准。 MPEG-21：MPEG-21 是一个正在制定中的标准，它的目标是为未来多媒体的应用提供一个完整的平台。 "},{"id":421,"href":"/note-cs/docs/domain/cc/virtual/parallels/","title":"Parallels","section":"虚拟化","content":" Parallels # "},{"id":422,"href":"/note-cs/docs/basic/pl/php/","title":"PHP","section":"1.5 编程语言","content":" PHP # 详见：PHP 学习笔记\n"},{"id":423,"href":"/note-cs/docs/direction/be/frame/php/","title":"PHP 框架","section":"2.2.3 后端框架","content":" PHP 框架 # "},{"id":424,"href":"/note-cs/docs/direction/be/devops/prometheus/","title":"Prometheus","section":"2.2.6 DevOps","content":" Prometheus # prometheus/prometheus quick-start # $ docker run --name prometheus -d -p 8015:9090 quay.io/prometheus/prometheus $ cat /etc/prometheus/prometheus.yml # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. rule_files: # - \u0026#34;first_rules.yml\u0026#34; # - \u0026#34;second_rules.yml\u0026#34; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#34;prometheus\u0026#34; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#34;localhost:9090\u0026#34;] Prometheus 证书 # $ tree /etc/kubernetes/pki /etc/kubernetes/pki ├── apiserver.crt ├── apiserver-etcd-client.crt ├── apiserver-etcd-client.key ├── apiserver.key ├── apiserver-kubelet-client.crt ├── apiserver-kubelet-client.key ├── ca.crt ├── ca.key ├── etcd │ ├── ca.crt │ ├── ca.key │ ├── healthcheck-client.crt │ ├── healthcheck-client.key │ ├── peer.crt │ ├── peer.key │ ├── server.crt │ └── server.key ├── front-proxy-ca.crt ├── front-proxy-ca.key ├── front-proxy-client.crt ├── front-proxy-client.key ├── sa.key └── sa.pub 1 directory, 22 files service account # token 和 ca.crt 挂载到 /var/run/secrets/kubernetes.io/serviceaccount/\n- name: kube-api-access-\u0026lt;random-suffix\u0026gt; projected: defaultMode: 420 # 0644 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespace 这里的 ca.crt 就是 /etc/kubernetes/pki/ca.crt\nbash-5.0# cd /var/run/secrets/kubernetes.io/serviceaccount/ bash-5.0# ls -l total 0 lrwxrwxrwx 1 root root 13 Oct 8 10:41 ca.crt -\u0026gt; ..data/ca.crt lrwxrwxrwx 1 root root 16 Oct 8 10:41 namespace -\u0026gt; ..data/namespace lrwxrwxrwx 1 root root 12 Oct 8 10:41 token -\u0026gt; ..data/token bash-5.0# 参考：\n一文带你彻底厘清 Kubernetes 中的证书工作机制 Bound Service Account Token Volume 教程 # yunlzheng/prometheus-book # Prometheus 操作指南 https://yunlzheng.gitbook.io/prometheus-book/\n"},{"id":425,"href":"/note-cs/docs/study/skill/stream-media/stream-media/ps/","title":"PS","section":"流媒体技术","content":" PS # Program stream\nPS 流的包结构是可变长度的， 一旦某一 PS 包的同步信息丢失，接收机无法确定下一包的同步位置，就会造成失步，导致严重的信息丢失。\n在信道环境较好，传输误码较低时，一般采用 PS 码流。\nTS # MPEG transport stream (MPEG-TS, MTS)\n传输流，是由固定长度为 188 字节的包组成， 含有一个或多个 program, 一个 program 可以包含多个视频、音频、和文字信息的 ES 流； 每个 ES 流会有不同的 PID 标示。\n而又为了可以分析这些 ES 流，TS 有一些固定的 PID 用来间隔发送 program 和 ES 流信息的表格:\nPAT PMT 表 TS 流的包结构是固定长度的， 当传输误码破坏了某一 TS 包的同步信息时，接收机可在固定的位置检测它后面包中的同步信息，从而恢复同步，避免了信息丢失。\n在信道环境较为恶劣，传输误码较高时，一般采用 TS 码流。\nTS 流解码过程 # 获取 TS 中的 PAT 获取 TS 中的 PMT 根据 PMT 可以知道当前网络中传输的视频（音频）类型（H264），相应的 PID，PCR 的 PID 等信息。 设置 demux 模块的视频 Filter 为相应视频的 PID 和 stream type 等。 从视频 Demux Filter 后得到的 TS 数据包中的 payload 数据就是 one piece of PES， 在 TS header 中有一些关于此 payload 属于哪个 PES 的 第多少个数据包。 因此软件中应该将此 payload 中的数据 copy 到 PES 的 buffer 中，用于拼接一个 PES 包。 拼接好的 PES 包的包头会有 PTS，DTS 信息，去掉 PES 的 header 就是 ES。 直接将被拔掉 PES 包头的 ES 包送给 decoder 就可以进行解码。 解码出来的数据就是一帧一帧的视频数据，这些数据至少应当与 PES 中的 PTS 关联一下，以便进行视音频同步。 ES # Elementary Stream\n基本码流，包含视频、音频或数据的连续码流。\nES -\u0026gt; PES -\u0026gt; PS/TS\nPES # Packet Elementary Stream\n打包的基本码流\n将基本的码流 ES 流根据需要分成长度不等的数据包，并加上包头就形成了打包的基本码流 PES 流。\n"},{"id":426,"href":"/note-cs/docs/direction/be/frame/python/","title":"Python 框架","section":"2.2.3 后端框架","content":" Python 框架 # "},{"id":427,"href":"/note-cs/docs/direction/be/frame/java/spring/","title":"Spring","section":"Java 框架","content":" Spring # "},{"id":428,"href":"/note-cs/docs/direction/be/frame/java/spring/spring-boot/","title":"Spring Boot","section":"Spring","content":" Spring Boot # 教程 # ityouknow/spring-boot-examples # Spring Boot 教程、技术栈示例代码，快速简单上手教程。\n"},{"id":429,"href":"/note-cs/docs/direction/be/frame/java/spring/spring-cloud/","title":"Spring Cloud","section":"Spring","content":" Spring Cloud # 教程 # ityouknow/spring-cloud-examples # Spring Cloud 学习案例，服务发现、服务治理、链路追踪、服务监控等\n"},{"id":430,"href":"/note-cs/docs/direction/be/frame/java/spring/spring-mvc/","title":"Spring MVC","section":"Spring","content":" Spring MVC # "},{"id":431,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/traefik/","title":"Traefik","section":"Ingress Controller","content":" Traefik # traefik/traefik The Cloud Native Application Proxy https://traefik.io/\n"},{"id":432,"href":"/note-cs/docs/direction/se/uml/","title":"UML","section":"2.1 软件工程","content":" UML # 泛化关系 (generalization) # is-a 最终代码中，泛化关系表现为继承非抽象类 带空心三角形箭头的直线\n实现关系 (realize) # 最终代码中，实现关系表现为继承抽象类 带空心三角形箭头的虚线\n聚合关系 (aggregation) # 表示整体由部分构成的语义 例如一个部门由多个员工组成 整体和部分不是强依赖的，即使整体不存在了，部分仍然存在 例如， 部门撤销了，人员不会消失，他们依然存在 带空心菱形箭头的直线\n组合关系 (composition) # 表示整体由部分构成的语义 比如公司由多个部门组成 是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了 例如， 公司不存在了，部门也将不存在了 带实心菱形箭头直线\n关联关系 (association) # 它一般用来定义对象之间静态的、天然的结构；通常与运行状态无关 所以，关联关系是一种 \u0026ldquo;强关联\u0026rdquo; 的关系 比如，乘车人和车票之间就是一种关联关系；学生和学校就是一种关联关系 在最终代码中，关联对象通常是以成员变量的形式实现的 带箭头的直线\n依赖关系 (dependency) # 描述一个对象在运行期间会用到另一个对象的关系 是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化，依赖关系也可能发生变化 在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系 依赖关系除了临时知道对方外，还是 \u0026ldquo;使用\u0026rdquo; 对方的方法和属性； 带箭头的虚线\n"},{"id":433,"href":"/note-cs/docs/domain/cc/virtual/virtualbox/","title":"VirtualBox","section":"虚拟化","content":" VirtualBox # "},{"id":434,"href":"/note-cs/docs/basic/os/memory/","title":"内存","section":"1.2 操作系统","content":" 内存 # "},{"id":435,"href":"/note-cs/docs/direction/be/devops/prometheus/alerting-rule/","title":"告警规则","section":"Prometheus","content":" 告警规则 # groups: - name: example rules: - alert: HighRequestLatency expr: job:request_latency_seconds:mean5m{job=\u0026#34;myjob\u0026#34;} \u0026gt; 0.5 for: 10m labels: severity: page annotations: summary: High request latency groups: - name: example rules: - record: job:http_inprogress_requests:sum expr: sum(http_inprogress_requests) by (job) "},{"id":436,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/command/","title":"命令","section":"行为型","content":" 命令模式 # Command Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":437,"href":"/note-cs/docs/direction/be/db/postgresql/basic/practice/error/","title":"常见错误","section":"实践","content":" PostgreSQL 常见错误 # 权限 # permission denied for relation # 解决 1:\n以 superUser 进入数据库 psql -U postgres -d postgres 切换到 mydb 数据库 \\c mydb 赋予所有表的所有权限给 xiaoming GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO xiaoming; 赋予 wechart 用户，tuser 表的所有权限 GRANT ALL PRIVILEGES ON tuser TO wechart; 解决 2：\nERROR: permission denied for relation hycom 权限被拒绝\n检查数据库连接 检查数据库拥有者和配置的是否一样 访问不同的数据库分区 @TableName (\u0026ldquo;分区名。表名\u0026rdquo;) @TableField (exist = false) 取消数据库映射 "},{"id":438,"href":"/note-cs/docs/direction/se/design-pattern/other/concurrency/","title":"并行模式","section":"其他模式","content":" 并行模式 # "},{"id":439,"href":"/note-cs/docs/direction/se/design-pattern/principle/ocp/","title":"开闭原则","section":"设计原则","content":" 开闭原则 # 程序中的对象应该对扩展是开放的，对修改是封闭的。\n当一个类实现了一个功能的时候，如果想要改变这个功能不是去修改代码，而是通过扩展的方式去实现。 实现该类提供的接口方法，然后注入到该类中，通过这种方法去实现功能的改变。\n"},{"id":440,"href":"/note-cs/docs/domain/ai/ml/","title":"机器学习","section":"3.3 人工智能","content":" 机器学习 # 详见：Machine Learning 学习笔记\n"},{"id":441,"href":"/note-cs/docs/direction/se/design-pattern/creational/builder/","title":"构造器","section":"创建型","content":" 构造器模式 # Builder\n抽象 Builder 规定要有哪些方法（用来创建产品） 具体 Builder 的方法可以实现不一样的内容，这些方法按顺序完成后，可以创建出来特定的产品 Director 规定创建产品的步骤；接收具体的 Builder 对象作为参数，按步骤调用 Builder 对象的各个方法，最后获取到创建的产品 解析\n创建产品的步骤是一致的，所有步骤完成后，就创建出产品 不同 Builder 的同一步可以做不同的事情，最后创建出不同的产品 缺点\n建造者模式所创建的产品一般具有较多的共同点，其组成部分相似；如果产品之间的差异性很大，则不适合使用建造者模式 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":442,"href":"/note-cs/docs/direction/se/design-pattern/structural/","title":"架构型","section":"2.1.1 设计模式","content":" 架构型模式 # "},{"id":443,"href":"/note-cs/docs/direction/se/design-pattern/structural/bridge/","title":"桥接","section":"架构型","content":" 桥接模式 # Bridge\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":444,"href":"/note-cs/docs/direction/be/db/postgresql/basic/version/","title":"版本","section":"第一部分 基础入门","content":" PostgreSQL 版本 # 12 # 12.2 # "},{"id":445,"href":"/note-cs/docs/domain/ai/agent/qianfan/","title":"百度千帆","section":"Agent","content":" 百度千帆 # conda create --name qianfan python=3.12 -y # 查看已创建的conda环境 conda info --envs # 激活环境 conda activate qianfan # 退出环境 conda deactivate "},{"id":446,"href":"/note-cs/docs/study/course/ai/baidu-aistudio/","title":"百度大脑","section":"6.8 人工智能","content":" 百度大脑 # "},{"id":447,"href":"/note-cs/docs/direction/","title":"第二部分 方向","section":"Docs","content":" 第二部分 方向 # ICT # "},{"id":448,"href":"/note-cs/docs/basic/os/thread/","title":"线程","section":"1.2 操作系统","content":" 线程 # 栈通常是连续增长的，由于每个进程中的各个线程共享虚拟内存空间，当有多个线程时，就需要为每个线程分配不同起始地址的栈。 这就需要在分配栈之前先预估每个线程栈的大小。\n如果线程数量非常多，就很容易栈溢出。\nSplit Stacks # 为了解决这个问题，就有了 Split Stacks 技术： 创建栈时，只分配一块比较小的内存，如果进行某次函数调用导致栈空间不足时，就会在其他地方分配一块新的栈空间。 新的空间不需要和老的栈空间连续。函数调用的参数会拷贝到新的栈空间中，接下来的函数执行都在新栈空间中进行。\nGolang 连续栈 # Golang 的栈管理方式与此类似，但是为了更高的效率，使用了 Golang 连续栈。 实现方式也是先分配一块固定大小的栈，在栈空间不足时，分配一块更大的栈，并把旧的栈全部拷贝到新栈中。 这样避免了 Split Stacks 方法可能导致的频繁内存分配和释放。\n"},{"id":449,"href":"/note-cs/docs/domain/cc/virtual/network/","title":"虚拟机网络","section":"虚拟化","content":" 虚拟机网络 # 在 VMware 的 3 中网络模式中，NAT 模式是最简单的，基本不需要手动配置 IP 地址等相关参数。至于桥接模式则需要额外的 IP 地址，如果是在内网环境中还很容易，如果是 ADSL 宽带就比较麻烦了，ISP 一般是不会大方的多提供一个公网 IP 的。\n三种网络模式 # 桥接 # 特点：\n如果主机可以上网，虚拟机可以上网 虚拟机之间可以 ping 通 虚拟机可以 ping 通主机 主机可以 ping 通虚拟机 如果主机不可以上网，所有 1-4 特点均无 应用场景：\n虚拟机要求可以上网，且虚拟机完全模拟一台实体机 桥接网络是指本地物理网卡和虚拟网卡通过 VMnet0 虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位，那么物理网卡和虚拟网卡就相当于处于同一个网段，虚拟交换机就相当于一台现实网络中的交换机，所以两个网卡的 IP 地址也要设置为同一网段。\n所以当我们要在局域网使用虚拟机，对局域网其他 pc 提供服务时，例如提供 ftp，提供 ssh，提供 http 服务，那么就要选择桥接模式。\n例如大学宿舍里有一个路由器，宿舍里四个人连接这个路由器，路由器的 wanip 就不理会了，这个 ip 是动态获取的，而 lanip 默认是 192.168.1.1, 子网掩码是 255.255.255.0。而其他四个人是自动获取 ip，假设四个人的 ip 是:\nA:192.168.1.100/255.255.255.0, B:192.168.1.101/255.255.255.0, C:192.168.1.102/255.255.255.0, D:192.168.1.103/255.255.255.0\n那么虚拟机的 ip 可以设置的 ip 地址是 192.168.1.2-192.168.1.99,192.168.1.104-192.168.1.254 (网络地址全 0 和全 1 的除外，再除去 ABCD 四个人的 ip 地址)\n那么虚拟机的 ip 地址可以设置为 192.168.1.98/255.255.255.0, 设置了这个 ip 地址，ABCD 这四个人就可以通过 192.168.1.98 访问虚拟机了，如果虚拟机需要上外网，那么还需要配置虚拟机的路由地址，就是 192.168.1.1 了，这样，虚拟机就可以上外网了，但是，上网我们一般是通过域名去访问外网的，所以我们还需要为虚拟机配置一个 dns 服务器，我们可以简单点，把 dns 服务器地址配置为 google 的 dns 服务器：8.8.8.8, 到此，虚拟机就可以上网了。\nNAT # 特点：\n如果主机可以上网，虚拟机可以上网 虚拟机之间不能 ping 通 虚拟机可以 ping 通主机（此时 ping 虚拟机的网关，即是 ping 主机） 主机不能 ping 通虚拟机 应用场景：\n虚拟机只要求可以上网，无其它特殊要求，满足最一般需求 NAT 模式中，就是让虚拟机借助 NAT (网络地址转换) 功能，通过宿主机器所在的网络来访问公网。\nNAT 模式中，虚拟机的网卡和物理网卡的网络，不在同一个网络，虚拟机的网卡，是在 vmware 提供的一个虚拟网络。\nNAT 和桥接的比较:\n(1) NAT 模式和桥接模式虚拟机都可以上外网。\n(2) 由于 NAT 的网络在 vmware 提供的一个虚拟网络里，所以局域网其他主机是无法访问虚拟机的，而宿主机可以访问虚拟机， 虚拟机可以访问局域网的所有主机，因为真实的局域网相对于 NAT 的虚拟网络，就是 NAT 的虚拟网络的外网，不懂的人可以查查 NAT 的相关知识。\n(3) 桥接模式下，多个虚拟机之间可以互相访问；NAT 模式下，多个虚拟机之间也可以相互访问。\n如果你建一个虚拟机，只是给自己用，不需要给局域网其他人用，那么可以选择 NAT，毕竟 NAT 模式下的虚拟系统的 TCP/IP 配置信息是由 VMnet8 (NAT) 虚拟网络的 DHCP 服务器提供的，只要虚拟机的网路配置是 DHCP，那么你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可，就可以让虚拟机联网了。\n例如你想建多个虚拟机集群，作为测试使用，而宿主机可能是一个笔记本，ip 不固定。这种应用场景，我们需要采用 nat 模式了，但是我们要考虑一个问题，虚拟机之间是需要互访的，默认采用 dhcp，虚拟机的 ip 每次重启，ip 都是不固定的，所以我们需要手工设置虚拟机的 ip 地址。\n但是我们对虚拟机网卡所在的虚拟网络的信息还一无所知，例如虚拟机网络的路由地址，子网掩码，所以我们需要先查下 nat 虚拟网络的信息。\n使用 vmware, 在 Edit-\u0026gt;Virtual Network Editor 中配置好虚拟网络信息后看到下图所示，注意 VMnet8，VMnet8 相当于是本机的一个路由，虚拟机设置 NAT 后就通过这个路由进行上网的，可以查看其网络地址，路由地址，子网掩码。\n选择 VMnet8-\u0026gt;NAT 设置，可以看到子网 ip 显示为 192.168.233.0，子网掩码是 255.255.255.0，那路由地址呢，其实就是网关 IP 了，都是同个东西，这里是 192.168.233.2。\n接下来就好办了，在对应的虚拟机设置好 ip，子网掩码，路由地址就可以上外网了，至于 dns 可以设置为 8.8.8.8.\nHost-Only # 特点：\n虚拟机不可以上网 虚拟机之间可以 ping 通 虚拟机可以 ping 通主机 注意虚拟机与主机通信是通过主机的名为 VirtualBox Host-Only Network 的网卡，因此 ip 是该网卡 ip 192.168.56.1，而不是你现在正在上网所用的 ip 主机可以 ping 通虚拟机 应用场景：\n在主机无法上网的情况下（主机可以上网的情况下可以用 host-only，也可以用桥接），需要搭建一个模拟局域网，所有机器可以互访 在 Host-Only 模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实 Host-Only 网络和 NAT 网络很相似，不同的地方就是 Host-Only 网络没有 NAT 服务，所以虚拟网络不能连接到 Internet。主机和虚拟机之间的通信是通过 VMware Network Adepter VMnet1 虚拟网卡来实现的。\nHost-Only 的宗旨就是建立一个与外界隔绝的内部网络，来提高内网的安全性。这个功能或许对普通用户来说没有多大意义，但大型服务商会常常利用这个功能。如果你想为 VMnet1 网段提供路由功能，那就需要使用 RRAS，而不能使用 XP 或 2000 的 ICS，因为 ICS 会把内网的 IP 地址改为 192.168.0.1，但虚拟机是不会给 VMnet1 虚拟网卡分配这个地址的，那么主机和虚拟机之间就不能通信了。\n"},{"id":450,"href":"/note-cs/docs/direction/be/devops/prometheus/recording-rule/","title":"记录规则","section":"Prometheus","content":" 记录规则 # "},{"id":451,"href":"/note-cs/docs/basic/os/process/","title":"进程","section":"1.2 操作系统","content":" 进程 # 进程虚拟地址空间 # "},{"id":452,"href":"/note-cs/docs/study/course/ai/baidu-aistudio/deep-learning-from-beginning/","title":"零基础实践深度学习","section":"百度大脑","content":" 百度架构师手把手带你零基础实践深度学习 # https://aistudio.baidu.com/aistudio/course/introduce/1297\n课程列表 # 预习课程 深度学习常用数学知识 第一章：零基础入门深度学习 第二章：一个案例吃透深度学习 第三章：深度学习实践应用 —— 计算机视觉 第四章：目标检测 YoloV3 第五章：深度学习实践应用 —— 自然语言处理 第六章：情感分类 第七章：深度学习实践应用 —— 推荐系统 第八章：深度学习高阶导入 拓展：【AI 实战案例项目集】 "},{"id":453,"href":"/note-cs/docs/direction/be/microservices/servicecomb/","title":"ServiceComb","section":"2.2.5 微服务","content":" ServiceComb # 子项目 # ServiceComb 目前拥有三个主要的子项目\napache/servicecomb-java-chassis # 开箱即用 Java 语言 微服务 SDK，含服务契约、编程模型、运行模型与通信模型四个部分，具备负载均衡、容错熔断、限流降级、调用链追踪等全面微服务治理能力，服务治理能力与业务逻辑隔离。\napache/servicecomb-service-center # 基于 Etcd 的高性能、高可用、无状态的 Golang 版分布式服务注册与发现中心，可实时服务实例注册、实时服务实例推送和服务间契约测试等。\napache/servicecomb-pack # Apache ServiceComb Pack (原 ServiceComb Saga) 是提供了分布式事务最终一致性解决方案，用户只需要通过注解方式定义事务的执行方法以及撤销方法，ServiceComb Pack 框架会自动保证分布式事务执行的最终一致性。\n其他 # apache/servicecomb-mesher # A high performance service mesh implementation written in go\nservicecomb-saga-actuator # Apache ServiceComb Saga Actuator https://servicecomb.apache.org/\n参考：\n如何评价华为新开源的 ServiceComb 微服务框架？ "},{"id":454,"href":"/note-cs/docs/study/book/basic/pl/go-in-action/","title":"Go in Action","section":"5.1.5 编程语言","content":" Go in Action # 作者 # William Kennedy\n"},{"id":455,"href":"/note-cs/docs/study/book/others/practical-vim/","title":"Practical Vim","section":"5.9 其他","content":" Practical Vim, 2nd Edition # 作者 # Drew Neil\n"},{"id":456,"href":"/note-cs/docs/study/activity/csapp/","title":"《深入理解计算机系统》学习","section":"4.4 学习活动","content":" 《深入理解计算机系统》学习 # 参考：\nhttps://talkgo.org/tag/深入理解计算机系统 打卡记录 # "},{"id":457,"href":"/note-cs/docs/basic/algs/","title":"1.3 数据结构与算法","section":"第一部分 基础","content":" 数据结构与算法 # 详见：算法学习笔记\n"},{"id":458,"href":"/note-cs/docs/domain/cc/istio/basic/arch/","title":"1.3 架构","section":"第一部分 基础入门","content":" Istio 架构 # 1.6 # 1.5 # Istiod # Istiod provides service discovery, configuration and certificate management.\n1.4 # Pilot # 1.1 # "},{"id":459,"href":"/note-cs/docs/basic/pl/assembly/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":460,"href":"/note-cs/docs/basic/pl/erlang/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":461,"href":"/note-cs/docs/basic/pl/haskell/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":462,"href":"/note-cs/docs/basic/pl/lua/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":463,"href":"/note-cs/docs/basic/pl/r/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":464,"href":"/note-cs/docs/basic/pl/ruby/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":465,"href":"/note-cs/docs/basic/pl/swift/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # raywenderlich/swift-style-guide # Swift 官方编码风格指导\n"},{"id":466,"href":"/note-cs/docs/basic/pl/zig/basic/spec/","title":"1.3 编程规范","section":"第一部分 基础入门","content":" 编程规范 # "},{"id":467,"href":"/note-cs/docs/basic/pl/shell/snippet/","title":"1.3.3 代码片段","section":"Shell","content":" 代码片段 # if item in list # list1=( a b c d ) list2=( b c ) # isIn $item $list function isIn() { item=$1 list=\u0026#34;${@:2}\u0026#34; for i in ${list[*]}; do if [[ $i == $item ]]; then return 0 fi done return 1 } for item in ${list1[*]}; do if isIn $item ${list2[*]}; then echo $item fi done 锁文件 # [建议] 使用 pid 生成锁文件，并用 set -C 来做逻辑判断 lockfile=/tmp/mylock if (set -C;echo $$ \u0026gt;$lockfile) 2\u0026gt;/dev/null; then # set -C 使已存在的文件不能再被写 # echo 不旦生成了锁文件，而且还将pid放入其中 # 当此lock文件存在时，if返回失败，跳到else trap \u0026#39;rm $lockfile; exit $?\u0026#39; INT TERM EXIT # trap保证了脚本异常中断时，释放锁文件（删） { my critical code... # 此处是正式的脚本代码 my critical code... my critical code... } rm $lockfile # 正式代码运行完了，释放锁文件 trap - INT TERM EXIT # 恢复trap的设置（如在脚本最后时，非必要恢复） exit 0 else # 锁文件生效，会跳到此处 echo \u0026#34;$lockfile exist, pid $(\u0026lt;$lockfile) is running.\u0026#34; # 打印错误信息 exit 1 fi "},{"id":468,"href":"/note-cs/docs/direction/be/db/postgresql/","title":"2.2.1.3 PostgreSQL","section":"2.2.1 数据库","content":" PostgreSQL # "},{"id":469,"href":"/note-cs/docs/direction/be/mq/rabbitmq/","title":"2.2.2.3 RabbitMQ","section":"2.2.2 消息队列","content":" RabbitMQ # rabbitmq/rabbitmq-server RabbitMQ 是一个 AMQP 实现，传统的 messaging queue 系统实现，基于 Erlang。老牌 MQ 产品了。AMQP 协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量还在其次。\n"},{"id":470,"href":"/note-cs/docs/direction/be/frame/","title":"2.2.3 后端框架","section":"2.2 后端","content":" 后端框架 # "},{"id":471,"href":"/note-cs/docs/direction/fe/frame/","title":"2.2.3 框架","section":"2.3 前端","content":" 框架 # "},{"id":472,"href":"/note-cs/docs/direction/fe/frame/angular/","title":"2.2.3.3 Angular","section":"2.2.3 框架","content":" Angular # "},{"id":473,"href":"/note-cs/docs/direction/be/distributed/zookeeper/","title":"2.2.4.3 Zookeeper","section":"2.2.4 分布式系统","content":" Zookeeper # "},{"id":474,"href":"/note-cs/docs/direction/be/microservices/rpc/dubbo/","title":"2.2.5.1.3 Dubbo","section":"2.2.5.1 RPC","content":" Dubbo # 国内最早开源的 RPC 框架，由阿里巴巴公司开发并于 2011 年末对外开源，仅支持 Java 语言\n"},{"id":475,"href":"/note-cs/docs/direction/fe/","title":"2.3 前端","section":"第二部分 方向","content":" 前端开发 # "},{"id":476,"href":"/note-cs/docs/domain/cc/istio/advanced/feature/","title":"2.3 功能","section":"第二部分 进阶实战","content":" 功能 # "},{"id":477,"href":"/note-cs/docs/basic/pl/assembly/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":478,"href":"/note-cs/docs/basic/pl/erlang/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":479,"href":"/note-cs/docs/basic/pl/haskell/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":480,"href":"/note-cs/docs/basic/pl/lua/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":481,"href":"/note-cs/docs/basic/pl/r/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":482,"href":"/note-cs/docs/basic/pl/ruby/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":483,"href":"/note-cs/docs/basic/pl/swift/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":484,"href":"/note-cs/docs/basic/pl/zig/advanced/pkg/","title":"2.3 常用库","section":"第二部分 进阶实战","content":" 常用库 # "},{"id":485,"href":"/note-cs/docs/domain/ai/","title":"3.3 人工智能","section":"第三部分 领域","content":" 人工智能 # "},{"id":486,"href":"/note-cs/docs/basic/pl/assembly/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":487,"href":"/note-cs/docs/basic/pl/erlang/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":488,"href":"/note-cs/docs/basic/pl/haskell/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":489,"href":"/note-cs/docs/basic/pl/lua/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":490,"href":"/note-cs/docs/basic/pl/r/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":491,"href":"/note-cs/docs/basic/pl/ruby/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":492,"href":"/note-cs/docs/basic/pl/swift/code/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":493,"href":"/note-cs/docs/basic/pl/zig/design/runtime/","title":"3.3 运行时","section":"第三部分 设计与实现","content":" 运行时 # "},{"id":494,"href":"/note-cs/docs/basic/pl/assembly/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":495,"href":"/note-cs/docs/basic/pl/erlang/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":496,"href":"/note-cs/docs/basic/pl/haskell/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":497,"href":"/note-cs/docs/basic/pl/lua/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # ngx_http_lua_module # openresty/lua-nginx-module ngx_http_lua_module - Embed the power of Lua into Nginx HTTP Servers.\nThis module is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty.\nTurbo.lua # kernelsauce/turbo Turbo is a framework built for LuaJIT 2 to simplify the task of building fast and scalable network applications. It uses a event-driven, non-blocking, no thread design to deliver excellent performance and minimal footprint to high-load applications while also providing excellent support for embedded uses.\nhttps://turbo.readthedocs.io/en/latest/\nPegasus.lua # EvandroLG/pegasus.lua Pegasus.lua is an http server to work with web applications written in Lua language.\nhttp://evandrolg.github.io/pegasus.lua/\n"},{"id":498,"href":"/note-cs/docs/basic/pl/r/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":499,"href":"/note-cs/docs/basic/pl/ruby/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":500,"href":"/note-cs/docs/basic/pl/swift/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # "},{"id":501,"href":"/note-cs/docs/basic/pl/zig/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # 代表项目 # oven-sh/bun # 推荐练手项目 # "},{"id":502,"href":"/note-cs/docs/domain/cc/cn/attention/","title":"4.3 关注项目","section":"云原生","content":" 关注项目 # cncf/landscape # The Cloud Native Interactive Landscape filters and sorts hundreds of projects and products, and shows details including GitHub stars, funding or market cap, first and last commits, contributor counts, headquarters location, and recent tweets. https://l.cncf.io\nTrail Map # CNCF Cloud Native Landscape # CNCF Serverless Landscape # dragonflyoss/Dragonfly # Dragonfly is an intelligent P2P based image and file distribution system.\nhttps://d7y.io\n"},{"id":503,"href":"/note-cs/docs/domain/cc/istio/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # istio/istio # Connect, secure, control, and observe services. https://istio.io\nenvoyproxy/envoy # Cloud-native high-performance edge/middle/service proxy https://www.envoyproxy.io\nkiali/kiali # Kiali project, observability for the Istio service mesh\nmosn/mosn # MOSN is a cloud native proxy for edge or service mesh. https://mosn.io\nrancher/rio Application Deployment Engine for Kubernetes https://rio.io\n其他 # kubernetes/kubernetes # Production-Grade Container Scheduling and Management https://kubernetes.io\nopenzipkin/zipkin # Zipkin is a distributed tracing system https://zipkin.io/\njaegertracing/jaeger # CNCF Jaeger, a Distributed Tracing Platform https://www.jaegertracing.io/\ndapr/dapr # layer5io/meshery # Meshery, the service mesh management plane https://meshery.io/\n"},{"id":504,"href":"/note-cs/docs/study/course/","title":"4.3 课程","section":"第五部分 学习","content":" 课程 # "},{"id":505,"href":"/note-cs/docs/study/book/basic/algs/","title":"5.1.3 数据结构与算法","section":"5.1 计算机基础","content":" 数据结构与算法 # "},{"id":506,"href":"/note-cs/docs/study/book/fe/","title":"5.3 前端","section":"4.2 读书","content":" 前端 # "},{"id":507,"href":"/note-cs/docs/study/course/basic/algs/","title":"6.1.3 数据结构与算法","section":"6.1 计算机基础","content":" 数据结构与算法 # "},{"id":508,"href":"/note-cs/docs/study/course/fe/","title":"6.3 前端","section":"4.3 课程","content":" 前端 # "},{"id":509,"href":"/note-cs/docs/direction/se/arch/scene/release/ab-testing/","title":"A/B 测试","section":"发布形式","content":" A/B 测试 # A/B testing\n参考 # "},{"id":510,"href":"/note-cs/docs/tool/macos/anki/","title":"Anki","section":"4.1 MacOS","content":" Anki # 插件 # glutanimate/review-heatmap # Anki add-on to help you keep track of your review activity\nninja33/ODH # 在线词典助手\nAnkiConnect # 该插件用于 Anki PC 客户端扩展功能，配合 Chrome 插件《Anki 划词制卡助手》 或者 《在线词典助手》使用。 https://www.laohuang.net/20160817/ankiconnect-py-file/\nNotes for Mac OS X Users # Starting with Mac OS X Mavericks, a feature named App Nap has been introduced to the operating system. This feature causes certain applications which are open (but not visible) to be placed in a suspended state. As this behavior causes AnkiConnect to stop working while you have another window in the foreground, App Nap should be disabled for Anki:\nStart the Terminal application. Execute the following commands in the terminal window: defaults write net.ankiweb.dtop NSAppSleepDisabled -bool true defaults write net.ichi2.anki NSAppSleepDisabled -bool true defaults write org.qt-project.Qt.QtWebEngineCore NSAppSleepDisabled -bool true Restart Anki. ninja33/FooSoft/anki-connect # Anki plugin to expose a remote API for creating flash cards.\n"},{"id":511,"href":"/note-cs/docs/tool/macos/autocut/","title":"AutoCut","section":"4.1 MacOS","content":" AutoCut # 安装 # pip install git+https://github.com/mli/autocut.git "},{"id":512,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/contour/","title":"Contour","section":"Ingress Controller","content":" Contour # projectcontour/contour Contour is a Kubernetes ingress controller using Envoy proxy.\n"},{"id":513,"href":"/note-cs/docs/study/skill/stream-media/debug/","title":"Debug","section":"4.5 流媒体","content":" Debug # "},{"id":514,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/xds/eds/","title":"EDS","section":"xDS","content":" EDS # "},{"id":515,"href":"/note-cs/docs/tool/macos/gitbook/","title":"Gitbook","section":"4.1 MacOS","content":" Gitbook # gitbook serve # serve 多个笔记本 # \u0026ndash;port Port for server to listen on (Default is 4000)\n\u0026ndash;lrport Port for livereload server to listen on (Default is 35729)\nSo you can change both two ports and serve as many books as you want.\neg:\none:\ngitbook --lrport 35730 --port 4001 serve another:\ngitbook --lrport 35731 --port 4002 serve "},{"id":516,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/","title":"Ingress Controller","section":"其他","content":" Ingress Controller # "},{"id":517,"href":"/note-cs/docs/domain/cc/virtual/iommu/","title":"IOMMU","section":"虚拟化","content":" IOMMU # "},{"id":518,"href":"/note-cs/docs/domain/cc/istio/","title":"Istio","section":"3.1 云计算","content":" Istio # "},{"id":519,"href":"/note-cs/docs/domain/cc/service-mesh/istio/","title":"Istio","section":"Service Mesh","content":" Istio # 详见：Istio 学习笔记\n"},{"id":520,"href":"/note-cs/docs/domain/cc/istio/code/istio/circuit-break/","title":"Istio 熔断","section":"3.1 Istio","content":" Istio 熔断 # "},{"id":521,"href":"/note-cs/docs/domain/cc/istio/code/istio/rate-limit/","title":"Istio 限流","section":"3.1 Istio","content":" Istio 限流 # "},{"id":522,"href":"/note-cs/docs/basic/pl/javascript/","title":"JavaScript","section":"1.5 编程语言","content":" JavaScript # 详见：JavaScript 学习笔记\n"},{"id":523,"href":"/note-cs/docs/domain/cc/kubernetes/","title":"Kubernetes","section":"3.1 云计算","content":" Kubernetes # 详见：Kubernetes 学习笔记\n"},{"id":524,"href":"/note-cs/docs/study/course/cc/kubernetes/","title":"Kubernetes","section":"6.6 云计算","content":" Kubernetes 课程 # "},{"id":525,"href":"/note-cs/docs/study/activity/kubernetes-scheduler/","title":"Kubernetes 调度器源码学习","section":"4.4 学习活动","content":" Kubernetes 调度器源码学习 # 参考：\n笔记链接：https://docs.qq.com/sheet/DR01kdWZkUmFLc0Jh?tab=o3eynn Kubernetes 源码研习社 学习笔记 # 第 8 章 kube-scheduler 核心实现\n8.1 kube-scheduler 命令行参数详解 8.2 kube-scheduler 架构设计详解 8.3 kube-scheduler 组件的启动流程 8.4 优先级与抢占机制 8.5 亲和性调度 8.6 内置调度算法 8.7 调度器核心实现 8.8 领导者选举机制 "},{"id":526,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/linkerd/","title":"Linkerd","section":"其他","content":" Linkerd # linkerd/linkerd2 Ultralight, security-first service mesh for Kubernetes. Main repo for Linkerd 2.x.\nhttps://linkerd.io/\nlinkerd/linkerd2-proxy A purpose-built proxy for the Linkerd service mesh. Written in Rust.\nlinkerd/linkerd A service mesh for Kubernetes and beyond. Main repo for Linkerd 1.x.\n"},{"id":527,"href":"/note-cs/docs/domain/cc/openstack/neutron/","title":"Neutron","section":"OpenStack","content":" Neutron # Neutron 当前支持的二层网络类型有 6 种：\nLocal Flat VLAN GRE VXLAN Geneve "},{"id":528,"href":"/note-cs/docs/domain/cc/others/paas/openshift/","title":"OpenShift","section":"PaaS","content":" OpenShift # Red Hat OpenShift is a leading hybrid cloud, enterprise Kubernetes application platform.\nOpenShift 在 Kubernetes 的基础上整合了应用的生命周期管理，包括 image 的编译，持续集成，部署以及更新。\nOpenshift 以前是 IaaS，现在 Openshift 自己宣称自己搭配 LXC 已经是 PaaS 了，VPS 不是云服务但可以类比为 IaaS。\nOpenshift 没有 root 权限\n参考：\nopenshift 和普通 vps 的区别在哪儿？ "},{"id":529,"href":"/note-cs/docs/domain/cc/openstack/","title":"OpenStack","section":"3.1 云计算","content":" OpenStack # openstack/nova OpenStack Compute openstack/swift OpenStack Storage: a distributed object storage system openstack/neutron OpenStack Networking openstack/horizon OpenStack Dashboard openstack/cinder OpenStack Block Storage openstack/ironic A service for managing and provisioning Bare Metal servers. 教程 # yeasy/openstack_understand_Neutron 深入理解 Neutron — OpenStack 网络实现 "},{"id":530,"href":"/note-cs/docs/domain/cc/service-mesh/","title":"Service Mesh","section":"3.1 云计算","content":" Service Mesh # Service Mesh Comparison # "},{"id":531,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/tracing/skywalking/","title":"SkyWalking","section":"Distributed Tracing","content":" SkyWalking # apache/skywalking APM, Application Performance Monitoring System https://skywalking.apache.org/\n"},{"id":532,"href":"/note-cs/docs/direction/be/web/soa/","title":"SOA","section":"Web Service","content":" SOA # "},{"id":533,"href":"/note-cs/docs/direction/be/web/soap/","title":"SOAP","section":"Web Service","content":" SOAP # "},{"id":534,"href":"/note-cs/docs/direction/be/auth/sso/","title":"SSO","section":"认证与授权","content":" SSO (Single sign-on) # "},{"id":535,"href":"/note-cs/docs/direction/be/devops/terraform/","title":"Terraform","section":"2.2.6 DevOps","content":" Terraform # hashicorp/terraform Terraform enables you to safely and predictably create, change, and improve infrastructure. It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned. https://www.terraform.io/\n"},{"id":536,"href":"/note-cs/docs/basic/os/type/android/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":537,"href":"/note-cs/docs/basic/os/type/ios/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":538,"href":"/note-cs/docs/basic/os/type/unix/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":539,"href":"/note-cs/docs/basic/os/type/windows/basic/practice/","title":"实践","section":"第一部分 基础入门","content":" 实践 # "},{"id":540,"href":"/note-cs/docs/direction/client/xiaochengxu/","title":"小程序","section":"2.4 客户端","content":" 小程序 # "},{"id":541,"href":"/note-cs/docs/direction/se/design-pattern/creational/factory-method/","title":"工厂方法","section":"创建型","content":" 工厂方法模式 # Factory Method\n又称工厂模式、多态工厂模式和虚拟构造器模式，\n通过定义工厂父类负责定义创建对象的公共接口，而子类则负责生成具体的对象。\n每个产品的实例化，分别有一个具体工厂负责 符合开闭原则：对扩展开放，对修改关闭 添加一种产品，就添加一种实现该产品的工厂 缺点\n每个工厂只能创建一类产品 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- 参考 # 简单工厂模式、工厂方法模式和抽象工厂模式有何区别？ "},{"id":542,"href":"/note-cs/docs/domain/cc/istio/basic/arch/components/","title":"组件","section":"1.3 架构","content":" 组件 # "},{"id":543,"href":"/note-cs/docs/direction/se/design-pattern/structural/composite/","title":"组合","section":"架构型","content":" 组合模式 # Composite Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":544,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/interpreter/","title":"翻译器","section":"行为型","content":" 翻译器模式 # Interpreter Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":545,"href":"/note-cs/docs/domain/cc/virtual/","title":"虚拟化","section":"3.1 云计算","content":" 虚拟化 # "},{"id":546,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/","title":"行为型","section":"2.1.1 设计模式","content":" 行为型模式 # "},{"id":547,"href":"/note-cs/docs/direction/se/design-pattern/principle/lsp/","title":"里氏替换原则","section":"设计原则","content":" 里氏替换原则 # 所有引用基类的地方必须能透明的使用其子类对象。 只要父类能出现的地方子类就可以出现，替换为子类也不会产生任何的错误。 开闭原则一般可以通过里氏替换实现对扩展开放，对修改关闭的效果。 "},{"id":548,"href":"/note-cs/docs/direction/se/arch/scene/release/canary-rollouts/","title":"金丝雀发布","section":"发布形式","content":" 金丝雀发布 # canary rollouts\n参考 # "},{"id":549,"href":"/note-cs/docs/basic/pl/shell/type/","title":"1.3.4 Shell 类型","section":"Shell","content":" Shell 类型 # "},{"id":550,"href":"/note-cs/docs/basic/pl/assembly/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":551,"href":"/note-cs/docs/basic/pl/erlang/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":552,"href":"/note-cs/docs/basic/pl/haskell/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":553,"href":"/note-cs/docs/basic/pl/lua/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # Lua 包管理 # LuaRocks # luarocks/luarocks LuaRocks is the package manager for the Lua programming language.\n"},{"id":554,"href":"/note-cs/docs/basic/pl/r/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":555,"href":"/note-cs/docs/basic/pl/ruby/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":556,"href":"/note-cs/docs/basic/pl/swift/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":557,"href":"/note-cs/docs/basic/pl/zig/basic/others/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":558,"href":"/note-cs/docs/domain/cc/istio/basic/other/","title":"1.4 其他","section":"第一部分 基础入门","content":" 其他 # "},{"id":559,"href":"/note-cs/docs/basic/network/","title":"1.4 计算机网络","section":"第一部分 基础","content":" 计算机网络 # 详见：网络学习笔记\n"},{"id":560,"href":"/note-cs/docs/direction/be/mq/pulsar/","title":"2.2.2.4 Pulsar","section":"2.2.2 消息队列","content":" Pulsar # apache/pulsar Apache Pulsar - distributed pub-sub messaging system\n"},{"id":561,"href":"/note-cs/docs/direction/be/distributed/","title":"2.2.4 分布式系统","section":"2.2 后端","content":" 分布式系统 # Distributed System\n问答 # 分布式与集群的区别 # 参考：\n知乎：分布式与集群的区别是什么？ 分布式架构（1） - 大白话讲解：分布式与集群的区别是什么？ "},{"id":562,"href":"/note-cs/docs/direction/be/distributed/etcd/","title":"2.2.4.4 Etcd","section":"2.2.4 分布式系统","content":" Etcd # 读音： 名称来源：UNIX 的 /etc 文件夹和分布式系统 (Distribute system) 的 D "},{"id":563,"href":"/note-cs/docs/direction/be/microservices/rpc/spring-cloud/","title":"2.2.5.1.4 Spring Cloud","section":"2.2.5.1 RPC","content":" Spring Cloud # TarsCloud/Tars 国外 Pivotal 公司 2014 年对外开源的 RPC 框架，仅支持 Java 语言。\nEureka：各个服务启动时，Eureka Client 都会将服务注册到 Eureka Server，并且 Eureka Client 还可以反过来从 Eureka Server 拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于 Ribbon 做负载均衡，从一个服务的多台机器中选择一台 Feign：基于 Feign 的动态代理机制，根据注解和选择的机器，拼接请求 URL 地址，发起请求 Hystrix：发起请求是通过 Hystrix 的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从 Zuul 网关进入，由 Zuul 网关转发请求给对应的服务 Eureka # Eureka 是微服务架构中的注册中心，专门负责服务的注册与发现。\nEureka Client：负责将这个服务的信息注册到 Eureka Server 中 Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号 Feign # Feign 的一个关键机制就是使用了动态代理。\nRibbon # 负载均衡\nRibbon 的负载均衡默认使用的最经典的 Round Robin 轮询算法\nHystrix # Hystrix 是隔离、熔断以及降级的一个框架。\nHystrix 会搞很多个小小的线程池， 比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。 每个线程池里的线程就仅仅用于请求那个服务。\n解决服务雪崩：\n熔断\n比如在 5 分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟。 这个过程，就是所谓的熔断！\n降级\n每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。 这个过程，就是所谓的降级。\nZuul # Netflix/zuul 微服务网关\n可以做统一的降级、限流、认证授权、安全等等\n"},{"id":564,"href":"/note-cs/docs/basic/pl/assembly/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":565,"href":"/note-cs/docs/basic/pl/erlang/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":566,"href":"/note-cs/docs/basic/pl/haskell/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":567,"href":"/note-cs/docs/basic/pl/lua/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":568,"href":"/note-cs/docs/basic/pl/r/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":569,"href":"/note-cs/docs/basic/pl/ruby/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":570,"href":"/note-cs/docs/basic/pl/swift/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":571,"href":"/note-cs/docs/basic/pl/zig/advanced/snippet/","title":"2.4 代码片段","section":"第二部分 进阶实战","content":" 代码片段 # "},{"id":572,"href":"/note-cs/docs/direction/client/","title":"2.4 客户端","section":"第二部分 方向","content":" 客户端 # 关注项目 # didi/DoraemonKit # 一款面向泛前端产品研发全生命周期的效率平台。\n"},{"id":573,"href":"/note-cs/docs/domain/blockchain/","title":"3.4 区块链","section":"第三部分 领域","content":" 区块链 # 教程 # yeasy/blockchain_guide 区块链技术指南 "},{"id":574,"href":"/note-cs/docs/study/activity/","title":"4.4 学习活动","section":"第五部分 学习","content":" 学习活动 # "},{"id":575,"href":"/note-cs/docs/study/book/basic/network/","title":"5.1.4 计算机网络","section":"5.1 计算机基础","content":" 计算机网络 # "},{"id":576,"href":"/note-cs/docs/study/book/security/","title":"5.4 安全","section":"4.2 读书","content":" 安全 # "},{"id":577,"href":"/note-cs/docs/study/course/basic/network/","title":"6.1.4 计算机网络","section":"6.1 计算机基础","content":" 计算机网络 # "},{"id":578,"href":"/note-cs/docs/study/course/security/","title":"6.4 安全","section":"4.3 课程","content":" 安全 # "},{"id":579,"href":"/note-cs/docs/direction/be/devops/ansible/","title":"Ansible","section":"2.2.6 DevOps","content":" Ansible # ansible/ansible Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems.\n"},{"id":580,"href":"/note-cs/docs/domain/cc/others/paas/cloud-foundry/","title":"Cloud Foundry","section":"PaaS","content":" Cloud Foundry # Cloud Foundry 提供了云、开发者框架和应用服务的选择，可以更快、更容易的构建、测试、发布和大规模部署应用程序。它是一个开源项目，可通过各种私有云发行版和公有云实例获得。\n组件 # cloudfoundry/bosh # Cloud Foundry BOSH is an open source tool for release engineering, deployment, lifecycle management, and monitoring of distributed systems.\ncloudfoundry/cli # The official command line client for Cloud Foundry https://docs.cloudfoundry.org/cf-cli\ncloudfoundry/uaa # CloudFoundry User Account and Authentication (UAA) Server\nCloud Foundry 缺点 # 诸如 Cloud Foundry 的 PaaS，用户必须为不同语言、不同框架区分不同的打包方式，这个打包过程是非常具有灾难性的。 而现实往往更糟糕，当在本地跑的好好的应用，由于和远端环境的不一致，在打包后却需要在云端各种调试，最终才能让应用 “平稳” 运行。\n而 Docker 的出现改变了一切，它凭借镜像解决了这个问题。Docker 一不做二不休，干脆把完整的操作系统目录也打包进去，如此高的集成度，保证了云端和本地环境的高度一致，并且随时随地轻易地移植。\n参考：\nKubernetes 如何打赢容器之战？ "},{"id":581,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/tracing/","title":"Distributed Tracing","section":"其他","content":" Distributed Tracing # opentracing Supported tracers\njaegertracing/jaeger apache/skywalking openzipkin/zipkin census-instrumentation/opencensus-go LightStep Instana inspectIT stagemonitor Datadog Wavefront by VMware Elastic APM 参考：\nDapper, a Large-Scale Distributed Systems Tracing Infrastructure "},{"id":582,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/gloo/","title":"Gloo","section":"其他","content":" Gloo # solo-io/gloo The Feature-rich, Kubernetes-native, Next-Generation API Gateway Built on Envoy\n"},{"id":583,"href":"/note-cs/docs/basic/pl/python/","title":"Python","section":"1.5 编程语言","content":" Python # 详见：Python 学习笔记\n"},{"id":584,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/xds/rds/","title":"RDS","section":"xDS","content":" RDS # "},{"id":585,"href":"/note-cs/docs/direction/be/web/wsdl/","title":"WSDL","section":"Web Service","content":" WSDL # "},{"id":586,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/tracing/zipkin/","title":"Zipkin","section":"Distributed Tracing","content":" Zipkin # openzipkin/zipkin Zipkin is a distributed tracing system https://zipkin.io/\n"},{"id":587,"href":"/note-cs/docs/direction/se/design-pattern/principle/dip/","title":"依赖倒置原则","section":"设计原则","content":" 依赖倒置原则 # 模块间的依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生的。 即依赖抽象，而不依赖具体的实现。 "},{"id":588,"href":"/note-cs/docs/direction/se/design-pattern/creational/prototype/","title":"原型","section":"创建型","content":" 原型模式 # Prototype\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":589,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/envoy/version/","title":"版本","section":"Envoy","content":" Envoy 版本 # 参考： https://www.envoyproxy.io/docs/envoy/v1.15.0/version_history/version_history\n1.17 # 1.17.1 # 1.17.0 # 1.16 # 1.16.2 # 1.16.0 (2020-10-08) # 1.15 # 1.15.0 (2020-07-06) # 1.14 # 1.14.3 (2020-06-30) # 1.14.2 (2020-06-08) # 1.14.0 (2020-04-08) # 1.13 # 1.13.3 (2020-06-30) # 1.13.0 (2020-01-20) # 1.12 # 1.12.5 (2020-06-30) # 1.12.1 (2019-11-08) # 1.5 (2017-12-04) # 1.4 (2017-08-24) # 1.3 (2017-05-17) # 1.2 (2017-03-07) # 1.1 (2016-11-30) # 1.0 (2016-09-12) # "},{"id":590,"href":"/note-cs/docs/domain/cc/istio/basic/other/version/","title":"版本","section":"1.4 其他","content":" Istio 版本 # istio/istio 参考： https://istio.io/news/releases/\n1.7 # 1.6 # 1.6.5 (2020-07-09) # 1.6.0 (2020-05-21) # 1.5 # 1.5.8 (2020-07-09) # 1.5.0 (2020-03-05) # 1.4 # 1.4.0 (2019-11-14) # 1.3 # 1.2 # 1.1 # 1.0 # 0.x # 0.8 (2018-06-01) # 0.2 (2017-10-10) # 0.1 (2017-05-24) # "},{"id":591,"href":"/note-cs/docs/tool/","title":"第四部分 工具","section":"Docs","content":" 网络加速 # Github 加速 # https://ghfast.top/ 最新地址：https://ghproxy.link/ AI IDE # google-gemini/gemini-cli cline/cline RooCodeInc/Roo-Code openai/codex anthropics/claude-code QwenLM/qwen-code sst/opencode block/goose charmbracelet/crush Kilo-Org/kilocode iflow-ai/iflow-cli Cursor Windsurf Codeium Antigravity Trae Github Copilot Auggie CLI (Augment Code) "},{"id":592,"href":"/note-cs/docs/direction/se/design-pattern/structural/decorator/","title":"装饰","section":"架构型","content":" 装饰模式 # Decorator\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":593,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/iterator/","title":"迭代器","section":"行为型","content":" 迭代器模式 # Iterator Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":594,"href":"/note-cs/docs/basic/pl/","title":"1.5 编程语言","section":"第一部分 基础","content":" 编程语言 # Every Language Fixes Something A History of Haskell: Being Lazy With Class 编程规范 # Google Style Guides # google/styleguide Google 开源项目风格指南 # zh-google-styleguide/zh-google-styleguide 函数式编程 # Mostly adequate guide to FP (in javascript) # MostlyAdequate/mostly-adequate-guide 函数式编程指北中文版 # llh911001/mostly-adequate-guide-chinese https://llh911001.gitbook.io/mostly-adequate-guide-chinese/\n"},{"id":595,"href":"/note-cs/docs/direction/be/microservices/","title":"2.2.5 微服务","section":"2.2 后端","content":" 微服务 # "},{"id":596,"href":"/note-cs/docs/direction/embedded/","title":"2.5 嵌入式","section":"第二部分 方向","content":" 嵌入式开发 # "},{"id":597,"href":"/note-cs/docs/domain/cc/istio/advanced/debug/","title":"2.5 故障排查","section":"第二部分 进阶实战","content":" 故障排查 # "},{"id":598,"href":"/note-cs/docs/basic/pl/assembly/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":599,"href":"/note-cs/docs/basic/pl/erlang/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":600,"href":"/note-cs/docs/basic/pl/haskell/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":601,"href":"/note-cs/docs/basic/pl/lua/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":602,"href":"/note-cs/docs/basic/pl/r/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":603,"href":"/note-cs/docs/basic/pl/ruby/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":604,"href":"/note-cs/docs/basic/pl/swift/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":605,"href":"/note-cs/docs/basic/pl/zig/advanced/test/","title":"2.5 测试","section":"第二部分 进阶实战","content":" 测试 # "},{"id":606,"href":"/note-cs/docs/tool/linux/debian/","title":"4.2.3 Debian","section":"4.2 Linux","content":" Debian # 参考： Debian 发行版本\n开源镜像 # Debian 9 # deb http://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free deb http://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free deb http://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free deb http://mirrors.tuna.tsinghua.edu.cn/debian-security stretch/updates main contrib non-free "},{"id":607,"href":"/note-cs/docs/study/skill/stream-media/","title":"4.5 流媒体","section":"4.1 技能树","content":" 流媒体 # "},{"id":608,"href":"/note-cs/docs/study/book/basic/pl/","title":"5.1.5 编程语言","section":"5.1 计算机基础","content":" 编程语言 # Go # 书名 作者 / 译者 出版时间 语言版本 豆瓣评分 其他说明 Go in Action 参考：\ngolang/go/wiki/Books dariubs/GoBooks List of Golang books "},{"id":609,"href":"/note-cs/docs/study/book/se/","title":"5.5 软件工程","section":"4.2 读书","content":" 软件工程 # "},{"id":610,"href":"/note-cs/docs/study/course/basic/pl/","title":"6.1.5 编程语言","section":"6.1 计算机基础","content":" 编程语言 # "},{"id":611,"href":"/note-cs/docs/study/course/se/","title":"6.5 软件工程","section":"4.3 课程","content":" 软件工程 # "},{"id":612,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/apisix/","title":"APISIX","section":"其他","content":" APISIX # apache/apisix "},{"id":613,"href":"/note-cs/docs/domain/cc/others/paas/appfog/","title":"AppFog","section":"PaaS","content":" AppFog # "},{"id":614,"href":"/note-cs/docs/domain/bigdata/flink/","title":"Flink","section":"3.2 大数据","content":" Flink # "},{"id":615,"href":"/note-cs/docs/domain/bigdata/hadoop/","title":"Hadoop","section":"3.2 大数据","content":" Hadoop # HDFS # Hadoop Distributed File System，是 Hadoop 的分布式文件系统\n每台机器上运行一个 DataNode 进程，负责管理一部分数据。\n有一台机器上运行了 NameNode 进程，负责管理整个 HDFS 集群的这么一个进程，里面存储了 HDFS 集群的所有元数据\n每次内存里改完了，写一条 edits log，元数据修改的操作日志到磁盘文件里，不修改磁盘文件内容，就是顺序追加\n每次 NameNode 重启的时候，把 edits log 里的操作日志读到内存里，就可以恢复元数据\nYARN # MapReduce # "},{"id":616,"href":"/note-cs/docs/domain/bigdata/hadoop/hbase/","title":"HBase","section":"Hadoop","content":" HBase # apache/hbase "},{"id":617,"href":"/note-cs/docs/domain/bigdata/hadoop/hdfs/","title":"HDFS","section":"Hadoop","content":" HDFS # "},{"id":618,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/istio-ingress/","title":"Istio Ingress","section":"Ingress Controller","content":" Istio Ingress # "},{"id":619,"href":"/note-cs/docs/basic/pl/java/","title":"Java","section":"1.5 编程语言","content":" Java # 详见：Java 学习笔记\n"},{"id":620,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/kong/","title":"Kong","section":"其他","content":" Kong # Kong/kong Kong is a cloud-native, fast, scalable, and distributed Microservice Abstraction Layer (also known as an API Gateway or API Middleware). Made available as an open-source project in 2015, its core values are high performance and extensibility.\nQuickstart # "},{"id":621,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/ingress-nginx/","title":"kubernetes/ingress-nginx","section":"Ingress Controller","content":" NGINX Ingress Controller # kubernetes/ingress-nginx NGINX Ingress Controller for Kubernetes https://kubernetes.github.io/ingress-nginx/\n"},{"id":622,"href":"/note-cs/docs/domain/bigdata/hadoop/mapreduce/","title":"MapReduce","section":"Hadoop","content":" MapReduce # "},{"id":623,"href":"/note-cs/docs/direction/be/devops/packer/","title":"Packer","section":"2.2.6 DevOps","content":" Packer # hashicorp/packer Packer is a tool for creating identical machine images for multiple platforms from a single source configuration. http://www.packer.io/\n"},{"id":624,"href":"/note-cs/docs/domain/bigdata/spark/","title":"Spark","section":"3.2 大数据","content":" Spark # apache/spark "},{"id":625,"href":"/note-cs/docs/direction/be/frame/php/swoole/","title":"Swoole","section":"PHP 框架","content":" Swoole # swoole/swoole-src Coroutine-based concurrency library for PHP https://www.swoole.co.uk\nSwoole 使 PHP 开发人员可以编写高性能高并发的 TCP、UDP、Unix Socket、HTTP、 WebSocket 等服务，让 PHP 不再局限于 Web 领域。\n"},{"id":626,"href":"/note-cs/docs/direction/be/db/tidb/","title":"TiDB","section":"2.2.1 数据库","content":" TiDB # pingcap/tidb TiDB is a distributed HTAP database compatible with the MySQL protocol https://pingcap.com\nTiDB (\u0026ldquo;Ti\u0026rdquo; stands for Titanium) is an open-source NewSQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability.\nTiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。\n"},{"id":627,"href":"/note-cs/docs/direction/be/web/uudi/","title":"UUDI","section":"Web Service","content":" UUDI # "},{"id":628,"href":"/note-cs/docs/direction/be/distributed/consistent-hashing/","title":"一致性哈希","section":"2.2.4 分布式系统","content":" 一致性哈希 # 这篇论文中提出了一致性 hash 的概念。\nincubator-brpc doc - 一致性哈希\n一致性 hash 满足以下四个性质：\n平衡性 (Balance) : 每个节点被选到的概率是 O (1/n)。 单调性 (Monotonicity) : 当新节点加入时， 不会有请求在老节点间移动， 只会从老节点移动到新节点。当有节点被删除时，也不会影响落在别的节点上的请求。 分散性 (Spread) : 当上游的机器看到不同的下游列表时 (在上线时及不稳定的网络中比较常见), 同一个请求尽量映射到少量的节点中。 负载 (Load) : 当上游的机器看到不同的下游列表的时候， 保证每台下游分到的请求数量尽量一致。 "},{"id":629,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/mediator/","title":"中介者","section":"行为型","content":" 中介者模式 # Mediator Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":630,"href":"/note-cs/docs/basic/os/type/android/basic/snippet/","title":"代码片段","section":"第一部分 基础入门","content":" 代码片段 # "},{"id":631,"href":"/note-cs/docs/basic/os/type/ios/basic/snippet/","title":"代码片段","section":"第一部分 基础入门","content":" 代码片段 # "},{"id":632,"href":"/note-cs/docs/basic/os/type/unix/basic/snippet/","title":"代码片段","section":"第一部分 基础入门","content":" 代码片段 # "},{"id":633,"href":"/note-cs/docs/basic/os/type/windows/basic/snippet/","title":"代码片段","section":"第一部分 基础入门","content":" 代码片段 # "},{"id":634,"href":"/note-cs/docs/direction/be/distributed/transaction/","title":"分布式事务","section":"2.2.4 分布式系统","content":" 分布式事务 # 微服务化带来的分布式事务问题 # 每一个服务内部的数据一致性仍由本地事务来保证。而整个业务层面的全局数据一致性要如何保障呢？\n解决方案 # 分布式事务的实现主要有以下 5 种方案：\nXA 方案 TCC 方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。\n你找一个严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。\n友情提示一下，RocketMQ 3.2.6 之前的版本，是可以按照上面的思路来的，但是之后接口做了一些改变，我这里不再赘述了。\n当然如果你愿意，你可以参考可靠消息最终一致性方案来自己实现一套分布式事务，比如基于 RocketMQ 来玩儿。\n参考：\n分布式事务了解吗？你们是如何解决分布式事务问题的？ XA 方案 # 两阶段提交方案\n有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？ 如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。\n这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。\n如果要玩儿，那么基于 Spring + JTA 就可以搞定，自己随便搜个 demo 看看就知道了。\n这个方案，我们很少用，一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。\nTCC # 这种方案说实话几乎很少人使用， 因为这个事务回滚实际上是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大，非常之恶心，业务代码是很难维护的。\n比如说我们，一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。\n而且最好是你的各个业务执行的时间都比较短。\nTCC 分布式事务框架，比如国内开源的\nByteTCC himly tcc-transaction Try # 首先你的业务的主流程以及各个接口提供的业务含义，不是说直接完成那个业务操作，而是完成一个 Try 的操作。\n这个操作，一般都是锁定某个资源，设置一个预备类的状态，冻结部分数据，等等，大概都是这类操作。\nConfirm # Cancel # 参考：\n拜托，面试请不要再问我 TCC 分布式事务的实现原理！ 本地消息表 # 本地消息表其实是国外的 ebay 搞出来的这么一套思想。\n这个大概意思是这样的：\nA 系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着 A 系统将这个消息发送到 MQ 中去； B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息； B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态； 如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理； 这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。 这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。\n可靠消息最终一致性方案 # 这个的意思，就是干脆不要用本地的消息表了，直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。\n大概的意思就是：\nA 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息； 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务； mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所以没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你就用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。 最大努力通知方案 # 这个方案的大致意思就是：\n系统 A 本地事务执行完之后，发送个消息到 MQ； 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口； 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。 开源实现 # seata/seata # TXC/GTS/Fescar/Seata 一脉相承\n2014 年，阿里中间件团队发布 TXC（Taobao Transaction Constructor），为集团内应用提供分布式事务服务。 2016 年，TXC 经过产品化改造，以 GTS（Global Transaction Service） 的身份登陆阿里云，成为当时业界唯一一款云上分布式事务产品，在阿云里的公有云、专有云解决方案中，开始服务于众多外部客户。 2019 年起，基于 TXC 和 GTS 的技术积累，阿里中间件团队发起了开源项目 Fescar（Fast \u0026amp; EaSy Commit And Rollback, FESCAR），和社区一起建设这个分布式事务解决方案。 开源分布式事务 Fescar 更名为 Seata 华为 DTM # 分布式事务管理中间件（Distributed Transaction Management）是一款用于解决分布式环境下事务一致性问题的产品。在复杂环境下，事务可能会出现的各种异常，DTM 能够将开发者从处理这种异常中解放出来，聚焦于业务逻辑本身。\nDTM 支持 TCC（Try-Confirm-Cancel）事务模型，支持以注解的方式定义事务信息，实现事务高效便捷的接入。此外，DTM 具有处理高并发事务请求的能力，支持自动部署、弹性伸缩等全生命周期运维管控能力。\n参考 # 如何理解 TCC 分布式事务？ "},{"id":635,"href":"/note-cs/docs/direction/se/design-pattern/creational/singleton/","title":"单例","section":"创建型","content":" 单例模式 # Singleton\n实现方法 # 初始化时即创建单例 饿汉式 枚举类型 按需，延迟创建单例 懒汉式 基础实现 同步锁 双重检验锁 静态内部类实现 饿汉式（线程安全） # JVM 在类的初始化阶段 (即 在 Class 被加载后、被线程使用前)，会执行类的初始化 在执行类的初始化期间，JVM 会去获取一个锁，这个锁可以同步多个线程对同一个类的初始化 class Singleton { // 1. 加载该类时，单例就会自动被创建 private static Singleton ourInstance = new Singleton(); // 2. 构造函数设置为 私有权限，禁止他人创建实例 private Singleton() { } // 3. 通过调用静态方法获得创建的单例 public static Singleton newInstance() { return ourInstance; } } 应用场景\n单例对象要求初始化速度快，占用内存小 枚举类（线程安全） # 这是最简洁，最易用的单例实现方式 单元素的枚举类型已经成为实现 Singleton 的最佳方法 - 《Effective Java》\npublic enum Singleton { // 定义 1 个枚举的元素，即为单例类的1个实例 INSTANCE; // 隐藏了 1 个空的、私有的 构造方法 // private Singleton () {} } // 获取单例的方式： Singleton singleton = Singleton.INSTANCE; 懒汉式 基础实现（线程不安全） # class Singleton { // 1. 类加载时，先不自动创建单例，将单例的引用先赋值为 Null private static Singleton ourInstance = null; // 2. 构造函数 设置为 私有权限 // 禁止他人创建实例 private Singleton() { } // 3. 需要时才手动调用 newInstance（） 创建 单例 public static Singleton newInstance() { // 先判断单例是否为空，以避免重复创建 if (ourInstance == null) { ourInstance = new Singleton(); } return ourInstance; } } 懒汉式 同步锁（线程安全） # // 写法1 class Singleton { // 1. 类加载时，先不自动创建单例 // 即，将单例的引用先赋值为 Null private static Singleton ourInstance = null； // 2. 构造函数 设置为 私有权限 // 原因：禁止他人创建实例 private Singleton() { } // 3. 加入同步锁 public static synchronized Singleton getInstance() { // 先判断单例是否为空，以避免重复创建 if (ourInstance == null) ourInstance = new Singleton(); return ourInstance; } } // 写法2 // 该写法的作用与上述写法作用相同，只是写法有所区别 class Singleton { private static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { // 加入同步锁 synchronized (Singleton.class) { if (instance == null) instance = new Singleton(); } return instance; } } 缺点\n每次访问都要进行线程同步（即 调用 synchronized 锁)，造成过多的同步开销（加锁 = 耗时、耗能） 实际上只需在第 1 次调用该方法时才需要同步，一旦单例创建成功后，就没必要进行同步 懒汉式 双重检验锁（线程安全） # class Singleton { private static Singleton ourInstance = null； private Singleton() { } public static Singleton newInstance() { // 加入双重校验锁 // 校验锁1：第1个if if (ourInstance == null) { // ① synchronized (Singleton.class) { // ② // 校验锁2：第2个 if if (ourInstance == null) { ourInstance = new Singleton(); } } } return ourInstance; } } // 说明 // 校验锁1：第1个if // 作用：若单例已创建，则直接返回已创建的单例，无需再执行加锁操作 // 即直接跳到执行 return ourInstance // 校验锁2：第2个 if // 作用：防止多次创建单例问题 // 原理 // 1. 线程A调用newInstance()，当运行到②位置时，此时线程B也调用了newInstance() // 2. 因线程A并没有执行instance = new Singleton();，此时instance仍为空，因此线程B能突破第1层 if // 判断，运行到①位置等待synchronized中的A线程执行完毕 // 3. 当线程A释放同步锁时，单例已创建，即instance已非空 // 4. 此时线程B 从①开始执行到位置②。此时第2层 if 判断 = 为空（单例已创建），因此也不会创建多余的实例 缺点\n实现复杂（多种判断），易出错 静态内部类（线程安全） # class Singleton { // 1. 创建静态内部类 private static class Singleton2 { // 在静态内部类里创建单例 private static Singleton ourInstance = new Singleton()； } // 私有构造函数 private Singleton() { } // 延迟加载、按需创建 public static Singleton newInstance() { return Singleton2.ourInstance; } } 调用过程说明：\n外部调用类的 newInstance() 自动调用 Singleton2.ourInstance 此时单例类 Singleton2 得到初始化 而该类在装载 \u0026amp; 被初始化时，会初始化它的静态域，从而创建单例； 由于是静态域，因此只会 JVM 只会加载 1 遍，Java 虚拟机保证了线程安全性 最终只创建 1 个单例 缺点\n单例类的职责过重，里面的代码可能会过于复杂，在一定程度上违背了 \u0026ldquo;单一职责原则\u0026rdquo; 如果实例化的对象长时间不被利用，会被系统认为是垃圾而被回收，这将导致对象状态的丢失 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":636,"href":"/note-cs/docs/direction/se/design-pattern/structural/facade/","title":"外观","section":"架构型","content":" 外观模式 # Facade\n适配器是将接口转换为不同接口 外观模式是提供一个统一的接口来简化接口 public class Facade Pattern { public static void main(String[] args) { //实例化电器类 SubSystemA_Light light = new SubSystemA_Light(); SubSystemB_Television television = new SubSystemB_Television(); SubSystemC_Aircondition aircondition = new SubSystemC_Aircondition(); //传参 Facade facade = new Facade(light,television,aircondition); //客户端直接与外观对象进行交互 facade.on; System.out.prinln(\u0026#34;可以看电视了\u0026#34;)； facade.off; System.out.prinln(\u0026#34;可以睡觉了\u0026#34;)； } } 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":637,"href":"/note-cs/docs/direction/se/design-pattern/principle/isp/","title":"接口隔离原则","section":"设计原则","content":" 接口隔离原则 # 客户端不应该依赖它不需要的接口。 目的是解开系统的耦合，从而容易重构更改。 "},{"id":638,"href":"/note-cs/docs/basic/pl/assembly/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":639,"href":"/note-cs/docs/basic/pl/erlang/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":640,"href":"/note-cs/docs/basic/pl/haskell/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":641,"href":"/note-cs/docs/basic/pl/lua/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":642,"href":"/note-cs/docs/basic/pl/r/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":643,"href":"/note-cs/docs/basic/pl/ruby/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":644,"href":"/note-cs/docs/basic/pl/swift/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":645,"href":"/note-cs/docs/basic/pl/zig/basic/others/version/","title":"版本","section":"1.4 其他","content":" 版本 # 版本历史 # "},{"id":646,"href":"/note-cs/docs/direction/se/design-pattern/other/simple-factory/","title":"简单工厂","section":"其他模式","content":" 简单工厂模式 # Simple Factory Pattern，又称为静态工厂方法 (Static Factory Method) 模式\n通过传入参数获取到对象，不关心创建对象的细节。\n// create 是静态方法，直接用类调用（不需要实例化） object1 = Factory.create(1); object2 = Factory.create(2); 优点\n将创建实例的工作与使用实例的工作分开，使用者不必关心类对象如何创建，实现了解耦； 把初始化实例时的工作放到工厂里进行，使代码更容易维护。更符合面向对象的原则 \u0026amp; 面向接口编程，而不是面向实现编程。 缺点\n工厂类集中了所有实例（产品）的创建逻辑，一旦这个工厂不能正常工作，整个系统都会受到影响； 违背 “开放 - 关闭原则”，一旦添加新产品就不得不修改工厂类的逻辑，这样就会造成工厂逻辑过于复杂。 简单工厂模式由于使用了静态工厂方法，静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。 静态方法可以被继承 应用场景\n客户如果只知道传入工厂类的参数，对于如何创建对象的逻辑不关心时； 当工厂类负责创建的对象（具体产品）比较少时。 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":647,"href":"/note-cs/docs/basic/compile/","title":"1.6 编译原理","section":"第一部分 基础","content":" 编译原理 # "},{"id":648,"href":"/note-cs/docs/direction/be/devops/","title":"2.2.6 DevOps","section":"2.2 后端","content":" DevOps # 不可变基础架构 # 不可变基础架构 Immutable Infrastructure hashicorp/terraform opentofu/opentofu Previously named OpenTF, OpenTofu is a fork of Terraform that is open-source, community-driven, and managed by the Linux Foundation. pulumi/pulumi OpenStack - Heat AWS CloudFormation 阿里云 ROS Resource Orchestration Service 华为云 AOS Application Orchestration Service 百度云 COS Cloud Orchestration Service 可变基础架构 Mutable Infrastructure ansible/ansible saltstack/salt chef/chef puppetlabs/puppet 申明式 API # 声明性代码 Declarative hashicorp/terraform saltstack/salt puppetlabs/puppet AWS CloudFormation 程序性代码 Procedural ansible/ansible chef/chef 其他 # prometheus/prometheus jenkinsci/jenkins "},{"id":649,"href":"/note-cs/docs/direction/security/","title":"2.6 安全","section":"第二部分 方向","content":" 安全 # "},{"id":650,"href":"/note-cs/docs/basic/pl/assembly/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":651,"href":"/note-cs/docs/basic/pl/erlang/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":652,"href":"/note-cs/docs/basic/pl/haskell/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":653,"href":"/note-cs/docs/basic/pl/lua/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":654,"href":"/note-cs/docs/basic/pl/r/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":655,"href":"/note-cs/docs/basic/pl/ruby/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":656,"href":"/note-cs/docs/basic/pl/swift/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":657,"href":"/note-cs/docs/basic/pl/zig/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":658,"href":"/note-cs/docs/domain/cc/istio/advanced/prof/","title":"2.6 性能","section":"第二部分 进阶实战","content":" 性能 # "},{"id":659,"href":"/note-cs/docs/study/book/basic/db/","title":"5.1.6 数据库","section":"5.1 计算机基础","content":" 数据库 # "},{"id":660,"href":"/note-cs/docs/study/book/cc/","title":"5.6 云计算","section":"4.2 读书","content":" 云计算读书笔记 # "},{"id":661,"href":"/note-cs/docs/study/course/basic/db/","title":"6.1.6 数据库","section":"6.1 计算机基础","content":" 数据库 # "},{"id":662,"href":"/note-cs/docs/study/course/cc/","title":"6.6 云计算","section":"4.3 课程","content":" 云计算 # "},{"id":663,"href":"/note-cs/docs/basic/pl/cpp/","title":"C++","section":"1.5 编程语言","content":" C++ 学习笔记 # 详见：C++ 学习笔记\n"},{"id":664,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/haproxy/","title":"haproxy","section":"其他","content":" Haproxy # haproxy/haproxy HAProxy Load Balancer\u0026rsquo;s development branch (mirror of git.haproxy.org) https://git.haproxy.org/\n"},{"id":665,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/haproxy-ingress/","title":"Haproxy Ingress","section":"Ingress Controller","content":" Haproxy Ingress # jcmoraisjr/haproxy-ingress # jcmoraisjr/haproxy-ingress "},{"id":666,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/mosn/","title":"MOSN","section":"其他","content":" MOSN # mosn/mosn MOSN is a cloud native proxy for edge or service mesh. https://mosn.io\n"},{"id":667,"href":"/note-cs/docs/direction/se/design-pattern/structural/flyweight/","title":"享元","section":"架构型","content":" 享元模式 # Flyweight\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":668,"href":"/note-cs/docs/direction/se/arch/scene/release/","title":"发布形式","section":"场景","content":" 发布形式 # 参考 # "},{"id":669,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/memento/","title":"回忆","section":"行为型","content":" 回忆模式 # Memento Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":670,"href":"/note-cs/docs/direction/se/arch/scene/seckill/","title":"秒杀","section":"场景","content":" 秒杀 # 参考 # qiurunze123/miaosha # 秒杀系统设计与实现。互联网工程师进阶与分析\ncodingXiaxw/seckill # Java 高并发秒杀系统 API\nGuoZhaoran/spikeSystem # 一个秒杀系统的例子分析\nzaiyunduan123/springboot-seckill # 基于 SpringBoot + MySQL + Redis + RabbitMQ + Guava 开发的高并发商品限时秒杀系统\n前端技术 ：Bootstrap + jQuery + Thymeleaf 后端技术 ：SpringBoot + MyBatis + MySQL 中间件技术 : Druid + Redis + RabbitMQ + Guava "},{"id":671,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/chain-of-responsibility/","title":"职责链","section":"行为型","content":" 职责链模式 # Chain-of-responsibility Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":672,"href":"/note-cs/docs/direction/se/design-pattern/principle/lod/","title":"迪米特原则","section":"设计原则","content":" 迪米特原则 # 一个对象应该对其他对象有最少的了解 一个类应该对自己需要耦合或调用的类知道的越少越好，类的内部如何实现与调用者或依赖者没关系。 "},{"id":673,"href":"/note-cs/docs/direction/mp/","title":"2.7 中台","section":"第二部分 方向","content":" 中台 # "},{"id":674,"href":"/note-cs/docs/basic/pl/assembly/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":675,"href":"/note-cs/docs/basic/pl/erlang/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":676,"href":"/note-cs/docs/basic/pl/haskell/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":677,"href":"/note-cs/docs/basic/pl/lua/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":678,"href":"/note-cs/docs/basic/pl/r/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":679,"href":"/note-cs/docs/basic/pl/ruby/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":680,"href":"/note-cs/docs/basic/pl/swift/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":681,"href":"/note-cs/docs/basic/pl/zig/advanced/frame/","title":"2.7 框架","section":"第二部分 进阶实战","content":" 框架 # "},{"id":682,"href":"/note-cs/docs/domain/cc/istio/advanced/test/test/","title":"2.7 测试","section":"第二部分 进阶实战","content":" 测试 # open-policy-agent/conftest # Write tests against structured configuration data using the Open Policy Agent Rego query language\n"},{"id":683,"href":"/note-cs/docs/study/book/basic/compile/","title":"5.1.7 编译原理","section":"5.1 计算机基础","content":" 编译原理 # "},{"id":684,"href":"/note-cs/docs/study/book/bigdata/","title":"5.7 大数据","section":"4.2 读书","content":" 大数据 # "},{"id":685,"href":"/note-cs/docs/study/course/basic/compile/","title":"6.1.7 编译原理","section":"6.1 计算机基础","content":" 编译原理 # "},{"id":686,"href":"/note-cs/docs/study/course/bigdata/","title":"6.7 大数据","section":"4.3 课程","content":" 大数据 # "},{"id":687,"href":"/note-cs/docs/direction/be/db/cassandra/","title":"Cassandra","section":"2.2.1 数据库","content":" Cassandra # "},{"id":688,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/dapr/","title":"Dapr","section":"其他","content":" Dapr # Distributed Application Runtime\ndapr/dapr Dapr is a portable, serverless, event-driven runtime that makes it easy for developers to build resilient, stateless and stateful microservices that run on the cloud and edge and embraces the diversity of languages and developer frameworks.\n"},{"id":689,"href":"/note-cs/docs/basic/pl/go/","title":"Go","section":"1.5 编程语言","content":" Go 学习笔记 # 详见：Go 学习笔记\n"},{"id":690,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/tracing/lightstep/","title":"LightStep","section":"Distributed Tracing","content":" LightStep # https://lightstep.com/\nlightstep-tracer-go # lightstep/lightstep-tracer-go "},{"id":691,"href":"/note-cs/docs/direction/be/db/minio/","title":"MinIO","section":"2.2.1 数据库","content":" MinIO # MinIO 是开源 (AGPL v3.0 协议) 高性能对象存储，提供了 Amazon S3 云存储服务兼容的 API，可以用于处理非结构化数据，例如图片、视频、日志文件，备份和容器镜像。最大支持 5TB 对象。\n专注于高性能，但简化了架构 (相比较 GlusterFS 和 Ceph)，所以不支持动态扩展 (提供有限的扩展运维能力) "},{"id":692,"href":"/note-cs/docs/direction/be/db/mongodb/","title":"MongoDB","section":"2.2.1 数据库","content":" MongoDB # 教程 # 基础 # karlseguin/the-little-mongodb-book # The Little MongoDB Book 中文版\njustinyhuang/the-little-mongodb-book-cn ilivebox/the-little-mongodb-book 进阶 # "},{"id":693,"href":"/note-cs/docs/direction/se/design-pattern/structural/proxy/","title":"代理","section":"架构型","content":" 代理模式 # Proxy\npublic interface Subject { public void buyMac(); } public class RealSubject implement Subject { @Override public void buyMac() { System.out.println(\u0026#34;买一台Mac\u0026#34;); } } public class Proxy implements Subject { @Override public void buyMac { //引用并创建真实对象实例，即\u0026#34;我\u0026#34; RealSubject realSubject = new RealSubject(); //调用真实对象的方法，进行代理购买Mac realSubject.buyMac(); //代理对象额外做的操作 this.WrapMac(); } public void WrapMac() { System.out.println(\u0026#34;用盒子包装好Mac\u0026#34;); } } public class ProxyPattern { public static void main(String[] args) { Subject proxy = new Proxy(); proxy.buyMac(); } } 代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":694,"href":"/note-cs/docs/direction/se/arch/scene/","title":"场景","section":"2.1.2 架构设计","content":" 场景 # "},{"id":695,"href":"/note-cs/docs/direction/se/arch/scene/cache/","title":"缓存","section":"场景","content":" 缓存 # 热点数据集中失效问题\n设置不同的失效时间 互斥锁 缓存穿透 # 查询不存在的数据\n布隆过滤器 把这个空结果进行缓存。 缓存雪崩 # 当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到 DB 上面。结果就是 DB 称不住，挂掉。\n解决 # 事前：使用集群缓存，保证缓存服务的高可用 事中：ehcache 本地缓存 + Hystrix 限流 \u0026amp; 降级，避免 MySQL 被打死 事后：开启 Redis 持久化机制，尽快恢复缓存集群 参考：\nehcache/ehcache3 缓存击穿 # 在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个 key 正好失效了， 就会导致大量的请求都打到数据库上面去。\n缓存击穿实际上是缓存雪崩的一个特例\n解决 # 问题是多个线程同时去查询数据库的这条数据， 我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。 其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。 后面的线程进来发现已经有缓存了，就直接走缓存。\n"},{"id":696,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/observer/","title":"观察者","section":"行为型","content":" 观察者模式 # Observer Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":697,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/","title":"2.8 生态","section":"第二部分 进阶实战","content":" 生态 # SMI (Service Mesh Interface) # servicemeshinterface/smi-spec A standard interface for service meshes on Kubernetes. https://smi-spec.io/\nSMI is an abstraction layer that provides a common API surface across different service mesh technology.\nOpen Service Mesh # Open Service Mesh (OSM) is a lightweight and extensible cloud native service mesh. https://openservicemesh.io/\n"},{"id":698,"href":"/note-cs/docs/study/book/ai/","title":"5.8 人工智能","section":"4.2 读书","content":" 人工智能 # "},{"id":699,"href":"/note-cs/docs/study/course/ai/","title":"6.8 人工智能","section":"4.3 课程","content":" 人工智能 # "},{"id":700,"href":"/note-cs/docs/direction/be/mq/activemq/","title":"ActiveMQ","section":"2.2.2 消息队列","content":" ActiveMQ # apache/activemq "},{"id":701,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/bfe/","title":"BFE","section":"其他","content":" BFE # bfenetworks/bfe # "},{"id":702,"href":"/note-cs/docs/direction/be/microservices/rpc/brpc/","title":"brpc","section":"2.2.5.1 RPC","content":" brpc # "},{"id":703,"href":"/note-cs/docs/direction/be/devops/chef/","title":"Chef","section":"2.2.6 DevOps","content":" Chef # chef/chef Chef Infra, a powerful automation platform that transforms infrastructure into code automating how infrastructure is configured, deployed and managed across any environment, at any scale http://www.chef.io/chef/\n"},{"id":704,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/cilium/","title":"Cilium","section":"其他","content":" Cilium # cilium/cilium eBPF-based Networking, Security, and Observability\n"},{"id":705,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/consul/","title":"Consul","section":"其他","content":" Consul # hashicorp/consul Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure. https://www.consul.io/\n"},{"id":706,"href":"/note-cs/docs/direction/be/devops/Jenkins/","title":"Jenkins","section":"2.2.6 DevOps","content":" Jenkins # jenkinsci/jenkins Jenkins automation server https://www.jenkins.io/\n"},{"id":707,"href":"/note-cs/docs/direction/be/devops/pulumi/","title":"Pulumi","section":"2.2.6 DevOps","content":" Pulumi # pulumi/pulumi Pulumi - Modern Infrastructure as Code. Any cloud, any language https://www.pulumi.com/\n"},{"id":708,"href":"/note-cs/docs/direction/be/devops/puppet/","title":"Puppet","section":"2.2.6 DevOps","content":" Puppet # puppetlabs/puppet Server automation framework and application https://puppet.com/open-source/#osp\n"},{"id":709,"href":"/note-cs/docs/basic/pl/rust/","title":"Rust","section":"1.5 编程语言","content":" Rust # 详见：Rust 学习笔记\n"},{"id":710,"href":"/note-cs/docs/direction/be/devops/saltstack/","title":"SaltStack","section":"2.2.6 DevOps","content":" SaltStack # saltstack/salt Software to automate the management and configuration of any infrastructure or application at scale. Get access to the Salt software package repository here: https://repo.saltstack.com/\n"},{"id":711,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/traefik-mesh/","title":"Traefik Mesh","section":"其他","content":" Traefik Mesh # traefik/mesh Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure. https://www.consul.io/\n"},{"id":712,"href":"/note-cs/docs/direction/be/mq/zeromq/","title":"ZeroMQ","section":"2.2.2 消息队列","content":" ZeroMQ # zeromq/libzmq ZeroMQ 只是一个网络编程的 Pattern 库，将常见的网络请求形式（分组管理，链接管理，发布订阅等）模式化、组件化，简而言之 socket 之上、MQ 之下。对于 MQ 来说，网络传输只是它的一部分，更多需要处理的是消息存储、路由、Broker 服务发现和查找、事务、消费模式（ack、重投等）、集群服务等。\nbrokerless # The philosophy of ZeroMQ starts with the zero. The zero is for zero broker (ZeroMQ is brokerless), zero latency, zero cost (it’s free), and zero administration.\n这里的 broker 指的是 “消息中间件 / 消息代理服务器”—— 一个位于通信两端之间的独立服务端组件，负责：\n接收客户端的消息并转发 / 路由到目标（队列、主题、订阅者等） 维护队列 / 主题、连接、订阅关系 处理持久化、确认、重试、鉴权、限流等 像 RabbitMQ、ActiveMQ、Kafka（更像分布式日志，但也充当代理）都属于有 broker 的体系。\nZeroMQ 说 “zero broker / brokerless”，意思是：\n没有必须依赖的中心化代理服务器；应用进程之间可以端到端直连通信。 路由/模式由库和你的程序来决定（REQ/REP、PUB/SUB、PUSH/PULL 等），你也可以用它搭一个可选的 “代理/路由器”，但不是必需。 优缺点一眼看懂：\n✅ 更少的网络跳数与开销、运维简单、低延迟。 ⚠️ 需要你自己处理服务发现、故障恢复、消息持久化、背压等，复杂需求时往往还是会引入自建的代理 / 网关来补齐能力。 "},{"id":713,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/state/","title":"状态机","section":"行为型","content":" 状态机模式 # State Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":714,"href":"/note-cs/docs/direction/be/auth/","title":"认证与授权","section":"2.2 后端","content":" 认证与授权 # "},{"id":715,"href":"/note-cs/docs/basic/pl/zig/design/code/","title":"3.7 源码分析","section":"第三部分 设计与实现","content":" 源码分析 # "},{"id":716,"href":"/note-cs/docs/domain/cc/istio/code/source/","title":"3.7 源码分析","section":"第三部分 设计与实现","content":" 源码分析 # "},{"id":717,"href":"/note-cs/docs/study/book/others/","title":"5.9 其他","section":"4.2 读书","content":" 其他 # "},{"id":718,"href":"/note-cs/docs/study/course/others/","title":"6.9 其他","section":"4.3 课程","content":" 其他 # "},{"id":719,"href":"/note-cs/docs/direction/fe/frame/jquery/","title":"Jquery","section":"2.2.3 框架","content":" Jquery # "},{"id":720,"href":"/note-cs/docs/basic/pl/kotlin/","title":"Kotlin","section":"1.5 编程语言","content":" Kotlin 学习笔记 # 详见：Kotlin 学习笔记\n"},{"id":721,"href":"/note-cs/docs/direction/be/microservices/rpc/motan/","title":"Motan","section":"2.2.5.1 RPC","content":" Motan # 微博内部使用的 RPC 框架，于 2016 年对外开源，仅支持 Java 语言。\n"},{"id":722,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/ingress/kubernetes-ingress/","title":"nginxinc/kubernetes-ingress","section":"Ingress Controller","content":" NGINX Ingress Controller # nginxinc/kubernetes-ingress NGINX and NGINX Plus Ingress Controllers for Kubernetes https://docs.nginx.com/nginx-ingress-controller/\nnginxinc/kubernetes-ingress vs kubernetes/ingress-nginx # 参考：\nDifferences Between nginxinc/kubernetes-ingress and kubernetes/ingress-nginx Ingress Controllers "},{"id":723,"href":"/note-cs/docs/direction/be/microservices/rpc/tars/","title":"Tars","section":"2.2.5.1 RPC","content":" Tars # Total Application Framework\nTarsCloud/Tars 腾讯内部使用的 RPC 框架，于 2017 年对外开源。\n目前支持 C++, Java 和 NodeJs 三种语言。\n"},{"id":724,"href":"/note-cs/docs/direction/be/microservices/rpc/thrift/","title":"Thrift","section":"2.2.5.1 RPC","content":" Thrift # 最初是由 Facebook 开发的内部系统跨语言的 RPC 框架，2007 年贡献给了 Apache 基金，成为 Apache 开源项目之一，支持多种语言。\n"},{"id":725,"href":"/note-cs/docs/direction/be/web/","title":"Web Service","section":"2.2 后端","content":" Web Service # 教程 # What happens when... # alex/what-happens-when An attempt to answer the age old interview question \u0026ldquo;What happens when you type google.com into your browser and press enter?\u0026rdquo;\nskyline75489/what-happens-when-zh_CN 这个仓库试图回答一个古老的面试问题：当你在浏览器中输入 google.com 并且按下回车之后发生了什么？\nkamranahmedse/developer-roadmap # Roadmap to becoming a web developer in 2021\n"},{"id":726,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/","title":"其他","section":"2.8 生态","content":" 其他 # "},{"id":727,"href":"/note-cs/docs/direction/se/design-pattern/other/","title":"其他模式","section":"2.1.1 设计模式","content":" 其他模式 # "},{"id":728,"href":"/note-cs/docs/direction/be/platform/","title":"平台","section":"2.2 后端","content":" 平台 # "},{"id":729,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/strategy/","title":"策略","section":"行为型","content":" 策略模式 # Strategy Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":730,"href":"/note-cs/docs/tool/macos/dotnet/","title":".NET","section":"4.1 MacOS","content":" .NET # .NET 8.0 SDK (v8.0.100) - macOS Arm64 Installer!\n# 安装 .NET SDK brew install --cask dotnet-sdk "},{"id":731,"href":"/note-cs/docs/tool/linux/ubuntu/ab/","title":"ab","section":"4.2.1 Ubuntu","content":" ab # apt install apache2-utils -y # -c 10 表示并发用户数为10 # -n 100 表示请求总数为100 ab -c 10 -n 100 http://localhost:8080 # This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1879490 $\u0026gt; # Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ # Licensed to The Apache Software Foundation, http://www.apache.org/ # Benchmarking localhost (be patient) # Completed 100 requests # Completed 200 requests # Completed 300 requests # Completed 400 requests # Completed 500 requests # Completed 600 requests # Completed 700 requests # Completed 800 requests # Completed 900 requests # Completed 1000 requests # Finished 1000 requests # Server Software: # Server Hostname: localhost # Server Port: 8080 # Document Path: / # Document Length: 12 bytes # Concurrency Level: 100 # Time taken for tests: 0.090 seconds # Complete requests: 1000 # Failed requests: 0 # Total transferred: 174000 bytes # HTML transferred: 12000 bytes # Requests per second: 11112.84 [#/sec] (mean) # Time per request: 8.999 [ms] (mean) # Time per request: 0.090 [ms] (mean, across all concurrent requests) # Transfer rate: 1888.31 [Kbytes/sec] received # Connection Times (ms) # min mean[+/-sd] median max # Connect: 0 3 1.0 3 6 # Processing: 1 5 5.3 4 24 # Waiting: 0 4 5.5 2 22 # Total: 5 9 5.0 7 26 # Percentage of the requests served within a certain time (ms) # 50% 7 # 66% 7 # 75% 8 # 80% 8 # 90% 22 # 95% 23 # 98% 25 # 99% 25 # 100% 26 (longest request) "},{"id":732,"href":"/note-cs/docs/tool/macos/adb/","title":"adb","section":"4.1 MacOS","content":" adb # 安装 # brew install android-platform-tools 教程 # # 启动 adb devices "},{"id":733,"href":"/note-cs/docs/tool/linux/ubuntu/ansible/","title":"Ansible","section":"4.2.1 Ubuntu","content":" Ansible # 安装 # # pipx 安装 pipx install --include-deps ansible # 升级 pipx upgrade --include-injected ansible # apt 安装 sudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible 参考：Installing Ansible on Ubuntu\n"},{"id":734,"href":"/note-cs/docs/tool/linux/ubuntu/apt/","title":"apt","section":"4.2.1 Ubuntu","content":" apt # apt vs apt-get # Advanced Package Tool，又名 apt-get，是一款适用于 Unix 和 Linux 系统的应用程序管理器\napt 可以看作 apt-get 和 apt-cache 命令的子集, 可以为包管理提供必要的命令选项 可以用 apt 替换部分 apt-get 系列命令，但不是全部 对于低级操作，仍然需要 apt-get 作为普通用户，可以首先使用 apt apt 命令 取代的命令 命令的功能 apt install apt-get install 安装软件包 apt remove apt-get remove 移除软件包 apt purge apt-get purge 移除软件包及配置文件 apt update apt-get update 刷新存储库索引 apt upgrade apt-get upgrade 升级所有可升级的软件包 apt autoremove apt-get autoremove 自动删除不需要的包 apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系 apt search apt-cache search 搜索应用程序 apt show apt-cache show 显示装细节 apt 还有一些自己的命令\napt update 命令不仅更新存储库索引，还告知存储库中是否可用软件以及有多少新版本可用 apt list: 列出包含条件的包（已安装，可升级等） apt edit-sources: 编辑源列表 "},{"id":735,"href":"/note-cs/docs/study/skill/type/asciidoc/","title":"AsciiDoc","section":"文档类型","content":" AsciiDoc # 表格内无序列表 # | 前面加个 a\n参考：\nFormat Content by Cell 教程 # AsciiDoc 指引 "},{"id":736,"href":"/note-cs/docs/tool/macos/axure/","title":"Axure","section":"4.1 MacOS","content":" Axure RP # Rapid Prototyping 快速原型\n快捷键 # cmd + D: 副本 cmd + R: 替换 "},{"id":737,"href":"/note-cs/docs/tool/macos/bmad/","title":"bmad","section":"4.1 MacOS","content":" bmad # "},{"id":738,"href":"/note-cs/docs/tool/macos/csharp/","title":"C#","section":"4.1 MacOS","content":" C# # 使用 Visual Studio Code 写 C# 程序 # C# Dev Kit # C# Dev Kit helps you manage your code with a solution explorer and test your code with integrated unit test discovery and execution, elevating your C# development experience wherever you like to develop (Windows, macOS, Linux, and even in a Codespace).\nThis extension builds on top of the great C# language capabilities provided by the C# extension, 即 vscode-csharp and enhances your C# environment by adding a set of powerful tools and utilities that integrate natively with VS Code to help C# developers write, debug, and maintain their code faster and with fewer errors. Some of this new tooling includes but is not limited to:\nC# project and solution management via an integrated solution explorer Native testing environment to run and debug tests using the Test Explorer Roslyn powered language service for best in-class C# language features such as code navigation, refactoring, semantic awareness, and more AI-Assisted development vscode-csharp # 安装 C# Dev Kit 会自动安装 vscode-csharp\ndotnet/vscode-csharp "},{"id":739,"href":"/note-cs/docs/tool/macos/capslock/","title":"Capslock","section":"4.1 MacOS","content":" Capslock # Vonng/Capslock 让 Capslock 再次伟大！\n"},{"id":740,"href":"/note-cs/docs/tool/linux/ubuntu/cargo/","title":"Cargo","section":"4.2.1 Ubuntu","content":" Cargo # 常用命令 # 安装配置 # curl https://sh.rustup.rs -sSf | sh\n参考：\nThe Cargo Book "},{"id":741,"href":"/note-cs/docs/tool/macos/conda/","title":"conda","section":"4.1 MacOS","content":" conda # mkdir -p ~/miniconda3 curl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh -o ~/miniconda3/miniconda.sh bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 rm -rf ~/miniconda3/miniconda.sh ~/miniconda3/bin/conda init bash ~/miniconda3/bin/conda init zsh 基础用法 # conda create --name d2l python=3.12 -y # 查看已创建的conda环境 conda info --envs # 激活环境 conda activate base # 退出环境 conda deactivate # 取消默认激活 conda config --set auto_activate_base false # conda config --show | grep auto_activate_base "},{"id":742,"href":"/note-cs/docs/tool/linux/centos/conda/","title":"Conda","section":"4.2.2 CentOS","content":" Conda # conda 是一款软件管理软件，相当于 windows 里面的应用商店 miniconda 和 anaconda 中都包含了 conda miniconda windows 64 位安装包大小为 51.4 Mb，只包含了 conda、python、和一些必备的软件工具 anaconda windows 64 位安装包大小为 462 Mb，是 miniconda 的扩展，包含了数据科学和机器学习要用到的很多软件。 安装 # wget -c --no-check-certificate https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh 参考：https://docs.conda.io/projects/conda/en/stable/\n使用教程 # # 清理缓存 conda clean -a # The base environment is activated by default conda config --set auto_activate_base True # The base environment is not activated by default conda config --set auto_activate_base False # 查看已创建的conda环境 conda info --envs # 激活环境 conda activate base # 退出环境 conda deactivate 镜像源 # 阿里云 # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - http://mirrors.aliyun.com/anaconda/pkgs/main - http://mirrors.aliyun.com/anaconda/pkgs/r - http://mirrors.aliyun.com/anaconda/pkgs/msys2 custom_channels: conda-forge: http://mirrors.aliyun.com/anaconda/cloud msys2: http://mirrors.aliyun.com/anaconda/cloud bioconda: http://mirrors.aliyun.com/anaconda/cloud menpo: http://mirrors.aliyun.com/anaconda/cloud pytorch: http://mirrors.aliyun.com/anaconda/cloud simpleitk: http://mirrors.aliyun.com/anaconda/cloud EOF conda clean -i 清华 TUNA # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud EOF conda clean -i 北京外国语 # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - https://mirrors.bfsu.edu.cn/anaconda/pkgs/main - https://mirrors.bfsu.edu.cn/anaconda/pkgs/r - https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.bfsu.edu.cn/anaconda/cloud msys2: https://mirrors.bfsu.edu.cn/anaconda/cloud bioconda: https://mirrors.bfsu.edu.cn/anaconda/cloud menpo: https://mirrors.bfsu.edu.cn/anaconda/cloud pytorch: https://mirrors.bfsu.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.bfsu.edu.cn/anaconda/cloud simpleitk: https://mirrors.bfsu.edu.cn/anaconda/cloud EOF conda clean -i conda vs pip # pip 是用来安装 python 包的，安装的是 python wheel 或者源代码的包。从源码安装的时候需要有编译器的支持，pip 也不会去支持 python 语言之外的依赖项。 conda 是用来安装 conda package，虽然大部分 conda 包是 python 的，但它支持了不少非 python 语言写的依赖项，比如 mkl cuda 这种 c c++写的包。conda 安装的都是编译好的二进制包，不需要你自己编译。这导致了 conda 装东西的体积一般比较大，尤其是 mkl 这种，动不动几百兆甚至一 G 多。 所以，pip 有时候系统环境没有某个编译器可能会失败，conda 不会。 conda 比 pip 更加严格，conda 会检查当前环境下所有包之间的依赖关系，pip 可能对之前安装的包就不管了。这样做的话，conda 基本上安上了就能保证工作，pip 有时候可能装上了也不 work。 conda 算依赖项的时间比 pip 多很多，而且重新安装的包也会更多（会选择更新旧包的版本） conda install vs pip install # conda install xxx：这种方式安装的库都会放在 anaconda3/pkgs 目录下，\n这样的好处就是，当在某个环境下已经下载好了某个库，再在另一个环境中还需要这个库时，就可以直接从 pkgs 目录下将该库复制至新环境而不用重复下载。 pip install xxx：分两种情况，\n一种情况就是当前 conda 环境的 python 是 conda 安装的，和系统的不一样，那么 xxx 会被安装到 anaconda3/envs/current_env/lib/python3.x/site-packages 文件夹中， 如果当前 conda 环境用的是系统的 python，那么 xxx 会通常会被安装到 ~/.local/lib/python3.x/site-packages 文件夹中 conda 和 pip 安装同一个 xxx 库情况下，conda 环境下 python 代码中 import xxx 时，谁安装的 xxx 优先级较高会被 import，这个问题通过下面这条命令可以解决：\npython -m site # 输出 sys.path = [ \u0026#39;/root/anaconda3\u0026#39;, \u0026#39;/root/anaconda3/lib/python39.zip\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9/lib-dynload\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9/site-packages\u0026#39;, ] USER_BASE: \u0026#39;/root/.local\u0026#39; (exists) USER_SITE: \u0026#39;/root/.local/lib/python3.9/site-packages\u0026#39; (doesn\u0026#39;t exist) ENABLE_USER_SITE: True # USER_BASE 和 USER_SITE 是用户自定义的启用Python脚本和依赖安装包的基础路径 Miniconda vs Miniforge # Miniconda 是 Conda 的一个极简版本，只包含 Conda 包管理器及其依赖项。 默认源: Miniconda 使用默认的 Anaconda 仓库。 Miniforge 是一个社区驱动的 Conda 发行版，旨在提供一个免费的、开源的包管理和环境管理工具。 适用场景: Miniforge 更加适合那些希望使用完全开源的软件包（避免 Anaconda 商业仓库的限制）或需要特定的社区包的用户。 默认源: Miniforge 使用 conda-forge 仓库，conda-forge 是一个社区维护的包仓库，提供大量的开源包。 Miniforge 通常会预装一些基础包以简化常见的环境配置。 可以在同一台机器同时使用 Miniconda 和 Miniforge # # 切换到 Miniconda source /root/miniconda3/bin/activate # 使用 Miniconda 环境 conda activate my_miniconda_env # 进行一些操作 # 切换到 Miniforge conda deactivate source /root/miniforge3/bin/activate # 使用 Miniforge 环境 conda activate my_miniforge_env # 进行其他操作 "},{"id":743,"href":"/note-cs/docs/tool/linux/ubuntu/conda/","title":"Conda","section":"4.2.1 Ubuntu","content":" Conda # conda 是一款软件管理软件，相当于 windows 里面的应用商店 miniconda 和 anaconda 中都包含了 conda miniconda windows 64 位安装包大小为 51.4 Mb，只包含了 conda、python、和一些必备的软件工具 anaconda windows 64 位安装包大小为 462 Mb，是 miniconda 的扩展，包含了数据科学和机器学习要用到的很多软件。 安装 # wget -c --no-check-certificate https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh 参考：https://docs.conda.io/projects/conda/en/stable/\n使用教程 # # 清理缓存 conda clean -a # The base environment is activated by default conda config --set auto_activate_base True # The base environment is not activated by default conda config --set auto_activate_base False # 查看已创建的conda环境 conda info --envs # 激活环境 conda activate base # 退出环境 conda deactivate 镜像源 # 阿里云 # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - http://mirrors.aliyun.com/anaconda/pkgs/main - http://mirrors.aliyun.com/anaconda/pkgs/r - http://mirrors.aliyun.com/anaconda/pkgs/msys2 custom_channels: conda-forge: http://mirrors.aliyun.com/anaconda/cloud msys2: http://mirrors.aliyun.com/anaconda/cloud bioconda: http://mirrors.aliyun.com/anaconda/cloud menpo: http://mirrors.aliyun.com/anaconda/cloud pytorch: http://mirrors.aliyun.com/anaconda/cloud simpleitk: http://mirrors.aliyun.com/anaconda/cloud EOF conda clean -i 清华 TUNA # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud EOF conda clean -i 北京外国语 # cat \u0026lt;\u0026lt; EOF \u0026gt; ~/.condarc channels: - defaults show_channel_urls: true default_channels: - https://mirrors.bfsu.edu.cn/anaconda/pkgs/main - https://mirrors.bfsu.edu.cn/anaconda/pkgs/r - https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.bfsu.edu.cn/anaconda/cloud msys2: https://mirrors.bfsu.edu.cn/anaconda/cloud bioconda: https://mirrors.bfsu.edu.cn/anaconda/cloud menpo: https://mirrors.bfsu.edu.cn/anaconda/cloud pytorch: https://mirrors.bfsu.edu.cn/anaconda/cloud pytorch-lts: https://mirrors.bfsu.edu.cn/anaconda/cloud simpleitk: https://mirrors.bfsu.edu.cn/anaconda/cloud EOF conda clean -i conda vs pip # pip 是用来安装 python 包的，安装的是 python wheel 或者源代码的包。从源码安装的时候需要有编译器的支持，pip 也不会去支持 python 语言之外的依赖项。 conda 是用来安装 conda package，虽然大部分 conda 包是 python 的，但它支持了不少非 python 语言写的依赖项，比如 mkl cuda 这种 c c++写的包。conda 安装的都是编译好的二进制包，不需要你自己编译。这导致了 conda 装东西的体积一般比较大，尤其是 mkl 这种，动不动几百兆甚至一 G 多。 所以，pip 有时候系统环境没有某个编译器可能会失败，conda 不会。 conda 比 pip 更加严格，conda 会检查当前环境下所有包之间的依赖关系，pip 可能对之前安装的包就不管了。这样做的话，conda 基本上安上了就能保证工作，pip 有时候可能装上了也不 work。 conda 算依赖项的时间比 pip 多很多，而且重新安装的包也会更多（会选择更新旧包的版本） conda install vs pip install # conda install xxx：这种方式安装的库都会放在 anaconda3/pkgs 目录下，\n这样的好处就是，当在某个环境下已经下载好了某个库，再在另一个环境中还需要这个库时，就可以直接从 pkgs 目录下将该库复制至新环境而不用重复下载。 pip install xxx：分两种情况，\n一种情况就是当前 conda 环境的 python 是 conda 安装的，和系统的不一样，那么 xxx 会被安装到 anaconda3/envs/current_env/lib/python3.x/site-packages 文件夹中， 如果当前 conda 环境用的是系统的 python，那么 xxx 会通常会被安装到 ~/.local/lib/python3.x/site-packages 文件夹中 conda 和 pip 安装同一个 xxx 库情况下，conda 环境下 python 代码中 import xxx 时，谁安装的 xxx 优先级较高会被 import，这个问题通过下面这条命令可以解决：\npython -m site # 输出 sys.path = [ \u0026#39;/root/anaconda3\u0026#39;, \u0026#39;/root/anaconda3/lib/python39.zip\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9/lib-dynload\u0026#39;, \u0026#39;/root/anaconda3/lib/python3.9/site-packages\u0026#39;, ] USER_BASE: \u0026#39;/root/.local\u0026#39; (exists) USER_SITE: \u0026#39;/root/.local/lib/python3.9/site-packages\u0026#39; (doesn\u0026#39;t exist) ENABLE_USER_SITE: True # USER_BASE 和 USER_SITE 是用户自定义的启用Python脚本和依赖安装包的基础路径 Miniconda vs Miniforge # Miniconda 是 Conda 的一个极简版本，只包含 Conda 包管理器及其依赖项。 默认源: Miniconda 使用默认的 Anaconda 仓库。 Miniforge 是一个社区驱动的 Conda 发行版，旨在提供一个免费的、开源的包管理和环境管理工具。 适用场景: Miniforge 更加适合那些希望使用完全开源的软件包（避免 Anaconda 商业仓库的限制）或需要特定的社区包的用户。 默认源: Miniforge 使用 conda-forge 仓库，conda-forge 是一个社区维护的包仓库，提供大量的开源包。 Miniforge 通常会预装一些基础包以简化常见的环境配置。 可以在同一台机器同时使用 Miniconda 和 Miniforge # # 切换到 Miniconda source /root/miniconda3/bin/activate # 使用 Miniconda 环境 conda activate my_miniconda_env # 进行一些操作 # 切换到 Miniforge conda deactivate source /root/miniforge3/bin/activate # 使用 Miniforge 环境 conda activate my_miniforge_env # 进行其他操作 "},{"id":744,"href":"/note-cs/docs/tool/linux/ubuntu/containerd/","title":"Containerd","section":"4.2.1 Ubuntu","content":" Containerd # # 生成一个默认的配置 mkdir /etc/containerd containerd config default \u0026gt; /etc/containerd/config.toml 配置 # disabled_plugins = [] imports = [] oom_score = 0 plugin_dir = \u0026#34;\u0026#34; required_plugins = [] root = \u0026#34;/var/lib/containerd\u0026#34; state = \u0026#34;/run/containerd\u0026#34; temp = \u0026#34;\u0026#34; version = 2 [cgroup] path = \u0026#34;\u0026#34; [debug] address = \u0026#34;\u0026#34; format = \u0026#34;\u0026#34; gid = 0 level = \u0026#34;\u0026#34; uid = 0 [grpc] address = \u0026#34;/run/containerd/containerd.sock\u0026#34; gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 tcp_address = \u0026#34;\u0026#34; tcp_tls_ca = \u0026#34;\u0026#34; tcp_tls_cert = \u0026#34;\u0026#34; tcp_tls_key = \u0026#34;\u0026#34; uid = 0 [metrics] address = \u0026#34;\u0026#34; grpc_histogram = false [plugins] [plugins.\u0026#34;io.containerd.gc.v1.scheduler\u0026#34;] deletion_threshold = 0 mutation_threshold = 100 pause_threshold = 0.02 schedule_delay = \u0026#34;0s\u0026#34; startup_delay = \u0026#34;100ms\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;] device_ownership_from_security_context = false disable_apparmor = false disable_cgroup = false disable_hugetlb_controller = true disable_proc_mount = false disable_tcp_service = true enable_selinux = false enable_tls_streaming = false enable_unprivileged_icmp = false enable_unprivileged_ports = false ignore_image_defined_volumes = false max_concurrent_downloads = 3 max_container_log_line_size = 16384 netns_mounts_under_state_dir = false restrict_oom_score_adj = false sandbox_image = \u0026#34;registry.k8s.io/pause:3.6\u0026#34; selinux_category_range = 1024 stats_collect_period = 10 stream_idle_timeout = \u0026#34;4h0m0s\u0026#34; stream_server_address = \u0026#34;127.0.0.1\u0026#34; stream_server_port = \u0026#34;0\u0026#34; systemd_cgroup = false tolerate_missing_hugetlb_controller = true unset_seccomp_profile = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.cni] bin_dir = \u0026#34;/opt/cni/bin\u0026#34; conf_dir = \u0026#34;/etc/cni/net.d\u0026#34; conf_template = \u0026#34;\u0026#34; ip_pref = \u0026#34;\u0026#34; max_conf_num = 1 [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd] default_runtime_name = \u0026#34;runc\u0026#34; disable_snapshot_annotations = true discard_unpacked_layers = false ignore_rdt_not_enabled_errors = false no_pivot = false snapshotter = \u0026#34;overlayfs\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.default_runtime] base_runtime_spec = \u0026#34;\u0026#34; cni_conf_dir = \u0026#34;\u0026#34; cni_max_conf_num = 0 container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = \u0026#34;\u0026#34; runtime_path = \u0026#34;\u0026#34; runtime_root = \u0026#34;\u0026#34; runtime_type = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.default_runtime.options] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc] base_runtime_spec = \u0026#34;\u0026#34; cni_conf_dir = \u0026#34;\u0026#34; cni_max_conf_num = 0 container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = \u0026#34;\u0026#34; runtime_path = \u0026#34;\u0026#34; runtime_root = \u0026#34;\u0026#34; runtime_type = \u0026#34;io.containerd.runc.v2\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.runtimes.runc.options] BinaryName = \u0026#34;\u0026#34; CriuImagePath = \u0026#34;\u0026#34; CriuPath = \u0026#34;\u0026#34; CriuWorkPath = \u0026#34;\u0026#34; IoGid = 0 IoUid = 0 NoNewKeyring = false NoPivotRoot = false Root = \u0026#34;\u0026#34; ShimCgroup = \u0026#34;\u0026#34; SystemdCgroup = false [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.untrusted_workload_runtime] base_runtime_spec = \u0026#34;\u0026#34; cni_conf_dir = \u0026#34;\u0026#34; cni_max_conf_num = 0 container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = \u0026#34;\u0026#34; runtime_path = \u0026#34;\u0026#34; runtime_root = \u0026#34;\u0026#34; runtime_type = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.containerd.untrusted_workload_runtime.options] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.image_decryption] key_model = \u0026#34;node\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] config_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.auths] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.configs] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.headers] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [\u0026#34;https://registry.aliyuncs.com\u0026#34;,\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;,\u0026#34;https://registry-1.docker.io\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;registry.k8s.io\u0026#34;] endpoint = [\u0026#34;https://gcr.mirrors.ustc.edu.cn/google-containers/\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;k8s.gcr.io\u0026#34;] endpoint = [\u0026#34;https://gcr.mirrors.ustc.edu.cn/google-containers/\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;gcr.io\u0026#34;] endpoint = [\u0026#34;https://gcr.mirrors.ustc.edu.cn\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;quay.io\u0026#34;] endpoint = [\u0026#34;https://quay.mirrors.ustc.edu.cn\u0026#34;] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.x509_key_pair_streaming] tls_cert_file = \u0026#34;\u0026#34; tls_key_file = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.internal.v1.opt\u0026#34;] path = \u0026#34;/opt/containerd\u0026#34; [plugins.\u0026#34;io.containerd.internal.v1.restart\u0026#34;] interval = \u0026#34;10s\u0026#34; [plugins.\u0026#34;io.containerd.internal.v1.tracing\u0026#34;] sampling_ratio = 1.0 service_name = \u0026#34;containerd\u0026#34; [plugins.\u0026#34;io.containerd.metadata.v1.bolt\u0026#34;] content_sharing_policy = \u0026#34;shared\u0026#34; [plugins.\u0026#34;io.containerd.monitor.v1.cgroups\u0026#34;] no_prometheus = false [plugins.\u0026#34;io.containerd.runtime.v1.linux\u0026#34;] no_shim = false runtime = \u0026#34;runc\u0026#34; runtime_root = \u0026#34;\u0026#34; shim = \u0026#34;containerd-shim\u0026#34; shim_debug = false [plugins.\u0026#34;io.containerd.runtime.v2.task\u0026#34;] platforms = [\u0026#34;linux/amd64\u0026#34;] sched_core = false [plugins.\u0026#34;io.containerd.service.v1.diff-service\u0026#34;] default = [\u0026#34;walking\u0026#34;] [plugins.\u0026#34;io.containerd.service.v1.tasks-service\u0026#34;] rdt_config_file = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.snapshotter.v1.aufs\u0026#34;] root_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.snapshotter.v1.btrfs\u0026#34;] root_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.snapshotter.v1.devmapper\u0026#34;] async_remove = false base_image_size = \u0026#34;\u0026#34; discard_blocks = false fs_options = \u0026#34;\u0026#34; fs_type = \u0026#34;\u0026#34; pool_name = \u0026#34;\u0026#34; root_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.snapshotter.v1.native\u0026#34;] root_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.snapshotter.v1.overlayfs\u0026#34;] root_path = \u0026#34;\u0026#34; upperdir_label = false [plugins.\u0026#34;io.containerd.snapshotter.v1.zfs\u0026#34;] root_path = \u0026#34;\u0026#34; [plugins.\u0026#34;io.containerd.tracing.processor.v1.otlp\u0026#34;] endpoint = \u0026#34;\u0026#34; insecure = false protocol = \u0026#34;\u0026#34; [proxy_plugins] [stream_processors] [stream_processors.\u0026#34;io.containerd.ocicrypt.decoder.v1.tar\u0026#34;] accepts = [\u0026#34;application/vnd.oci.image.layer.v1.tar+encrypted\u0026#34;] args = [\u0026#34;--decryption-keys-path\u0026#34;, \u0026#34;/etc/containerd/ocicrypt/keys\u0026#34;] env = [\u0026#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf\u0026#34;] path = \u0026#34;ctd-decoder\u0026#34; returns = \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34; [stream_processors.\u0026#34;io.containerd.ocicrypt.decoder.v1.tar.gzip\u0026#34;] accepts = [\u0026#34;application/vnd.oci.image.layer.v1.tar+gzip+encrypted\u0026#34;] args = [\u0026#34;--decryption-keys-path\u0026#34;, \u0026#34;/etc/containerd/ocicrypt/keys\u0026#34;] env = [\u0026#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf\u0026#34;] path = \u0026#34;ctd-decoder\u0026#34; returns = \u0026#34;application/vnd.oci.image.layer.v1.tar+gzip\u0026#34; 1 disabled_plugins = [] 2 imports = [] 3 oom_score = 0 4 plugin_dir = \u0026#34;\u0026#34; 5 required_plugins = [] 6 root = \u0026#34;/var/lib/containerd\u0026#34; 7 state = \u0026#34;/run/containerd\u0026#34; 8 temp = \u0026#34;\u0026#34; 9 version = 2 10 11 [cgroup] 12 path = \u0026#34;\u0026#34; 13 14 [debug] 15 address = \u0026#34;\u0026#34; :set nu [timeouts] \u0026#34;io.containerd.timeout.bolt.open\u0026#34; = \u0026#34;0s\u0026#34; \u0026#34;io.containerd.timeout.shim.cleanup\u0026#34; = \u0026#34;5s\u0026#34; \u0026#34;io.containerd.timeout.shim.load\u0026#34; = \u0026#34;5s\u0026#34; \u0026#34;io.containerd.timeout.shim.shutdown\u0026#34; = \u0026#34;3s\u0026#34; \u0026#34;io.containerd.timeout.task.state\u0026#34; = \u0026#34;2s\u0026#34; [ttrpc] address = \u0026#34;\u0026#34; gid = 0 uid = 0 "},{"id":745,"href":"/note-cs/docs/basic/cc/cpu/","title":"CPU","section":"1.1 计算机组成原理","content":" CPU # 参考：\n史上最全桌面级 CPU 天梯图 "},{"id":746,"href":"/note-cs/docs/tool/linux/ubuntu/crictl/","title":"crictl","section":"4.2.1 Ubuntu","content":" crictl # crictl 是 CRI 兼容的容器运行时命令行接口，用来检查和调试 Kubernetes 节点上的容器运行时和应用程序 kubernetes-sigs/cri-tools - crictl 不支持改镜像 tag - crictl 不支持 load 镜像文件 - 需要用 ctr ```shell # namespace 为 k8s.io ctr -n=k8s.io image pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 ctr -n=k8s.io image tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 registry.k8s.io/pause:3.6 ``` 参考： - [Crictl not support load images?](https://github.com/kubernetes-sigs/cri-tools/issues/546) - [Manually Loading Container Images with containerD](https://blog.scottlowe.org/2020/01/25/manually-loading-container-images-with-containerd/) 安装 # VERSION=\u0026#34;v1.26.0\u0026#34; wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin # rm -f crictl-$VERSION-linux-amd64.tar.gz # 默认是使用 docker # 配置使用 containerd cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/crictl.yaml runtime-endpoint: unix:///run/containerd/containerd.sock image-endpoint: unix:///run/containerd/containerd.sock timeout: 10 EOF 使用 # crictl image ls crictl ps -a "},{"id":747,"href":"/note-cs/docs/tool/linux/ubuntu/ctr/","title":"ctr","section":"4.2.1 Ubuntu","content":" ctr # ctr 是 containerd 自带的 CLI 命令行工具 - ctr image pull 的镜像，namespace 必须是 k8s.io，containerd 才能使用（`crictl image` 才能看到） - ctr -n k8s.io image list - ctr -n k8s.io image pull # namespace ctr ns ls # 删除镜像 ctr -n k8s.io i rm $(ctr -n k8s.io i ls -q) # 删除容器 ctr -n k8s.io c rm $(ctr -n k8s.io c ls -q) ctr -n k8s.io image pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 # tag 重命名 ctr -n k8s.io image tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 registry.k8s.io/pause:3.6 # 导出镜像 ctr -n k8s.io image export pause3.6.tar registry.k8s.io/pause:3.6 # --base-name 重命名 ctr -n k8s.io image import --base-name registry.k8s.io/pause-self-define:3.6 pause3.6.tar "},{"id":748,"href":"/note-cs/docs/tool/linux/centos/cuda/","title":"cuda","section":"4.2.2 CentOS","content":" cuda # 安装 # # centos 7 安装 cuda 12.1 wget -c https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-rhel7-12-1-local-12.1.0_530.30.02-1.x86_64.rpm sudo rpm -i cuda-repo-rhel7-12-1-local-12.1.0_530.30.02-1.x86_64.rpm sudo yum clean all sudo yum -y install nvidia-driver-latest-dkms sudo yum -y install cuda # 参考：https://developer.nvidia.com/cuda-12-1-0-download-archive?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=RHEL\u0026amp;target_version=7\u0026amp;target_type=rpm_local "},{"id":749,"href":"/note-cs/docs/basic/cc/gpu/cuda/","title":"CUDA","section":"GPU","content":" CUDA # Compute Unified Device Architecture\n统一计算架构 nvcc -V 显示的当前安装的 cuda 版本\nnvcc: NVIDIA (R) Cuda compiler driver 我们常说的 cuda 指的是 nvidia cuda toolkit 软件开发包，而不是 GPU 驱动\ncuda 版本也即 CUDA 工具包的版本，而不是显卡驱动版本 cuda 每个版本都对应一个最低版本的显卡驱动程序\ncuda 程序是向后兼容的，针对特定版本的 CUDA 编译的应用程序将继续在后续驱动程序版本上工作\ncuda 可以是旧的，驱动可以是更新的 最新 nvidia 驱动版本支持所有版本的 CUDA GPU 核心和 CUDA 核心通常指的是同一个概念。在 NVIDIA 的术语中，CUDA 核心是 GPU 上的处理单元，负责执行计算任务。\n只有一半的 CUDA 能支持整数计算\n在 CUDA 核心（CUDA Core）的右边，是 TenSor 核心 (Tensor Core) Tensor Cores 是 NVIDIA 在其 Volta 和后续架构中引入的另一种专用计算核心，主要用于加速深度学习和机器学习中的张量运算 nvidia driver 和 cuda toolkit 版本兼容性 # CUDA Toolkit runtime, libraries, tools Nvidia Display Driver Package CUDA user-mode driver (libcuda.so) GPU kernel-mode driver (nvidia.ko) 参考：CUDA Compatibility\n安装 # # ubuntu 20.04, x86_64 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb sudo dpkg -i cuda-keyring_1.0-1_all.deb sudo apt-get update sudo apt-get -y install cuda 参考：\nCUDA Toolkit Downloads apt install linux-headers-$(uname -r) 升级 cuda # wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub sudo add-apt-repository \u0026#34;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\u0026#34; wget https://developer.download.nvidia.com/compute/cuda/12.0.0/local_installers/cuda-repo-ubuntu2004-12-0-local_12.0.0-525.60.13-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2004-12-0-local_12.0.0-525.60.13-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2004-12-0-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda 22.04 # # https://developer.nvidia.com/cuda-downloads?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=Ubuntu\u0026amp;target_version=22.04\u0026amp;target_type=deb_local # 安装 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/13.0.0/local_installers/cuda-repo-ubuntu2204-13-0-local_13.0.0-580.65.06-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-13-0-local_13.0.0-580.65.06-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-13-0-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-13-0 # 卸载 # 卸载 CUDA Toolkit 13.0 主包 sudo apt purge cuda-toolkit-13-0 -y # 移除所有 CUDA 关联包（含驱动以外的依赖库） sudo apt --purge remove \u0026#34;cuda*\u0026#34; \u0026#34;libcudnn*\u0026#34; \u0026#34;nvidia-cuda-toolkit\u0026#34; -y # 清理残留依赖 sudo apt autoremove \u0026amp;\u0026amp; sudo apt autoclean # 确认无 CUDA 残留包 dpkg -l | grep -i cuda # 应无输出 # 强制卸载残留包（忽略依赖检查） sudo dpkg --purge --force-all libnvptxcompiler-13-0 # https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=Ubuntu\u0026amp;target_version=22.04\u0026amp;target_type=deb_local # 安装 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-4 安装 nvcc # apt install nvidia-cuda-toolkit 安装 cuda 11.4 # Cleaning remaining files # # Deleting any NVIDIA/CUDA packages you may already have installed sudo rm /etc/apt/sources.list.d/cuda* sudo apt remove --autoremove nvidia-cuda-toolkit sudo apt remove --autoremove nvidia-* # Deleting any remaining Cuda files on /usr/local/ sudo rm -rf /usr/local/cuda* # Purge any remaining NVIDIA configuration files sudo apt-get purge nvidia* # updating and deleting unnecessary dependencies. sudo apt-get update sudo apt-get autoremove sudo apt-get autoclean # For 18.04 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda-repo-ubuntu1804-11-4-local_11.4.0-470.42.01-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1804-11-4-local_11.4.0-470.42.01-1_amd64.deb sudo apt-key add /var/cuda-repo-ubuntu1804-11-4-local/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda # For 20.04 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda-repo-ubuntu2004-11-4-local_11.4.0-470.42.01-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2004-11-4-local_11.4.0-470.42.01-1_amd64.deb sudo apt-key add /var/cuda-repo-ubuntu2004-11-4-local/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda # 配置 path cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # set PATH for cuda 11.4 installation if [ -d \u0026#34;/usr/local/cuda-11.4/bin/\u0026#34; ]; then export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} fi EOF zsh # check nvidia-smi nvcc -V # nvcc --version 参考：\nHow to install Cuda 11.4 on ubuntu 测试 cuda # vi kernel.cu nvcc -o kernel kernel.cu ./kernel # 输出 # Max error: 0.000000 #include \u0026lt;stdio.h\u0026gt; __global__ void saxpy(int n, float a, float *x, float *y) { int i = blockIdx.x*blockDim.x + threadIdx.x; if (i \u0026lt; n) y[i] = a*x[i] + y[i]; } int main(void) { int N = 1\u0026lt;\u0026lt;20; float *x, *y, *d_x, *d_y; x = (float*)malloc(N*sizeof(float)); y = (float*)malloc(N*sizeof(float)); cudaMalloc(\u0026amp;d_x, N*sizeof(float)); cudaMalloc(\u0026amp;d_y, N*sizeof(float)); for (int i = 0; i \u0026lt; N; i++) { x[i] = 1.0f; y[i] = 2.0f; } cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice); // Perform SAXPY on 1M elements saxpy\u0026lt;\u0026lt;\u0026lt;(N+255)/256, 256\u0026gt;\u0026gt;\u0026gt;(N, 2.0f, d_x, d_y); cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost); float maxError = 0.0f; for (int i = 0; i \u0026lt; N; i++) maxError = max(maxError, abs(y[i]-4.0f)); printf(\u0026#34;Max error: %f\\n\u0026#34;, maxError); cudaFree(d_x); cudaFree(d_y); free(x); free(y); } CUDA vs cuDNN vs cuBLAS # cuDNN 是基于 CUDA 的深度学习 GPU 加速库，有了它才能在 GPU 上完成深度学习的计算 只要把 cuDNN 文件复制到 CUDA 的对应文件夹里就可以，即是所谓插入式设计 cuBLAS (CUDA Basic Linear Algebra Subroutine library) CUDA 基本线性代数子程序库 cutlass 仅支持矩阵乘法运算，不支持卷积算子，从而难以直接应用到计算机视觉领域的推理部署中 查看 cuDNN 版本 # # 查看cuDNN版本 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 例如： #define CUDNN_MAJOR 8 #define CUDNN_MINOR 2 #define CUDNN_PATCHLEVEL 4 表示当前使用的是cuDNN 8.2.4 版本 "},{"id":750,"href":"/note-cs/docs/basic/cc/gpu/cuda/cuda-programming/","title":"CUDA 编程","section":"CUDA","content":" CUDA 编程 # Hello World for CUDA # // This is the REAL \u0026#34;hello world\u0026#34; for CUDA! // It takes the string \u0026#34;Hello \u0026#34;, prints it, then passes it to CUDA // with an array of offsets. Then the offsets are added in parallel // to produce the string \u0026#34;World!\u0026#34; // By Ingemar Ragnemalm 2010 // nvcc hello-world.cu -L /usr/local/cuda/lib -lcudart -o hello-world #include \u0026lt;stdio.h\u0026gt; const int N = 16; const int blocksize = 16; __global__ void hello(char *a, int *b) { a[threadIdx.x] += b[threadIdx.x]; } int main() { char a[N] = \u0026#34;Hello \\0\\0\\0\\0\\0\\0\u0026#34;; int b[N] = {15, 10, 6, 0, -11, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}; char *ad; int *bd; const int csize = N*sizeof(char); const int isize = N*sizeof(int); printf(\u0026#34;%s\u0026#34;, a); cudaMalloc( (void**)\u0026amp;ad, csize ); cudaMalloc( (void**)\u0026amp;bd, isize ); cudaMemcpy( ad, a, csize, cudaMemcpyHostToDevice ); cudaMemcpy( bd, b, isize, cudaMemcpyHostToDevice ); dim3 dimBlock( blocksize, 1 ); dim3 dimGrid( 1, 1 ); hello\u0026lt;\u0026lt;\u0026lt;dimGrid, dimBlock\u0026gt;\u0026gt;\u0026gt;(ad, bd); cudaMemcpy( a, ad, csize, cudaMemcpyDeviceToHost ); cudaFree( ad ); cudaFree( bd ); printf(\u0026#34;%s\\n\u0026#34;, a); sleep(1); return EXIT_SUCCESS; } 参考：\nHello World for CUDA, OpenCL and GLSL 教程 # An Even Easier Introduction to CUDA CUDA C++ Programming Guide CUDA C++ Best Practices Guide DefTruth/CUDA-Learn-Notes "},{"id":751,"href":"/note-cs/docs/tool/linux/centos/curl/","title":"curl","section":"4.2.2 CentOS","content":" curl # 安装 curl 支持 https # sudo yum install openssl-devel libssh2-devel -y cd /usr/local/src # sudo wget -c --no-check-certificate https://curl.se/download/curl-7.79.0.tar.gz # 放到 vpc sudo wget -c vultr.kingye.me/curl-7.79.0.tar.gz sudo tar -xzf curl-7.79.0.tar.gz cd curl-7.79.0 sudo ./configure --with-ssl sudo make sudo make install sudo ldconfig /usr/local/bin/curl -V "},{"id":752,"href":"/note-cs/docs/tool/linux/ubuntu/dash/","title":"Dash","section":"4.2.1 Ubuntu","content":" Dash # "},{"id":753,"href":"/note-cs/docs/basic/cc/dmi/","title":"DMI","section":"1.1 计算机组成原理","content":" DMI # 直接媒体接口（英语：Direct Media Interface，DMI）是英特尔专用的总线，用于电脑主板上南桥芯片和北桥芯片之间的连接。 DMI 的首次应用是作为 2004 年推出的英特尔 900 系列北桥芯片与 ICH6 南桥芯片之间的连接接口。\nDMI 1.0, introduced in 2004. DMI 2.0, introduced in 2011, doubles the data transfer rate to 2 GB/s with a ×4 link. It is used to link an Intel CPU with the Intel Platform Controller Hub (PCH), which supersedes the historic implementation of a separate northbridge and southbridge.: 14 DMI 3.0, released in August 2015, allows the 8 GT/s transfer rate per lane, for a total of four lanes and 3.93 GB/s for the CPU–PCH link. It is used by two-chip variants of the Intel Skylake microprocessors, which are used in conjunction with Intel 100 Series chipsets; some low power (Skylake-U onwards) and ultra low power (Skylake-Y onwards) mobile Intel processors have the PCH integrated into the physical package as a separate die, referred to as OPI (On Package DMI interconnect Interface) and effectively following the system on a chip (SoC) design layout. On 9 March 2015, Intel announced the Broadwell-based Xeon D as its first enterprise platform to fully incorporate the PCH in an SoC configuration. In 2021, with the release of 500 series chipsets, Intel increased the amount of DMI 3.0 lanes from four to eight, doubling the bandwidth. DMI 4.0, released on 2021-11-04 with 600 series chipsets, doubles the bandwidth each lane provides and is two times faster when compared to DMI 3.0. The number of DMI 4.0 lanes depends on chipset model used. "},{"id":754,"href":"/note-cs/docs/tool/linux/centos/docker/","title":"docker","section":"4.2.2 CentOS","content":" docker # 安装 # sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin sudo systemctl start docker sudo docker run hello-world 参考：https://docs.docker.com/engine/install/centos/\n"},{"id":755,"href":"/note-cs/docs/tool/linux/debian/docker/","title":"Docker","section":"4.2.3 Debian","content":" Docker # 安装 # sudo apt-get update sudo apt-get install ca-certificates curl gnupg # 添加 GPG 密钥 sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # 配置仓库源 echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\ https://download.docker.com/linux/debian $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin "},{"id":756,"href":"/note-cs/docs/tool/linux/ubuntu/docker/","title":"Docker","section":"4.2.1 Ubuntu","content":" Docker # 使用 # # 停止 docker systemctl stop docker.socket ## 配置 sudo tee /etc/docker/daemon.json \u0026gt; /dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://hub.kingye.me\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker echo \u0026#34;207.246.111.213 ghcr.io\u0026#34; | sudo tee -a /etc/hosts 安装 # # Add Docker\u0026#39;s official GPG key: sudo apt update sudo apt install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: sudo tee /etc/apt/sources.list.d/docker.sources \u0026lt;\u0026lt;EOF Types: deb URIs: https://download.docker.com/linux/ubuntu Suites: $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;${UBUNTU_CODENAME:-$VERSION_CODENAME}\u0026#34;) Components: stable Signed-By: /etc/apt/keyrings/docker.asc EOF sudo apt update sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y 安装指定版本 docker # # List the available versions: apt-cache madison docker-ce | awk \u0026#39;{ print $3 }\u0026#39; # 5:20.10.16~3-0~ubuntu-jammy # 5:20.10.15~3-0~ubuntu-jammy # 5:20.10.14~3-0~ubuntu-jammy # 5:20.10.13~3-0~ubuntu-jammy VERSION_STRING=5:20.10.13~3-0~ubuntu-jammy sudo apt-get install docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-compose-plugin 设置镜像源 # cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; /etc/docker/daemon.json { \u0026#34;experimental\u0026#34;: false, \u0026#34;debug\u0026#34;: true, \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker.1panel.live\u0026#34;, \u0026#34;https://hub.rat.dev\u0026#34;, \u0026#34;https://docker.anyhub.us.kg\u0026#34;, \u0026#34;https://docker.chenby.cn\u0026#34;, \u0026#34;https://dockerhub.jobcher.com\u0026#34;, \u0026#34;https://docker.awsl9527.cn\u0026#34;, \u0026#34;https://docker.m.daocloud.io\u0026#34; ] } EOF systemctl restart docker docker compose # 安装 # # docker compose version mkdir -p ~/.docker/cli-plugins/ curl -SL \u0026#34;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o ~/.docker/cli-plugins/docker-compose chmod +x ~/.docker/cli-plugins/docker-compose docker compose version docker \u0026ndash;privileged # docker run \u0026ndash;privileged=true 和 docker run \u0026ndash;privileged 是完全等价的\nSetting privileged should modify:\ncapabilities: removing any capability restrictions devices: the host devices will be visible seccomp: removing restrictions on allowed syscalls apparmor/selinux: policies aren\u0026rsquo;t applied cgroups: I don\u0026rsquo;t believe the container is limited within a cgroup 参考：\nDifference between --privileged and --cap-add=all in docker https://docs.docker.com/engine/containers/run/#runtime-privilege-and-linux-capabilities docker proxy # dqzboy/Docker-Proxy # ubuntu \u0026amp;\u0026amp; debian apt -y install curl # 国外环境 bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/dqzboy/Docker-Proxy/main/install/DockerProxy_Install.sh)\u0026#34; # 安装所有 registry ~/.acme.sh/acme.sh --set-default-ca --server letsencrypt ~/.acme.sh/acme.sh --set-accountemail \u0026#34;admin@kingye.me\u0026#34; ~/.acme.sh/acme.sh --issue --dns dns_cf -d \u0026#34;*.kingye.me\u0026#34; -d \u0026#34;kingye.me\u0026#34; sudo mkdir -p /ssl ~/.acme.sh/acme.sh --install-cert -d \u0026#34;*.kingye.me\u0026#34; \\ --key-file /ssl/wildcard.kingye.me.key \\ --fullchain-file /ssl/wildcard.kingye.me.crt \\ --reloadcmd \u0026#34;systemctl reload nginx\u0026#34; sudo chmod 600 /ssl/wildcard.kingye.me.key sudo chmod 644 /ssl/wildcard.kingye.me.crt # 验证证书是否包含通配域名 openssl x509 -in /ssl/wildcard.kingye.me.crt -noout -text | grep -A1 \u0026#34;Subject Alternative Name\u0026#34; sudo mkdir -p /etc/nginx/snippets sudo tee /etc/nginx/snippets/registry_proxy_common.conf \u0026gt; /dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; client_max_body_size 0; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_buffering off; proxy_request_buffering off; EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; /etc/nginx/conf.d/docker-proxy-registries.conf # Docker Hub (docker.io) server { listen 443 ssl http2; server_name hub.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:51000; } } # GHCR (ghcr.io) server { listen 443 ssl http2; server_name ghcr.kingye.me ghcr.io; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:52000; } } # GCR (gcr.io) server { listen 443 ssl http2; server_name gcr.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:53000; } } # k8s.gcr.io (legacy) server { listen 443 ssl http2; server_name k8sgcr.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:54000; } } # registry.k8s.io server { listen 443 ssl http2; server_name k8s.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:55000; } } # Quay (quay.io) server { listen 443 ssl http2; server_name quay.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:56000; } } # MCR (mcr.microsoft.com) server { listen 443 ssl http2; server_name mcr.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:57000; } } # Elastic (docker.elastic.co) server { listen 443 ssl http2; server_name elastic.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:58000; } } # NVCR (nvcr.io) server { listen 443 ssl http2; server_name nvcr.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; include /etc/nginx/snippets/registry_proxy_common.conf; location / { proxy_pass http://127.0.0.1:59000; } } # HubCMD-UI (management UI) server { listen 443 ssl http2; server_name ui.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; location / { proxy_pass http://127.0.0.1:30080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; } } # Optional: registry-ui (port 50000) server { listen 443 ssl http2; server_name regui.kingye.me; ssl_certificate /ssl/wildcard.kingye.me.crt; ssl_certificate_key /ssl/wildcard.kingye.me.key; location / { proxy_pass http://127.0.0.1:50000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; } } EOF "},{"id":757,"href":"/note-cs/docs/domain/cc/istio/basic/quick/faq/","title":"FAQ","section":"1.1 快速上手","content":" FAQ # Istio 如何实现 Sidecar 注入？ # Istio 如何实现流量管理？ # 如何拦截流量 intercept traffic\nIstio 是在哪一层实现流量管理？为什么要在那一层？ # Layer7 routing\nIstio 如何实现 mTLS 认证？ # "},{"id":758,"href":"/note-cs/docs/tool/linux/ubuntu/feh/","title":"feh","section":"4.2.1 Ubuntu","content":" feh # feh: image viewer and cataloguer\n安装 # sudo apt install feh feh ERROR: Can\u0026rsquo;t open X display. # lsix # hackerb9/lsix Like \u0026ldquo;ls\u0026rdquo;, but for images. Shows thumbnails in terminal using sixel graphics.\n# 安装 sudo apt-get install imagemagick sudo curl -Lo /usr/local/bin/lsix https://github.com/hackerb9/lsix/blob/1.8/lsix chmod +x /usr/local/bin/lsix "},{"id":759,"href":"/note-cs/docs/tool/macos/flowchart/","title":"Flowchart","section":"4.1 MacOS","content":" Flowchart # adrai/flowchart.js Draws simple SVG flow chart diagrams from textual representation of the diagram http://flowchart.js.org/\n"},{"id":760,"href":"/note-cs/docs/tool/linux/centos/git/","title":"git","section":"4.2.2 CentOS","content":" git # "},{"id":761,"href":"/note-cs/docs/tool/macos/git/","title":"Git","section":"4.1 MacOS","content":" Git # 分支 # # 本地仓库 分支引用 refs/heads/v1.0.0 # 远程跟踪分支引用, 远程仓库 origin 中有一个分支 v1.0.0 refs/remotes/origin/v1.0.0 # 标签引用，包括远程和本地 refs/tags/v1.0.0 tag # 远程 tag 被视为本地 tag 的一种，它们都存储在 refs/tags/ 路径下。当你从远程仓库拉取或推送 tag 时，Git 会自动同步这些 tag 到本地仓库中的 refs/tags/ 路径 分支和 tag 重名 # 远程有个 v1.0.0 tag，想基于它拉一个远程 v1.0.0 分支 # # 本地拉 v1.0.0 tag git fetch origin tag v1.0.0 # git fetch origin --tags # 基于 tag 拉 v1.0.0 分支, # git co -b 分支名 tag名 git co -b v1.0.0 v1.0.0 # 把本地分支推送到远程分支 git push origin refs/heads/v2.11.3:refs/heads/v2.11.3 原理：\ngit show-ref v2.11.3 git module # git submodule foreach git reset --hard HEAD git submodule update git submodule foreach \u0026#34;git checkout master; git pull\u0026#34; git submodule foreach git clean -f 更新 submodule # git submodule update --init git submodule update --remote merge vs squash vs rebase # merge 不能保持 master 分支干净，但是保持了所有的 commit history，大多数情况下都是不好的，个别情况挺好 squash 也可以保持 master 分支干净，但是 master 中 author 都是 maintainer，而不是原 owner rebase 可以尽可能保持 master 分支干净整洁，并且易于识别 author\nsquash merge # # 切换到目标分支 $ git checkout master # 以 squash 的形式 merge $ git merge --squash devel # it does not produce a commit right away: you need an additional commit $ git commit -m \u0026#34;squash branch\u0026#34; 你会发现，在 master 分支上居然有未提交的修改，然后你就需要在 master 上主动提交了修改， 注意，这里是你 commit 的，也就是改变了 commit 的 author。 git merge has a \u0026ndash;commit option, but it cannot be used with \u0026ndash;squash. It was never possible to use \u0026ndash;commit and \u0026ndash;squash together. 参考：\nIn git, what is the difference between merge \u0026ndash;squash and rebase? rebase merge # # 先切换到 devel 分支（不一样咯） $ git checkout devel # 变基 $ git rebase -i master # 切换回目标分支 $ git checkout master # 合并 $ git merge 我们在 devel 里面对照 master 进行了变基 所谓的变基其实就是找到两个分支共同的祖先 然后在当前分支上合并从共同祖先到现在的所有 commit 会选择怎么处理这些 commit 然后我们就得到了一个从公共 commit 到现在的单个 commit 这个时候别人将我们这个 commit 合并到 master 也只会在 master 上留下一个 commit 记录 合并 git commit # 参考：\nTrimming Git Commits/Squashing Git History git branch 与 git tag 同名 # 需要使用完整路径\ngit checkout refs/heads/v1.5.2 git checkout refs/tags/v1.5.2 git push -u origin refs/heads/v4.8.0 参考：\nIn git, is it a bad idea to create a tag with the same name as a deleted branch? git pull force # git fetch --all # git reset --hard origin/\u0026lt;branch_name\u0026gt; git reset --hard origin/master 参考：\nHow do I force “git pull” to overwrite local files? hard reset vs mixed reset vs soft reset # # 回到 reset 版本，之后的文件都属于 git add 的状态 git reset --soft # git reset 默认就是 --mixed # 回到 reset 版本，之后的文件都属于 git add 前的状态 git reset --mixed # 回到 reset 版本，之后文件都丢弃（使用 git reflog 可以找回来） git reset --hard git reflog # reflog 是 Git 操作的一道安全保障，它能够记录几乎所有本地仓库的改变。\n包括所有分支 commit 提交，已经删除的 commit（其实并未被实际删除）都会被记录。\n只要 HEAD 发生变化，就可以通过 reflog 查看到。\ngit 回退 # # 文件放弃本地修改 git checkout -- \u0026lt;file\u0026gt; # 回退到某个版本 git checkout commit-id \u0026lt;path\u0026gt; git reset -- \u0026lt;path\u0026gt; 参考：\nWhy git can\u0026rsquo;t do hard/soft resets by path? config 权限 # 问题： Bad owner or permissions on ~/.ssh/config\n解决：\nchown $USER ~/.ssh/config chmod 644 ~/.ssh/config git submodule # 拉取 submodule # git submodule init git submodule update --remote git submodule add -b # 参考：\nHow can I specify a branch/tag when adding a Git submodule? submodule 修改 url # edit the .gitmodules file to update the URL git submodule sync 参考： How to change the remote repository for a git submodule?\ndelete submodule # Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config. Run git rm --cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule (no trailing slash). Commit git commit -m \u0026quot;Removed submodule \u0026quot; Delete the now untracked submodule files rm -rf path_to_submodule 参考：\nHow do I remove a submodule? untracked status # [submodule \u0026#34;example\u0026#34;] path = example url = git://github.com/ikingye/example.git ignore = dirty How to get rid of Git submodules untracked status? 教程 # pcottle/learnGitBranching # LearnGitBranching is a git repository visualizer, sandbox, and a series of educational tutorials and challenges.\nhttps://learngitbranching.js.org/\n常见问题 # 保留 remote 的历史记录，但是不关心未来这个文件的变化 # 比如某个文件频繁变化，希望不再管理后续更新。\ngit update-index --assume-unchanged xxx-filepath # 继续跟进变化 git update-index --no-assume-unchanged xxx-filepath git worktree # mkdir -p ~/code/github/kvasium cd ~/code/github/kvasium git clone https://github.com/ikingye/kvasium main cd main git worktree add ../codex -b codex git worktree add ../claude -b claude # 使用 codex 开发 cd ~/code/github/kvasium/codex codex # 使用 claude 开发 cd ~/code/github/kvasium/claude claude Git # merge vs squash vs rebase # merge 不能保持 master 分支干净，但是保持了所有的 commit history，大多数情况下都是不好的，个别情况挺好 squash 也可以保持 master 分支干净，但是 master 中 author 都是 maintainer，而不是原 owner rebase 可以尽可能保持 master 分支干净整洁，并且易于识别 author\nsquash merge # # 切换到目标分支 $ git checkout master # 以 squash 的形式 merge $ git merge --squash devel # it does not produce a commit right away: you need an additional commit $ git commit -m \u0026#34;squash branch\u0026#34; 你会发现，在 master 分支上居然有未提交的修改，然后你就需要在 master 上主动提交了修改， 注意，这里是你 commit 的，也就是改变了 commit 的 author。 git merge has a \u0026ndash;commit option, but it cannot be used with \u0026ndash;squash. It was never possible to use \u0026ndash;commit and \u0026ndash;squash together. 参考：\nIn git, what is the difference between merge \u0026ndash;squash and rebase? rebase merge # # 先切换到 devel 分支（不一样咯） $ git checkout devel # 变基 $ git rebase -i master # 切换回目标分支 $ git checkout master # 合并 $ git merge 我们在 devel 里面对照 master 进行了变基 所谓的变基其实就是找到两个分支共同的祖先 然后在当前分支上合并从共同祖先到现在的所有 commit 会选择怎么处理这些 commit 然后我们就得到了一个从公共 commit 到现在的单个 commit 这个时候别人将我们这个 commit 合并到 master 也只会在 master 上留下一个 commit 记录 合并 git commit # 参考：\nTrimming Git Commits/Squashing Git History git # 删除 submodule # Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config. Run git rm --cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule (no trailing slash). Commit git commit -m \u0026quot;Removed submodule \u0026quot; Delete the now untracked submodule files rm -rf path_to_submodule Git # 参考：\n如何恢复丢弃的 git stash 数据 git # git config 优先级（从高到低）\n仓库级别 local, .git/config 用户级别 global, ～/.gitconfig 系统级别 system, /etc/gitconfig git # rename # git mv oldfile newfile\nGit 的默认 similarity 值是 50%，即如果修改内容超过原来 50%，就不显示 renamed 了，而是显示 new file, delete file。\ngit # git stash # 参考：\n如何恢复丢弃的 git stash 数据 git # branch 重命名 # 本地 branch 如果在当前分支 git branch -m new git branch -m old new remote branch git branch -m old new git push origin -d old git push origin -u new Git # 删除分支 # # 删除本地分支 # --delete git branch -d xxx # --delete --force git branch -D xxx # 删除远程分支 git push -d origin xxx 参考：\nHow do I delete a Git branch locally and remotely? 只在本地忽略它的后续修改 # # 标记忽略工作区改动（仅本地生效） git update-index --skip-worktree path/to/file # 恢复（取消忽略） git update-index --no-skip-worktree path/to/file # 查看哪些文件被 skip-worktree git ls-files -v | grep \u0026#39;^[S]\u0026#39; "},{"id":762,"href":"/note-cs/docs/tool/macos/github/","title":"GitHub","section":"4.1 MacOS","content":" GitHub # 设置代理 # git config --global http.proxy \u0026#34;http://127.0.0.1:8081\u0026#34; git config --global https.proxy \u0026#34;http://127.0.0.1:8081\u0026#34; # socks5 代理（如 Shadowsocks） git config --global http.proxy \u0026#34;socks5://127.0.0.1:1080\u0026#34; git config --global https.proxy \u0026#34;socks5://127.0.0.1:1080\u0026#34; # 取消代理 git config --global --unset http.proxy git config --global --unset https.proxy 学习 Github # Github Learning Lab # Introduction to GitHub # Github 工具 # cli/cli # GitHub’s official command line tool https://cli.github.com\ngithub/hub # A command-line tool that makes git easier to use with GitHub. https://hub.github.com/\n开源库 素材 / 规范 # 徽章 shields.io # 如：\n参考：\n用 [Substats] 和 Shields.io 为你的个人主页定制动态数据小牌子\nspencerwooo/Substats Github star 历史 # timqian/star-history # https://star-history.t9t.io/\nvesoft-inc/github-statistics # A react static app for displaying github repo statistiscs like Star History, Fork History and more.\nhttps://vesoft-inc.github.io/github-statistics/\nantonmedv/spark # seladb/startrack-js # GitHub star history and stats - based on JavaScript only!\nhttps://seladb.github.io/StarTrack-js/\nelliotreborn/github-stars # 技术栈的 star 趋势数据\nGithub PR 统计 # 开源相关工作岗位 # t9tio/open-source-jobs A list of Open Source projects offering jobs. https://oo.t9t.io/organizations\n角落标志 tholman/github-corners # http://tholman.com/github-corners/\n如： GitHub Apps # Run persistently and can react to events quickly. Work great when persistent data is needed. Work best with API requests that aren\u0026rsquo;t time consuming. Run on a server or compute infrastructure that you provide. 参考：\nStrengths of GitHub Actions and GitHub Apps Mergify # Stop merging your pull requests manually.\nWe save your time by automatically merging, commenting, rebasing, updating, labeling, backporting, closing, assigning, your pull requests.\nMergifyio/mergify-engine # Engine for Mergify https://mergify.io\nNetlify # [wei/pull] # Pull # Keep your forks up-to-date via automated PRs\nwei/pull probot/weekly-digest # 自动生成周报到 issue\nGitHub Actions # Provide automation that can perform continuous integration and continuous deployment. Can run directly on runner machines or in Docker containers. Can include access to a clone of your repository, enabling deployment and publishing tools, code formatters, and command line tools to access your code. Don\u0026rsquo;t require you to deploy code or serve an app. Have a simple interface to create and use secrets, which enables actions to interact with third-party services without needing to store the credentials of the person using the action. Github 工具开发 # webhook # NetEaseGame/git-webhook # 使用 Python Flask + SQLAchemy + Celery + Redis + React 开发的用于迅速搭建并使用 WebHook 进行自动化部署和运维，支持 Github / GitLab / Gogs / GitOsc。 https://webhook.hust.cc/\n若觉得 git-webhook 部署依然比较复杂，可以尝试更为简洁的 cli 版本 hustcc/webhookit github-webhook-handler # Node.js web handler / middleware for processing GitHub Webhooks\ngo-playground/webhooks # Webhook receiver for GitHub, Bitbucket, GitLab, Gogs\nhustcc/webhookit # Simple git webhook cli tool for automation tasks, bind git webhook to action.\ngorda/issue-man # Building apps # 参考：\nBuilding apps Building actions # 参考：\nBuilding actions "},{"id":763,"href":"/note-cs/docs/tool/macos/goland/","title":"Goland","section":"4.1 MacOS","content":" Goland # 快捷键 # 跳转 # 指定行 cmd + L\n指定文件 shift + cmd + O\n返回光标上一个位置 cmd + opt + 方向键\n查询 # 函数列表 cmd + f12\n当前文件查询 cmd + F\n当前文件替换 cmd + R\n所有文件查询 shift + cmd + F\n所有文件替换 shift + cmd + R\n选择 # 选中下一个相同内容 ctrl + G 选中所有相同内容 ctrl + G 展开所有代码块 shift + cmd + = 折叠所有代码块 shift + cmd + - 折叠或展开当前代码块 cmd + . 修改 # 复制当前行内容到下一行 cmd + D 删除当前行 cmd + delete 格式化代码 option + cmd + L 在当前行下一行增加空行 shift + enter 在当前行上一行增加空行 option + cmd + enter license # 下载 "},{"id":764,"href":"/note-cs/docs/basic/cc/gpu/","title":"GPU","section":"1.1 计算机组成原理","content":" \\(\\) GPU # GPU 算力 # GPU 算力单位 # 单位换算：\n一个 MFLOPS（mega FLOPS）等于每秒一佰万（= $10^6$ ）次的浮点运算；\n一个 GFLOPS（giga FLOPS）等于每秒拾亿（= $10^9$ ）次的浮点运算；\n一个 TFLOPS（tera FLOPS）等于每秒万亿（= $10^{12}$ ）次的浮点运算；\n一个 PFLOPS（peta FLOPS）等于每秒千万亿（= $10^{15}$ ）次的浮点运算;\n一个 EFLOPS（exa FLOPS）等于每秒百亿亿（= $10^{18}$ ）次的浮点运算;\n一个 ZFLOPS（zetta FLOPS）等于每秒十万京（= $10^{21}$ ）次的浮点运算。\nGPU 天梯图 # 参考：\n史上最全桌面级显卡天梯图 "},{"id":765,"href":"/note-cs/docs/tool/linux/ubuntu/gradio/","title":"Gradio","section":"4.2.1 Ubuntu","content":" Gradio # gradio-app/gradio import gradio as gr def greet(name): return \u0026#34;Hello \u0026#34; + name + \u0026#34;!\u0026#34; with gr.Blocks() as demo: output = gr.Textbox(label=\u0026#34;Output Box\u0026#34;) name = gr.Textbox(label=\u0026#34;Name\u0026#34;) greet_btn = gr.Button(\u0026#34;Greet\u0026#34;) greet_btn.click(fn=greet, inputs=name, outputs=output) demo.launch(share=True, server_name=\u0026#34;0.0.0.0\u0026#34;, server_port=8722) "},{"id":766,"href":"/note-cs/docs/tool/macos/graphviz/","title":"Graphviz","section":"4.1 MacOS","content":" Graphviz # graphviz/graphviz\nhttp://www.graphviz.org/documentation/\n插件 # xflr6/graphviz Simple Python interface for Graphviz https://graphviz.readthedocs.io/\n"},{"id":767,"href":"/note-cs/docs/tool/linux/ubuntu/gvm/","title":"gvm","section":"4.2.1 Ubuntu","content":" gvm # moovweb/gvm 安装：\nzsh \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 使用：\ngvm listall gvm list apt-get install bison make gcc -y # 使用二进制安装 gvm install go1.15.15 -B gvm install go1.16.15 -B gvm install go1.17.13 -B gvm install go1.18.9 -B gvm install go1.19.4 -B gvm install go1.24.10 -B gvm install go1.25.4 -B gvm use go1.15 gvm uninstall go1.15 # 使用二进制安装 gvm install go1.15 -B $ gvm install -h Invalid version: -h Usage: gvm install [version] [options] -s, --source=SOURCE Install Go from specified source. -n, --name=NAME Override the default name for this version. -pb, --with-protobuf Install Go protocol buffers. -b, --with-build-tools Install package build tools. -B, --binary Only install from binary. --prefer-binary Attempt a binary install, falling back to source. -h, --help Display this message. $ gvm help Usage: gvm [command] Description: GVM is the Go Version Manager Commands: version - print the gvm version number get - gets the latest code (for debugging) use - select a go version to use (--default to set permanently) diff - view changes to Go root help - display this usage text implode - completely remove gvm install - install go versions uninstall - uninstall go versions cross - install go cross compilers linkthis - link this directory into GOPATH list - list installed go versions listall - list available versions alias - manage go version aliases pkgset - manage go packages sets pkgenv - edit the environment for a package set "},{"id":768,"href":"/note-cs/docs/tool/macos/gvm/","title":"gvm","section":"4.1 MacOS","content":" gvm # moovweb/gvm 安装：\nzsh \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) mac m1 # mac m1 使用 gvm 安装 arm64 版本的 go\nfile ~/.gvm/gos/go1.16.15/bin/go ~/.gvm/gos/go1.16.15/bin/go: Mach-O 64-bit executable arm64 参考：https://github.com/moovweb/gvm/issues/406\nRROR: Couldn't remove pkgsets # gvm use go1.11.1 go clean -modcache gvm use go1.11.4 gvm uninstall go1.11.1 也可以手动删除\nrm -rf ~/.gvm/pkgsets/go1.11.1 gvm uninstall go1.11.1 参考：\nERROR: Couldn\u0026rsquo;t remove pkgsets 代理 # "},{"id":769,"href":"/note-cs/docs/tool/macos/hhkb/","title":"HHKB","section":"4.1 MacOS","content":" HHKB 键盘 # Happy Hacking Keyboard\n使用 # 方向键 # 右侧的 Fn 键 + [ / ; '\n"},{"id":770,"href":"/note-cs/docs/tool/macos/brew/","title":"homebrew","section":"4.1 MacOS","content":" Homebrew # tap # brew tap 可以为 brew 的软件的 跟踪，更新，安装添加更多的的 tap formulae\n如果你在核心仓库没有找到你需要的软件，那么你就需要安装第三方的仓库去安装你需要的软件\ntap 命令的仓库源默认来至于 Github，但是这个命令也不限制于这一个地方\nbrew tap # 没有参数会自动更新已经存在的 tap 并列出当前已经 tapped 的仓库\n# URL 默认是 https://github.com/user/homebrew-repo brew tap \u0026lt;user\u0026gt;/\u0026lt;repo\u0026gt; brew tap \u0026lt;user\u0026gt;/\u0026lt;homebrew-repo\u0026gt; # URL 可以是任何位置，任何协议 brew tap \u0026lt;user\u0026gt;/\u0026lt;repo\u0026gt; URL homebrew/core 默认是最高优先级\n可以使用 brew tap-pin username/repo 使这个仓库优先级高于 core\n使用 brew-tap-unpin username/repo 取消\n当你使用 brew install foo 这个命令时，brew 将按照下面的顺序去查找哪个 formula(tap) 将被使用:\npinned taps core formulae other taps 镜像加速 # 清华大学镜像 # # 替换 brew 程序本身的源 # export HOMEBREW_API_DOMAIN= export HOMEBREW_BREW_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\u0026#34; # 使用下面的几行命令自动设置 export HOMEBREW_CORE_GIT_REMOTE=\u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\u0026#34; for tap in core cask command-not-found; do brew tap --custom-remote --force-auto-update \u0026#34;homebrew/${tap}\u0026#34; \u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git\u0026#34; done brew update 参考 # Homebrew 和 Fink、MacPort 相比有什么优势？ 解决 Homebrew 下载更新极慢的问题 "},{"id":771,"href":"/note-cs/docs/tool/macos/idea/","title":"IntelliJ IDEA","section":"4.1 MacOS","content":" IntelliJ IDEA # 插件 # Alibaba Java Coding Guidelines # 教程 # xiaoxiunique/tool-tips # idea 中相见恨晚的技巧 https://atips.cn/idea/\n"},{"id":772,"href":"/note-cs/docs/tool/linux/ubuntu/java/","title":"Java","section":"4.2.1 Ubuntu","content":" Java # apt install default-jdk # lts version sudo apt install -y openjdk-8-jdk sudo apt install -y openjdk-11-jdk sudo apt install -y openjdk-17-jdk # list java versions update-java-alternatives --list # java-1.8.0-openjdk-amd64 1081 /usr/lib/jvm/java-1.8.0-openjdk-amd64 # java-1.11.0-openjdk-amd64 1111 /usr/lib/jvm/java-1.11.0-openjdk-amd64 # java-1.17.0-openjdk-amd64 1711 /usr/lib/jvm/java-1.17.0-openjdk-amd64 cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; ~/.zshrc # switch java version alias javato8=\u0026#34;update-java-alternatives --set /usr/lib/jvm/java-1.8.0-openjdk-amd64\u0026#34; alias javato11=\u0026#34;update-java-alternatives --set /usr/lib/jvm/java-1.11.0-openjdk-amd64\u0026#34; alias javato17=\u0026#34;update-java-alternatives --set /usr/lib/jvm/java-1.17.0-openjdk-amd64\u0026#34; EOF zsh "},{"id":773,"href":"/note-cs/docs/tool/linux/ubuntu/jupyter/","title":"Jupyter","section":"4.2.1 Ubuntu","content":" Jupyter # JupyterLab 包含了 Jupyter Notebook 所有功能，并升级增加了很多功能\npipenv install jupyterlab alias python-jupyter=\u0026#34;/Users/yewang/.local/share/virtualenvs/yewang-jvfc4aCO/bin/python\u0026#34; alias jupyter=\u0026#34;python-jupyter -m jupyter\u0026#34; alias jlab=\u0026#34;jupyter lab\u0026#34; alias jlist=\u0026#34;jupyter kernelspec list\u0026#34; 参考：\nJupyterLab Installation 配置 # # vi ~/.jupyter/jupyter_notebook_config.py # 绝对路径 c.NotebookApp.notebook_dir = \u0026#39;/Users/yewang/note/kingye/jupyter\u0026#39; Jupyter Notebook vs Jupyter Lab # Jupyter Lab is a next-generation web-based user interface for Project Jupyter Jupyter Notebook Interface is a Web-based application for authoring documents that combine live-code with narrative text, equations and visualizations. Jupyter Notebook 原名 IPython Notebook (version 3 or earlier) Jupyter kernel # jupyter kernelspec list jupyter kernelspec uninstall 参考：\nHow to list all installed Jupyter kernels? Go # gopherdata/gophernotes # go get -u github.com/gopherdata/gophernotes mkdir -p ~/Library/Jupyter/kernels/gophernotes # cp $GOPATH/src/github.com/gopherdata/gophernotes/kernel/* ~/Library/Jupyter/kernels/gophernotes cp /Users/yewang/.gvm/pkgsets/go1.15.10/global/pkg/mod/github.com/gopherdata/gophernotes@v0.7.2/kernel/* ~/Library/Jupyter/kernels/gophernotes Java # SpencerPark/IJava # A Jupyter kernel for executing Java code.\nPHP # Litipk/Jupyter-PHP # 先安装 zmq 查看扩展是否存在：php74 -m | grep zmq 不存在就需要安装 Litipk/Jupyter-PHP git clone git://github.com/mkoppanen/php-zmq.git cd php-zmq phpize74 \u0026amp;\u0026amp; configure74 make \u0026amp;\u0026amp; make install 修改 php.ini，添加 extension=zmq php -ini 查看 php.ini 文件位置 phpto74 php jupyter-php-installer.phar install -vvv 使用 -vvv 查看详细信息 Python # IPython # IPython Documentation Installing the IPython kernel 编辑器 # nteract/nteract # The interactive computing suite for you!\n"},{"id":774,"href":"/note-cs/docs/tool/macos/jupyter/","title":"Jupyter","section":"4.1 MacOS","content":" Jupyter # 安装 # # install jupyterlab pipx install jupyterlab --include-deps pipx ensurepath pipx inject jupyterlab pandas pipx ensurepath pipx install notebook pipx install jupyter-book # 验证安装 jupyter --version jupyter-lab --version notebook --version jupyter-book --version jupyter --version # Selected Jupyter core packages... # IPython : 8.18.1 # ipykernel : 6.29.4 # ipywidgets : 8.1.2 # jupyter_client : 7.4.9 # jupyter_core : 5.7.2 # jupyter_server : 2.14.0 # jupyterlab : not installed # nbclient : 0.10.0 # nbconvert : 7.16.4 # nbformat : 5.10.4 # notebook : 6.5.7 # qtconsole : 5.5.2 # traitlets : 5.14.3 "},{"id":775,"href":"/note-cs/docs/tool/linux/centos/k3d/","title":"k3d","section":"4.2.2 CentOS","content":" k3d # rancher/k3d 常用命令 # k3d cluster create yewang-test-1 --subnet \u0026#34;172.27.1.0/24\u0026#34; --api-port 10.173.199.27:8701 --servers 1 --agents 2 k3d cluster create yewang-test-2 --subnet \u0026#34;172.27.2.0/24\u0026#34; --api-port 10.173.199.27:8702 k3d cluster delete cluster-1 k3d cluster delete cluster-2 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; k3d-config-cluster-1.yaml apiVersion: k3d.io/v1alpha5 kind: Simple metadata: name: cluster-1 servers: 1 agents: 2 registries: create: name: registry-1 host: \u0026#34;127.0.0.1\u0026#34; config: | mirrors: \u0026#34;docker.io\u0026#34;: endpoint: - https://docker.kingye.me subnet: \u0026#34;172.27.1.0/24\u0026#34; kubeAPI: hostIP: \u0026#34;10.173.199.27\u0026#34; hostPort: \u0026#34;8701\u0026#34; EOF k3d cluster create --config k3d-config-cluster-1.yaml --verbose cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; k3d-config-cluster-2.yaml apiVersion: k3d.io/v1alpha5 kind: Simple metadata: name: cluster-2 servers: 1 agents: 2 registries: create: name: registry-2 host: \u0026#34;127.0.0.1\u0026#34; config: | mirrors: \u0026#34;docker.io\u0026#34;: endpoint: - https://docker.kingye.me subnet: \u0026#34;172.27.2.0/24\u0026#34; kubeAPI: hostIP: \u0026#34;10.173.199.27\u0026#34; hostPort: \u0026#34;8702\u0026#34; EOF k3d cluster create --config k3d-config-cluster-2.yaml --verbose k3d kubeconfig get cluster-1 \u0026gt; cluster-1-kubeconfig.yaml k3d kubeconfig get cluster-2 \u0026gt; cluster-2-kubeconfig.yaml k3d kubeconfig get cluster-3 \u0026gt; cluster-3-kubeconfig.yaml k3d kubeconfig get cluster-4 \u0026gt; cluster-4-kubeconfig.yaml k3d kubeconfig get cluster-5 \u0026gt; cluster-5-kubeconfig.yaml export KUBECONFIG=~/.kube/config:cluster-1-kubeconfig.yaml:cluster-2-kubeconfig.yaml kubectl config view --merge --flatten \u0026gt; ~/.kube/config unset KUBECONFIG kubectl config get-contexts # k ctx 安装配置 # "},{"id":776,"href":"/note-cs/docs/tool/linux/ubuntu/k3d/","title":"k3d","section":"4.2.1 Ubuntu","content":" k3d # rancher/k3d 常用命令 # # 安装 k3d wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash k3d cluster create aicp-test-1 --subnet \u0026#34;172.27.1.0/24\u0026#34; --api-port 172.16.48.74:8701 --servers 1 --agents 2 k3d cluster create aicp-test-2 --subnet \u0026#34;172.27.2.0/24\u0026#34; --api-port 172.16.48.74:8702 docker pull ghcr.io/k3d-io/k3d-proxy:5.8.3 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; k3d-config-cluster-1.yaml apiVersion: k3d.io/v1alpha5 kind: Simple metadata: name: cluster-1 servers: 1 agents: 2 registries: create: name: registry-1 host: \u0026#34;127.0.0.1\u0026#34; config: | mirrors: \u0026#34;docker.io\u0026#34;: endpoint: - https://hub.kingye.me subnet: \u0026#34;172.27.1.0/24\u0026#34; kubeAPI: hostIP: \u0026#34;172.16.48.74\u0026#34; hostPort: \u0026#34;8701\u0026#34; EOF k3d cluster create --config k3d-config-cluster-1.yaml --verbose 安装配置 # "},{"id":777,"href":"/note-cs/docs/tool/macos/katex/","title":"KaTeX","section":"4.1 MacOS","content":" KaTeX # \\[f(x) = \\int\\_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\\] \\(f(x) = \\int\\_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\\) $$ L(Y,f(X))=\\left{\\begin{matrix} 1,Y\\neq f(X) \\ 0,Y = f(X)\\end{matrix}\\right. $$\n"},{"id":778,"href":"/note-cs/docs/domain/cc/istio/basic/quick/kiali/","title":"Kiali","section":"1.1 快速上手","content":" Kiali # kiali/kiali Kiali project, observability for the Istio service mesh\n"},{"id":779,"href":"/note-cs/docs/tool/macos/kubectx/","title":"kubectx","section":"4.1 MacOS","content":" kubectx # ahmetb/kubectx # 安装 brew install kubectx alias kx=kubectx alias kn=kubens # 展示当前可用集群列表 kx # 选中某集群 kx xxx # 展示 namespace 列表 kn # 选中某 ns kn xxx kubemerge # # vim ~/.zshrc kubemerge() { if [ $# -eq 0 ]; then echo \u0026#34;Usage: kubemerge \u0026lt;path-to-kubeconfig1\u0026gt; [\u0026lt;path-to-kubeconfig2\u0026gt; ...]\u0026#34; return 1 fi # Ensure ~/.kube directory exists mkdir -p ~/.kube # Ensure ~/.kube/config exists and is not empty if [ ! -f ~/.kube/config ] || [ ! -s ~/.kube/config ]; then touch ~/.kube/config fi for NEW_KUBECONFIG in \u0026#34;$@\u0026#34;; do if [[ \u0026#34;$NEW_KUBECONFIG\u0026#34; == \u0026#34;cache\u0026#34; || \u0026#34;$NEW_KUBECONFIG\u0026#34; == \u0026#34;config_temp\u0026#34; || \u0026#34;$NEW_KUBECONFIG\u0026#34; == \u0026#34;kubectx\u0026#34; ]]; then echo \u0026#34;Skipping $NEW_KUBECONFIG\u0026#34; continue fi if [ ! -f \u0026#34;$NEW_KUBECONFIG\u0026#34; ]; then echo \u0026#34;File not found: $NEW_KUBECONFIG\u0026#34; continue fi local CONTEXT_NAME=$(basename \u0026#34;$NEW_KUBECONFIG\u0026#34;) # Check if the context name already exists if kubectl config get-contexts -o name | grep -q \u0026#34;^$CONTEXT_NAME$\u0026#34;; then echo \u0026#34;Context \\\u0026#34;$CONTEXT_NAME\\\u0026#34; already exists. Skipping merge and rename.\u0026#34; else # Merge the new kubeconfig with the existing one if KUBECONFIG=~/.kube/config:$NEW_KUBECONFIG kubectl config view --merge --flatten \u0026gt;~/.kube/config_temp; then mv ~/.kube/config_temp ~/.kube/config echo \u0026#34;Merged $NEW_KUBECONFIG successfully.\u0026#34; # Extract new contexts from the new kubeconfig file NEW_CONTEXTS=$(kubectl --kubeconfig=\u0026#34;$NEW_KUBECONFIG\u0026#34; config get-contexts -o name) for CONTEXT in $NEW_CONTEXTS; do kubectl config rename-context \u0026#34;$CONTEXT\u0026#34; \u0026#34;$CONTEXT_NAME\u0026#34; done else echo \u0026#34;Failed to merge $NEW_KUBECONFIG due to invalid format or content.\u0026#34; return 1 fi fi done } "},{"id":780,"href":"/note-cs/docs/tool/linux/ubuntu/kubeedge/","title":"KubeEdge","section":"4.2.1 Ubuntu","content":" KubeEdge # 部署 # # ime-study3 keadm init --advertise-address=\u0026#34;120.241.124.226\u0026#34; --profile version=v1.13.0 --kube-config=/root/.kube/config kubectl get all -n kubeedge keadm gettoken # ime-study4 # namespace 必须是 k8s.io，containerd 才能使用，crictl image 才能看到 ctr -n=k8s.io image pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 ctr -n=k8s.io image tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 registry.k8s.io/pause:3.6 rm -rf /etc/kubeedge/ keadm join --cloudcore-ipport=\u0026#34;120.241.124.226:10000\u0026#34; --token=f76a721023f724ae4ff872c8ec9e04e672d4eb93d1327638526389267084629b.eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NzU3Mjk0MDl9.TrcHtDra2gwuBw-9Aa8aDkDK99n1JoxwYYz8Kv4ugPo --kubeedge-version=v1.13.0 "},{"id":781,"href":"/note-cs/docs/tool/linux/ubuntu/kubesphere/","title":"KubeSphere","section":"4.2.1 Ubuntu","content":" KubeSphere # kubectl patch storageclass local-storage -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; "},{"id":782,"href":"/note-cs/docs/tool/linux/ubuntu/langflow/","title":"langflow","section":"4.2.1 Ubuntu","content":" langflow # langflow --host \u0026#34;0.0.0.0\u0026#34; --port 7865 "},{"id":783,"href":"/note-cs/docs/tool/macos/latex/","title":"LaTeX","section":"4.1 MacOS","content":" LaTeX # latex3/latex2e The LaTeX2e kernel https://www.latex-project.org/\nlatex3/latex3 The LaTeX3 Development Repository https://latex-project.org/latex3.html\nMathpix # Mathpix 允许你截取复杂数学方程式的截图，并立即将其转换为 LaTeX 可编辑文本。\n参考 # 自学 LaTeX 可以读什么书入门？ 如何在 1 小时内快速入手 LaTeX？ 有哪些好的 LaTeX 编辑器？ 用这个漂亮的工具将方程式截图迅速转换为 LaTeX KaTeX/KaTeX TeX wiki LaTeX 在线编辑器 一份其实很短的 LaTeX 入门文档 LaTeX 数学符号对应表 "},{"id":784,"href":"/note-cs/docs/tool/linux/centos/mamba/","title":"mamba","section":"4.2.2 CentOS","content":" mamba # conda-forge/miniforge 安装 # # 安装 curl -L -O \u0026#34;https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\u0026#34; bash Miniforge3-$(uname)-$(uname -m).sh # -c 表示渠道 mamba create -n myjlabenv jupyterlab -c conda-forge mamba activate myjlabenv # activate our environment jupyter lab # this will start up jupyter lab and open a browser mamba activate myjlabenv mamba install bqplot # now you can use bqplot in myjlabenv mamba install \u0026#34;matplotlib\u0026gt;=3.5.0\u0026#34; cartopy # now you installed matplotlib with version\u0026gt;=3.5.0 and default version of cartopy mamba create -n pytorch python=3.10 mamba activate pytorch mamba info --envs # mkdir -p /home/users/yewang/tmp # mkdir -p /home/users/yewang/.cache/pip cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.bashrc # 设置 TMPDIR export TMPDIR=/home/users/yewang/tmp # 设置 PIP_CACHE_DIR export PIP_CACHE_DIR=/home/users/yewang/.cache/pip EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 设置 TMPDIR export TMPDIR=/home/users/yewang/tmp # 设置 PIP_CACHE_DIR export PIP_CACHE_DIR=/home/users/yewang/.cache/pip EOF zsh "},{"id":785,"href":"/note-cs/docs/tool/linux/ubuntu/mamba/","title":"mamba","section":"4.2.1 Ubuntu","content":" mamba # conda-forge/miniforge 安装 # # 安装 curl -L -O \u0026#34;https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\u0026#34; bash Miniforge3-$(uname)-$(uname -m).sh # -c 表示渠道 mamba create -n myjlabenv jupyterlab -c conda-forge mamba activate myjlabenv # activate our environment jupyter lab # this will start up jupyter lab and open a browser mamba activate myjlabenv mamba install bqplot # now you can use bqplot in myjlabenv mamba install \u0026#34;matplotlib\u0026gt;=3.5.0\u0026#34; cartopy # now you installed matplotlib with version\u0026gt;=3.5.0 and default version of cartopy mamba create -n pytorch python=3.10 mamba activate pytorch "},{"id":786,"href":"/note-cs/docs/tool/macos/mamba/","title":"mamba","section":"4.1 MacOS","content":" mamba # conda-forge/miniforge 安装 # # 安装 curl -L -O \u0026#34;https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\u0026#34; bash Miniforge3-$(uname)-$(uname -m).sh # -c 表示渠道 mamba create -n myjlabenv jupyterlab -c conda-forge mamba activate myjlabenv # activate our environment jupyter lab # this will start up jupyter lab and open a browser mamba activate myjlabenv mamba install bqplot # now you can use bqplot in myjlabenv mamba install \u0026#34;matplotlib\u0026gt;=3.5.0\u0026#34; cartopy # now you installed matplotlib with version\u0026gt;=3.5.0 and default version of cartopy # 删除环境 mamba env remove -y -p /home/users/yewang/miniconda3/envs/pytorch # 环境改名 ## 克隆 mamba create -n pytorch --clone hello-pytorch ## 删除老的 mamba env remove -y -n hello-pytorch ## 使用环境路径 mamba create -n d2l --clone /home/users/yewang/miniconda3/envs/d2l mamba env remove -y -p /home/users/yewang/miniconda3/envs/d2l # 从文件中安装 mamba install --file requirements.txt -y # 删除缓存文件 conda clean --all -y "},{"id":787,"href":"/note-cs/docs/tool/macos/marimo/","title":"marimo","section":"4.1 MacOS","content":" marimo # uv init uv venv uv pip install marimo # 教程 marimo tutorial intro "},{"id":788,"href":"/note-cs/docs/tool/macos/mas/","title":"Mas","section":"4.1 MacOS","content":" mas-cli/mas # Each application in the Mac App Store has a product identifier which is also used for mas-cli commands. Using mas list will show all installed applications and their product identifiers.\n$ mas list 446107677 Screens 407963104 Pixelmator 497799835 Xcode $ mas search Xcode 497799835 Xcode 688199928 Docs for Xcode 449589707 Dash 3 - API Docs \u0026amp; Snippets. Integrates with Xcode, Alfred, TextWrangler and many more. [...] $ mas install 808809998 ==\u0026gt; Downloading PaintCode 2 ==\u0026gt; Installed PaintCode 2 # If you want to install the first result that the search command returns, use the lucky command. $ mas lucky twitter ==\u0026gt; Downloading Twitter ==\u0026gt; Installed Twitter $ mas outdated 497799835 Xcode (7.0) 446107677 Screens VNC - Access Your Computer From Anywhere (3.6.7) $ mas upgrade Upgrading 2 outdated applications: Xcode (7.0), Screens VNC - Access Your Computer From Anywhere (3.6.7) ==\u0026gt; Downloading Xcode ==\u0026gt; Installed Xcode ==\u0026gt; Downloading iFlicks ==\u0026gt; Installed iFlicks $ mas upgrade 715768417 Upgrading 1 outdated application: Xcode (8.0) ==\u0026gt; Downloading Xcode ==\u0026gt; Installed Xcode $ mas signin mas@example.com ==\u0026gt; Signing in to Apple ID: mas@example.com Password: "},{"id":789,"href":"/note-cs/docs/tool/macos/mathjax/","title":"MathJax","section":"4.1 MacOS","content":" MathJax # 参考：\nMathJax input TeX and LaTeX MathML AsciiMath "},{"id":790,"href":"/note-cs/docs/tool/macos/mermaid/","title":"Mermaid","section":"4.1 MacOS","content":" Mermaid # mermaid-js/mermaid Generation of diagram and flowchart from text in a similar manner as markdown http://mermaid-js.github.io/mermaid/\n"},{"id":791,"href":"/note-cs/docs/tool/linux/ubuntu/microk8s/","title":"MicroK8s","section":"4.2.1 Ubuntu","content":" MicroK8s # ubuntu/microk8s MicroK8s is a small, fast, single-package Kubernetes for developers, IoT and edge.\nhttps://microk8s.io\n安装 # snap install microk8s --classic snap install kubectl --classic # snap install microk8s --classic --channel=1.23/stable # snap install kubectl --classic --channel=1.23/stable mkdir -p ~/.kube microk8s config \u0026gt; ~/.kube/config microk8s enable dns microk8s enable dashboard ingress # 拉镜像 microk8s ctr image pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.7 microk8s ctr image tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.7 k8s.gcr.io/pause:3.7 microk8s ctr image tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.7 registry.k8s.io/pause:3.7 microk8s ctr image pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.2.0 microk8s ctr image tag registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.2.0 k8s.gcr.io/ingress-nginx/controller:v1.2.0 microk8s ctr image pull registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.5.2 microk8s ctr image tag registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.5.2 k8s.gcr.io/metrics-server/metrics-server:v0.5.2 echo \u0026#34;alias k=kubectl\u0026#34; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#34;export PATH=\\$PATH:/snap/bin\u0026#34; \u0026gt;\u0026gt; ~/.zshrc zsh 安装 kubectl 的另一种方法 # # install kubectl curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt update sudo apt install kubectl -y 配置镜像源 # # 先停止 sudo microk8s.stop sudo vim /var/snap/microk8s/current/args/containerd-template.toml [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;docker.io\u0026#34;] endpoint = [ \u0026#34;docker.1panel.live\u0026#34;, \u0026#34;hub.rat.dev\u0026#34;, \u0026#34;docker.anyhub.us.kg\u0026#34;, \u0026#34;docker.chenby.cn\u0026#34;, \u0026#34;dockerhub.jobcher.com\u0026#34;, \u0026#34;docker.awsl9527.cn\u0026#34;, \u0026#34;docker.m.daocloud.io\u0026#34; ] sudo microk8s.start microk8s.ctr images pull docker.io/library/busybox:latest microk8s.ctr images pull docker.io/calico/cni:v3.19.1 常用命令 # microk8s enable dns 安装配置 # # microk8s kubelet service 配置文件 vi /etc/systemd/system/snap.microk8s.daemon-kubelet.service # 查看状态 systemctl status snap.microk8s.daemon-kubelet 代理 # vi /etc/environment\nHTTPS_PROXY=http://your-proxy-server:8215 HTTP_PROXY=http://your-proxy-server:8215 NO_PROXY=10.0.0.0/8,172.16.0.0/12,192.168/16 https_proxy=http://your-proxy-server:8215 http_proxy=http://your-proxy-server:8215 no_proxy=10.0.0.0/8,172.16.0.0/12,192.168/16 然后重启\nmicrok8s stop microk8s start 参考：\nInstalling behind a proxy "},{"id":792,"href":"/note-cs/docs/tool/linux/ubuntu/mosquitto/","title":"Mosquitto","section":"4.2.1 Ubuntu","content":" Mosquitto # eclipse/mosquitto 安装 # apt install mosquitto -y apt install mosquitto-clients -y 使用 # # mosquitto_pub version 1.6.9 running on libmosquitto 1.6.9. mosquitto_pub {[-h host] [-p port] [-u username] [-P password] -t topic | -L URL} {-f file | -l | -n | -m message} [-c] [-k keepalive] [-q qos] [-r] [--repeat N] [--repeat-delay time] [-A bind_address] [-i id] [-I id_prefix] [-d] [--quiet] [-M max_inflight] [-u username [-P password]] [--will-topic [--will-payload payload] [--will-qos qos] [--will-retain]] [{--cafile file | --capath dir} [--cert file] [--key file] [--ciphers ciphers] [--insecure] [--tls-alpn protocol] [--tls-engine engine] [--keyform keyform] [--tls-engine-kpass-sha1]] [--psk hex-key --psk-identity identity [--ciphers ciphers]] [--proxy socks-url] [--property command identifier value] [-D command identifier value] "},{"id":793,"href":"/note-cs/docs/direction/be/mq/mqtt/","title":"MQTT","section":"2.2.2 消息队列","content":" MQTT # mqtt 各种 broker 如何选择？\nAgent 和 Broker 的差别是什么？\n经纪人（Broker）：是为促成他人交易，充当订约居间人，为委托方提供订约的信息、机会和条件的主体。 Broker 是一个独立主体，但没有自主决策能力，只负责订约过程。 代理人（Agent）：是行使被代理者的权力，完成相关的使命或者任务主体。 Agent 是一个独立主体，负责完成任务但不负责执行任务，Agent 具有一定的自主决策能力，如对服务请求的选择。 代理（Proxy）是指行为代理，不是一个主体。 Proxy 是完全的传递者，如请求和响应的转发，操作控制的传递。 mqtt 版本 # mqtt 5.0 # mqtt 3.1.1 # mqtt 开源实现 # MQTT.fx # MQTT.fx 是目前主流的 MQTT 桌面客户端，它支持 Windows、 Mac、Linux 操作系统， 可以快速验证连接，并发布或订阅消息。\n"},{"id":794,"href":"/note-cs/docs/tool/linux/ubuntu/multipass/","title":"Multipass","section":"4.2.1 Ubuntu","content":" Multipass # canonical/multipass Multipass orchestrates virtual Ubuntu instances https://multipass.run\n# 安装 snap install multipass # Find available images multipass find # 使用本地 image multipass launch --name k3s --mem 1G --disk 5G file://~/ubuntu-20.04-server-cloudimg-amd64.img # 默认就是 cpus 1, mem 1G, disk 5G # 参考：https://multipass.run/docs/launch-command multipass launch --name rd-node-1 --cpus 10 --mem 20G --disk 20G multipass launch --name rd-node-2 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-1 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-2 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-3 --cpus 10 --mem 20G --disk 20G # 挂载 multipass mount /home/work/ecsp/deploy/ecsp-edge rd-node-1:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge rd-node-2:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-1:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-2:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-3:/home/work/host # 为 VM 启动一个 shell multipass shell rd-node-1 multipass shell rd-node-2 multipass shell qa-node-1 multipass shell qa-node-2 multipass shell qa-node-3 # 安装需要的 sudo su apt update apt install net-tools selinux-utils # 删除 # Delete instances multipass delete ecsp-node-1 multipass delete ecsp-node-2 # Purge all deleted instances permanently multipass purge 网络 # 使用的是桥接模式，因为：\n主机可以 ping 通虚拟机 所以不是 NAT 虚拟机之间可以 ping 通 所以不是 NAT 虚拟机可以上网 所以不是 Host-Only "},{"id":795,"href":"/note-cs/docs/tool/macos/multipass/","title":"Multipass","section":"4.1 MacOS","content":" Multipass # canonical/multipass Multipass orchestrates virtual Ubuntu instances https://multipass.run\n# 安装 # Find available images multipass find # 使用本地 image multipass launch --name rd-node-1 --mem 1G --disk 5G file://~/multipass/ubuntu-22.04-server-cloudimg-amd64.img # 默认就是 cpus 1, mem 1G, disk 5G # 参考：https://multipass.run/docs/launch-command multipass launch --name rd-node-1 --cpus 10 --mem 20G --disk 20G file://~/multipass/ubuntu-22.04-server-cloudimg-amd64.img multipass launch --name rd-node-2 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-1 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-2 --cpus 10 --mem 20G --disk 20G multipass launch --name qa-node-3 --cpus 10 --mem 20G --disk 20G # 挂载 multipass mount /home/work/ecsp/deploy/ecsp-edge rd-node-1:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge rd-node-2:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-1:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-2:/home/work/host multipass mount /home/work/ecsp/deploy/ecsp-edge qa-node-3:/home/work/host # 为 VM 启动一个 shell multipass shell rd-node-1 multipass shell rd-node-2 multipass shell qa-node-1 multipass shell qa-node-2 multipass shell qa-node-3 # 安装需要的 sudo su apt update apt install net-tools selinux-utils # 删除 # Delete instances multipass delete ecsp-node-1 multipass delete ecsp-node-2 # Purge all deleted instances permanently multipass purge 网络 # 使用的是桥接模式，因为：\n主机可以 ping 通虚拟机 所以不是 NAT 虚拟机之间可以 ping 通 所以不是 NAT 虚拟机可以上网 所以不是 Host-Only "},{"id":796,"href":"/note-cs/docs/basic/cc/gpu/nvidia/nccl/","title":"NCCL","section":"Nvidia","content":" NCCL # NCCL 在网络模型训练框架中位于深度学习框架（如 Torch、TF、PP 等），和 CUDA 框架之间。同级并列的还有深度学习库 CUDNN、线性代数库 CUBLAS。\nNvidia Collective multi-GPU Communication Library\n是一个实现多 GPU 的 collective communication 通信（all-gather, reduce, broadcast）库，Nvidia 做了很多优化，以在 PCIe、Nvlink、InfiniBand 上实现较高的通信速度。\nPCIe 适用于标准 GPU 连接和一般数据传输 NVLink 主要用于连接高性能计算（HPC）和深度学习应用中的 GPU，可以显著提高多 GPU 系统的数据传输和处理能力 NVLink 可以提供每秒几百 GB 的带宽，显著高于 PCIe GPU Direct P2P 是一种允许 NVIDIA GPU 直接通过 PCIe 或 NVLink 互相通信的技术，无需 CPU 介入 InfiniBand 连接不同计算机或服务器的一种网络技术 Communication Primitive # 并行任务的通信一般可以分为\nPoint-to-point Communication P2P 通信这种模式只有一个 sender 和一个 receiver，实现起来比较简单 Collective Communication Collective Communication 包含多个 sender 多个 receiver 一般的通信原语包括 broadcast, gather, all-gather, scatter, reduce, all-reduce, reduce-scatter, all-to-all 等 ring-based Collective communication # 传统 Collective communication 假设通信节点组成的 topology 是一颗 fat tree，这样通信效率最高\n但实际的通信 topology 可能比较复杂，并不是一个 fat tree 因此一般用 ring-based Collective communication\nring-based Collective communication 将所有的通信节点通过首尾连接形成一个单向环，数据在环上依次传输 把要传输的数据分成 S 份，每次只传 N/S 的数据量，GPU1 接收到 GPU0 的一份数据后，也接着传到环的下个节点 时间为 S*(N/S/B) + (k-2)*(N/S/B) = N(S+K-2)/(SB) \u0026ndash;\u0026gt; N/B，条件是 S 远大于 K，即数据的份数大于节点数，这个很容易满足 所以通信时间不随节点数的增加而增加，只和数据总量以及带宽有关 构建通信环的方式：\n单机 4 卡\n单机 8 卡\nNCCL 实现 # NCCL 实现成 CUDA C++ kernels，包含 3 种 primitive operations：\nCopy Reduce ReduceAndCopy NCCL 1.0 版本只支持单机多卡，卡之间通过 PCIe、NVlink、GPU Direct P2P 来通信。 NCCL 2.0 会支持多机多卡，多机间通过 Sockets (Ethernet)或者 InfiniBand with GPU Direct RDMA 通信 参考：\n如何理解 Nvidia 英伟达的 Multi-GPU 多卡通信框架 NCCL？ "},{"id":797,"href":"/note-cs/docs/basic/cc/gpu/nvidia/","title":"Nvidia","section":"GPU","content":" Nvidia # 例如： NVIDIA GeForce RTX 3060 Ti\nNVIDIA: 即英伟达，品牌名 GeForce: 是显卡系列名称 Tesla: 专业级显卡, Data Center 数值计算 深度学习、人工智能和高性能计算 Quadro: 专业级显卡 NVIDIA RTX 图形计算 专业可视化设计和创作 2018 年 RTX 4000 出来后逐渐放弃了 Quadro，2020 年的 RTX A6000 标志着正式放弃 Quadro GeForce: 普通消费级显卡 图形计算 游戏娱乐领域 RTX: 代表“高端”，一般是带光影追踪功能，只出现在 20 系显卡及以上 RTX 是 NVIDIA 较新的 GPU 系列，首次引入了实时光线追踪技术（Ray Tracing） GTX 是系列中的高端显卡 这是 NVIDIA 的图形处理单元（GPU）中较早的一个系列 GTX 可以视为 Giga Texel Shader eXtreme 的非正式缩写，尽管这并不是 NVIDIA 官方的解释，主要强调其在图形处理方面的高性能 GTX 系列更多的是针对传统的高性能图形处理，而 RTX 系列则是在此基础上加入了对最新渲染技术（如光线追踪）的支持，以及针对 AI 计算的优化。 GTS 是系列中的中端显卡 GT 是系列中的入门级显卡 30: 代表的是第几代 20 30 40 6: 是显卡性能档次的定位 89 是高端 567 是中端 1234 是低端 0: 不用管这位数字，一般都是 0 Ti Ti 增强 Super 小增强 SE 阉割 M 等于移动端如 MX, Max-Q AD102 (76.3B): 4090\nAD103 (45.9B): 4080\nAD104 (35.8B): 4070Ti\nGA102 芯片，对应 3090ti, 3090, 3080ti, 3080\nGA104 芯片，对应 3070ti, 3070, 3060ti\nGA106 芯片，对应 3060, 3050ti\nGA107 芯片，对应 3050\nQuadro vs Geforce # Quadro 和 Geforce 基本上只有如下 3 个主要区别了：\n显存。 Geforce 限一个尴尬的 11G 就是为了让你做大工程的时候爆显存，逼着刚需用户买专业卡。 另外专业卡用 ECC 显存，主打一个遇到错误能检查和恢复的能力，非 ECC 显存此时只要不是严重错误可能直接忽略了，错误严重了就挂了。但由于现代内存可靠性足够好，关于 ecc 的作用其实很玄学，我就问一点 —— 主内存怎么办，工作条件更复杂的主内存都不支持 ecc，你若不放心显存，就放心内存了？若关注 ecc，请你别光盯着显卡，主板也换工作站或服务器板，也用 ecc 内存。服务器上专业卡是企业合理的选择，没啥说的，我吐槽的是 desktop。 驱动。 会通过驱动的识别，仅在专业卡上 enable 一些功能，比如 nvenc 编码并发度，比如针对一些老旧工业软件的 workaround 等，这种是纯软件的。 Titan 和 3090 被称为半专业卡，显存高于一般的 Geforce，但是也会在驱动上限制。 AMD 由于市场弱势，对游戏卡的软件限制要少很多。 频率、散热和外形。 非公高端游戏卡往往做成 3slot，散热堆料丧病，频率灰烬。 专业卡为了多卡好插甚至上机架，至多双 slot。频率也会压得低点，更有利于长稳运行。 大家可能知道现在很多矿老板买来游戏卡也是降频挖矿，一样的道理，还省电，单位千瓦时产出更高。 产品 # 据统计 NVIDIA 当前在售的 AI 加速卡至少有 9 款型号，其中高性能的有 4 款，分别是 V100, A800, A100 及 H100\nV100 加速卡至少 1 万美元，按当前的汇率，约合 6.9 万元人民币； A800 售价 1.2 万美元，约合人民币 8.7 万元，市场一度炒高到 10 万元人民币； 服务器现货更是从 120 万涨到了 140 万元左右 A100 售价在 1.5 万美元，约合人民币 10.8 万元； H100 加速卡是 NVIDIA 当前最强的，售价 3.65 万美元，约合 26.4 万元人民币 nvml: NVIDIA Management Library # A C-based API for monitoring and managing various states of the NVIDIA GPU devices. It provides a direct access to the queries and commands exposed via nvidia-smi. The runtime version of NVML ships with the NVIDIA display driver, and the SDK provides the appropriate header, stub libraries and sample applications. Each new version of NVML is backwards compatible and is intended to be a platform for building 3rd party applications.\n"},{"id":798,"href":"/note-cs/docs/basic/cc/gpu/nvidia/list/","title":"Nvidia 显卡系列","section":"Nvidia","content":" Nvidia 显卡系列 # Nvidia 显卡系列 # 参考：\n[Nvidia] General GPU Support Tesla: 专业级显卡 # 用于对抗 AMD 的 FireStream 系列\nNVIDIA H100 Tensor Core GPU\n至于 H 系列是目前主打的旗舰产品，未来都将会是 H 系列占主导 H100 是一款针对大模型专门优化过的芯片，使用台积电 5nm 定制版本制程（4N）打造，单块芯片包含 800 亿晶体管 同时也是全球首款 PCI-E 5 和 HBM 3 显卡，一块 H100 的 IO 带宽就是 40 terabyte 每秒 NVIDIA A100 Tensor Core GPU\nNVIDIA A40\nNVIDIA A30\nNVIDIA A16\nNVIDIA A10\nTesla V100\nTesla P100\nTesla P40\nTesla P4\nTesla M60\nTesla M40\nTesla M10\nTesla M4\nTesla K40\nTesla K20\nQuadro: 专业级显卡 # RTX A6000 Ada RTX A6000 Quadro RTX 8000 Quadro RTX 6000 Quadro RTX 5000 Quadro RTX 4000 Quadro GV100 Quadro GP100 Quadro P6000 Quadro P5000 Quadro P4000 Quadro P2000 Quadro P1000 Quadro P600 Quadro P500 Quadro P400 Quadro M6000 Quadro M5000 Quadro M4000 Quadro M2000 Quadro K6000 Quadro K5200 Quadro K2200 Quadro K1200 Quadro K620 GeForce: 普通消费级显卡 # 参考：Compare: GeForce Graphics Cards\nGeForce RTX 4090 大模型的训练用 4090 是不行的，但推理（inference/serving）用 4090 不仅可行，在性价比上还能比 H100 稍高。4090 如果极致优化，性价比甚至可以达到 H100 的 2 倍。 GeForce RTX 4080 GeForce RTX 4070 Ti GeForce RTX 4070 GeForce RTX 4060 GeForce RTX 4050 GeForce RTX 3090 GeForce RTX 3080 Ti Laptop GPU GeForce RTX 3080 TI GeForce RTX 3080 GeForce RTX 3070 TI GeForce RTX 3070 GeForce RTX 3060 TI GeForce RTX 3060 GeForce RTX 3050 TI GeForce RTX 3050 NVIDIA TITAN RTX GeForce RTX 2080 Ti GeForce RTX 2080 Super GeForce RTX 2080 GeForce RTX 2070 Super GeForce RTX 2070 GeForce RTX 2060 Super GeForce RTX 2060 GeForce GTX 1660 Ti Max-Q GeForce GTX 1660 Ti GeForce GTX 1660 GeForce GTX 1650 Ti Max-Q GeForce GTX 1650 Ti GeForce GTX 1650 Max-Q GeForce GTX 1650 NVIDIA TITAN V NVIDIA TITAN Xp NVIDIA TITAN X GeForce GTX 1080 Ti GeForce GTX 1080 GeForce GTX 1070 Ti GeForce GTX 1070 GeForce GTX 1060 GeForce GTX 1050 Ti GeForce GTX 1050 GeForce GT 1030 GeForce GT 1010 GeForce GTX TITAN X GeForce GTX 980 Ti GeForce GTX 980 GeForce GTX 980M GeForce GTX 970 GeForce GTX 970M GeForce GTX 960 GeForce GTX 950 GeForce GTX 750 Ti GeForce GTX 750 GeForce GTX 745 1999 GeForce 256 2000 GeForce 2 series 2001 GeForce 3 series 2002 GeForce 4 series 2003 GeForce FX series 2004 GeForce 6 series 2005 GeForce 7 series 2006 GeForce 8 series 2008 GeForce 9 series GeForce 200 series 2009 GeForce 100 series GeForce 300 series 2010 GeForce 400 series GeForce 500 series 2012 GeForce 600 series 2013 GeForce 700 series 2014 GeForce 800M series GeForce 900 series 2016 GeForce 10 series 2018 GeForce 20 series 2019 GeForce 16 series 2020 GeForce 30 series 2022 GeForce 40 series Tegra # Tegra（中国大陆官方中文名称：“图睿”）是由 NVIDIA 开发的系统单芯片系列产品，2008 年 6 月 1 日正式发表，替代之前的 GoForce 系列。主要用于手持式装置。Tegra 可搭配 NVIDIA 专为智能手机及平板电脑开发的 NVIDIA Icera 系列芯片组。Tegra 的主要竞争对手是高通和德州仪器的对应产品。\nNvida 系列 # Nvidia HGX # NVIDIA HGX 是一个计算平台，通过 NVLink 和 NVSwitch 将多个 GPU 串连起来，提供强大的 AI 运算能力。\nHGX 是一个计算模组，DGX 是一个完整的主机 Nvidia DGX # 2023 年 5 月 29 日，NVIDIA DGX™ 超级计算机发布\nNVIDIA DGX 是 AI 超级计算机。硬件方面包含：GPU、CPU、内存、硬盘、散热系统、软件、操作系统等等，也就是说，除了显示器、键盘、鼠标，它全都有。\nNVIDIA 今日宣布推出第四代 NVIDIA® DGX™ 系统，这是全球首个基于全新 NVIDIA H100 Tensor Core GPU 的 AI 平台，它也是全球最先进的企业级 AI 基础设施。DGX H100 系统能够满足大型语言模型、推荐系统、医疗健康研究和气候科学的大规模计算需求。每个 DGX H100 系统配备八块 NVIDIA H100 GPU，并由 NVIDIA NVLink® 连接，能够在新的 FP8 精度下达到 32 Petaflop 的 AI 性能，比上一代系统性能高 6 倍。\nNVIDIA DGX™ A100 NVIDIA DGX H100 "},{"id":799,"href":"/note-cs/docs/basic/cc/gpu/nvidia/arch/","title":"Nvidia 架构","section":"Nvidia","content":" Nvidia 架构 # Fahrenheit Celsius Kelvin Rankine Curie 2008 Tesla: 市面已经没有相关显卡 2010 Fermi: GeForce 400, 500, 600, GT-630 2012 Kepler: K40/K80, GeForce 700, GT-730 2014 Maxwell: Tesla/Quadro M series GeForce 900, GTX-970 2016 Pascal: P4, P100, GTX 1080, GTX 1070, GTX 1060 2017 Volta: V100, GTX 1180, TiTan V 首次引入 Tensor Core 2018 Turing: T4, GTX 1660 Ti, RTX 2060, RTX 5000 2020 Ampere: A2, A10, A16, A30, A40, A100, GTX 3080 2022 Hopper: H100, H200 2022 Ada Lovelace: 4090, L4, L40, L40S 2024 Blackwell: B40, B100, B200 14. Blackwell # 13. Ada Lovelace vs Hopper # Ada Lovelace (consumer) # officially announced on 2022-09-20\nRTX 40 系列 GeForce RTX 4090 Hopper (professional) # H100 今年 3 月，英伟达发布了新一代基于 4nm 工艺，拥有 800 亿个晶体管、18432 个核心的 H100 GPU H100 加速卡是 NVIDIA 当前最强的，售价 3.65 万美元，约合 26.4 万元人民币 芯片的数据传输速率为 800GB/s H800 芯片的数据传输速率为 400GB/s 12. Ampere (consumer, professional) # 安培微架构（Ampere）是 NVIDIA 于 2020 年 5 月发布的一个 GPU 架构。用以取代图灵微架构（Turing microarchitecture）。命名为“安培”以向法国物理学家安德烈-马里·安培（André-Marie Ampère）致敬。Ampere 架构拥有晶体管达 540 亿，是三星 8nm 级芯片。是世界上晶体管最多的芯片，直到后来被苹果 M1 Max 击败。\nRTX 30 系列\nGeForce MX series\nGeForce MX570 (mobile) (GA107) GeForce 20 series\nGeForce RTX 2050 (mobile) (GA107) GeForce 30 series\nGeForce RTX 3050 Laptop GPU (GA107) GeForce RTX 3050 (GA106 or GA107) GeForce RTX 3050 Ti Laptop GPU (GA107) GeForce RTX 3060 Laptop GPU (GA106) GeForce RTX 3060 (GA106 or GA104) GeForce RTX 3060 Ti (GA104 or GA103) GeForce RTX 3070 Laptop GPU (GA104) GeForce RTX 3070 (GA104) GeForce RTX 3070 Ti Laptop GPU (GA104) GeForce RTX 3070 Ti (GA104 or GA102) GeForce RTX 3080 Laptop GPU (GA104) GeForce RTX 3080 (GA102) GeForce RTX 3080 12GB (GA102) GeForce RTX 3080 Ti Laptop GPU (GA103) GeForce RTX 3080 Ti (GA102) GeForce RTX 3090 (GA102) GeForce RTX 3090 Ti (GA102) Nvidia Workstation GPUs (formerly Quadro)\nRTX A1000 (mobile) (GA107) RTX A2000 (mobile) (GA107) RTX A2000 (GA106) RTX A3000 (mobile) (GA104) RTX A4000 (mobile) (GA104) RTX A4000 (GA104) RTX A4500 (GA102) RTX A5000 (mobile) (GA104) RTX A5000 (GA102) RTX A5500 (GA102) RTX A6000 (GA102) Nvidia Data Center GPUs (formerly Tesla)\nNvidia A2 (GA107) Nvidia A10 (GA102), 24GB 显存 Nvidia A16 (4 × GA107) Nvidia A30 (GA100) Nvidia A40 (GA102) Nvidia A100 (GA100) / NVIDIA A100 Tensor Core GPU 芯片的数据传输速率为 600GB/s NVIDIA A800 40GB 芯片的数据传输速率为 400GB/s A800 只影响多卡互联的性能，而计算能力完全保留 11. Turing vs Volta # Turing（consumer 消费） # 2018\nRTX 20 系列\nGTX 16 系列\nTesla T4\n按照英伟达的说法，Tesla T4 是为推理而生的。 在语音识别模型 DeepSpeech 2 上，T4 比 P4 的 5 倍还要快； 在神经网络翻译模型 GNMT 上，T4 的速度接近 P4 的 4 倍； 在图像识别模型 ResNet-50 上，T4 也接近 P4 的 3 倍。 在 T4 诞生之前，P4 在深度学习界的地位，也是很崇高的。 Volta（ professional 专业） # 2017\nV100 32GB V100 16GB 10 Pascal # 2016\nGTX 10 系列 P100 Tesla P4 2016 年 9 月 13 日，GTC China 大会上，NVIDIA 发布了 Tesla P4 GPU。这是一块采用 Pascal 架构、2560 个 CUDA 核心、8GB GDDR5 显存、显存带宽 192.0GB/S 半高 Data Center 系列 GPU。 Tesla P4 的 GPU 算力为 6.1，核心代号为 GP104，同 GTX1080 一样。具有 4 个 GPC，20 个 SM 单元，每个 GPC 有 5 个 SM，每个 SM 有 128 个 CUDA 核心，共计 2560 个 CUDA 核心，提供 5.5TFLOPS 的单精度计算性能，，256KB 寄存器，96KB 的 Shared Memory，总共 48KB 的 L1 缓存和 8 个纹理单元。 P4 是专业卡，其实就是老黄为了坑钱给专业人士弄的卡。性能和 1080 一样。做某些程序时 1080 会负优化，但有办法可以解除这个限制。所以专业卡一般等于智商税 9. Maxwell # 2014\nGTX 900 系列 8. Kepler # 2012\n7. Fermi # 2010\n6. Tesla # 2008\n5. Curie # 4. Rankine # 3. Kelvin # 2. Celsius # 1. Fahrenheit # "},{"id":800,"href":"/note-cs/docs/tool/linux/centos/nvidia/","title":"nvidia 驱动","section":"4.2.2 CentOS","content":" nvidia 驱动 # "},{"id":801,"href":"/note-cs/docs/basic/cc/gpu/nvidia/driver/","title":"Nvidia 驱动","section":"Nvidia","content":" Nvidia 驱动 # 显卡类型 说明 GeForce RTX 游戏卡 TITAN 游戏发烧卡, 深度学习屌丝卡 NVIDIA RTX / Quadro 图形卡 Data Center / Tesla 计算卡 GRID 物理卡：只有 GRID K1/K2 两个型号，早停产。 虚拟卡：Quadro 系列或者是 Tesla 系列分出来的多张虚拟显卡 Networking NVS ION apt install -y ubuntu-drivers-common # 查询推荐的 nvidia 驱动 ubuntu-drivers devices # 按推荐安装驱动 apt install -y nvidia-driver-535 # https://download.nvidia.com/XFree86/Linux-x86_64/ curl -LO https://download.nvidia.com/XFree86/Linux-x86_64/550.163.01/NVIDIA-Linux-x86_64-550.163.01.run bash NVIDIA-Linux-x86_64-550.163.01.run # CUDA Toolkit: 12.2 # Driver Version: 535.54.03 # Release Date: 2023.6.26 curl -LO https://us.download.nvidia.com/tesla/535.54.03/NVIDIA-Linux-x86_64-535.54.03.run bash NVIDIA-Linux-x86_64-535.54.03.run # CUDA Toolkit: 12.0 # Driver Version: 525.60.13 # Release Date: 2022.12.5 curl -LO https://us.download.nvidia.com/tesla/525.60.13/NVIDIA-Linux-x86_64-525.60.13.run bash NVIDIA-Linux-x86_64-525.60.13.run # CUDA Toolkit: 11.7 # Driver Version: 515.86.01 # Release Date: 2022.11.22 curl -LO https://us.download.nvidia.com/tesla/515.86.01/NVIDIA-Linux-x86_64-515.86.01.run bash NVIDIA-Linux-x86_64-515.86.01.run # CUDA Toolkit: 11.6 # Driver Version: 510.108.03 # Release Date: 2022.11.22 curl -LO https://us.download.nvidia.com/tesla/510.108.03/NVIDIA-Linux-x86_64-510.108.03.run bash NVIDIA-Linux-x86_64-510.108.03.run # CUDA Toolkit: 11.4 # Driver Version: 470.161.03 # Release Date: 2022.11.22 curl -LO https://us.download.nvidia.com/tesla/470.161.03/NVIDIA-Linux-x86_64-470.161.03.run bash NVIDIA-Linux-x86_64-470.161.03.run # CUDA Toolkit: 11.2 # Driver Version: 460.106.00 # Release Date: 2021.10.26 curl -LO https://us.download.nvidia.com/tesla/460.106.00/NVIDIA-Linux-x86_64-460.106.00.run bash NVIDIA-Linux-x86_64-460.106.00.run # CUDA Toolkit: 11.0 # Driver Version: 450.216.04 # Release Date: 2022.11.22 curl -LO https://us.download.nvidia.com/tesla/450.216.04/NVIDIA-Linux-x86_64-450.216.04.run bash NVIDIA-Linux-x86_64-450.216.04.run # CUDA Toolkit: 10.2 # Driver Version: 440.118.02 # Release Date: 2020.9.30 curl -LO https://us.download.nvidia.com/tesla/440.118.02/NVIDIA-Linux-x86_64-440.118.02.run bash NVIDIA-Linux-x86_64-440.118.02.run # CUDA Toolkit: 10.1 # Driver Version: 418.226.00 # Release Date: 2021.10.26 curl -LO https://us.download.nvidia.com/tesla/418.226.00/NVIDIA-Linux-x86_64-418.226.00.run bash NVIDIA-Linux-x86_64-418.226.00.run # CUDA Toolkit: 10.0 # Driver Version: 410.129 # Release Date: 2019.9.4 curl -LO https://us.download.nvidia.com/tesla/410.129/NVIDIA-Linux-x86_64-410.129.run bash NVIDIA-Linux-x86_64-410.129.run 卸载 nvidia driver # # 方法一 dpkg -l | grep -i nvidia sudo apt-get remove --purge \u0026#39;^nvidia-.*\u0026#39; # If the ubuntu-desktop package is removed, reinstall it with the following command: # sudo apt-get install ubuntu-desktop # 方法二 sh NVIDIA-Linux-x86_64-535.54.03.run --uninstall nvidia-smi # nvidia-smi 右上角显示的 CUDA Version: 是指支持的最高版本的 cuda\nSMI: System Management Interface\n# 查询全部信息 nvidia-smi -q # 查询 gpu 架构 nvidia-smi -q | grep Product # 拓扑信息 nvidia-smi topo -m # GPU 利用率统计 nvidia-smi --format=csv,noheader,nounits --query-gpu=timestamp,index,memory.total,memory.used,memory.free,utilization.gpu,utilization.memory -lms 500 -f gup.log # 筛选 gpu2 awk -F\u0026#34;,\u0026#34; \u0026#39;{ if($2==2){print $0} } \u0026#39; smi-1-90s-instance.log \u0026gt; gpu2.log # 计算 gpu 平均利用率 cat gpu2.log| awk \u0026#39;{sum7+=$7;count++} END {print sum7/count}\u0026#39; # 动态观察 GPU 的状态（原地刷新） watch -n 0.5 nvidia-smi # 5 秒刷新一次 nvidia-smi -l 5 "},{"id":802,"href":"/note-cs/docs/basic/cc/gpu/nvidia/nvidia-docker/","title":"nvidia-docker","section":"Nvidia","content":" nvidia-docker # 因为 GPU 属于特定的厂商产品，需要特定的 driver， Docker 本身并不支持 GPU。 以前如果要在 Docker 中使用 GPU，就需要在 container 中安装主机上使用 GPU 的 driver， 然后把主机上的 GPU 设备（例如：/dev/nvidia0）映射到 container 中。 所以这样的 Docker image 并不具备可移植性。\nNvidia-docker 项目就是为了解决这个问题， 它让 Docker image 不需要知道底层 GPU 的相关信息，而是通过启动 container 时 mount 设备和驱动文件来实现的。\nNVIDIA Container Toolkit # NVIDIA Container Toolkit（以前称为 NVIDIA Docker）是一个更全面的工具集，包括了 NVIDIA Container Runtime，以及其他工具和库，使得在 Docker 和其他容器平台上能够方便地部署和管理 GPU 加速的容器应用。\nToolkit 主要包括以下几个组件：\nlibnvidia-container: 一个库，用于构建和运行 NVIDIA GPU 加速的容器，无论宿主机的配置如何。\nnvidia-container-runtime: 实际的容器运行时，可以集成到 Docker 和其他容器平台。\nnvidia-docker2: 一个便捷的包，包括 Docker 插件和 nvidia-container-runtime，简化了使用 Docker 运行 GPU 加速容器的过程。\n依赖关系如下：\n├─ nvidia-container-toolkit (version) │ ├─ libnvidia-container-tools (\u0026gt;= version) │ └─ nvidia-container-toolkit-base (version) │ ├─ libnvidia-container-tools (version) │ └─ libnvidia-container1 (\u0026gt;= version) └─ libnvidia-container1 (version) # 二进制 /usr/bin/nvidia-container-runtime /usr/bin/nvidia-container-runtime-hook /usr/bin/nvidia-container-toolkit /usr/bin/nvidia-container-cli /usr/bin/nvidia-ctk # 库文件 $ ldconfig -p | grep libnvidia-container libnvidia-container.so.1 (libc6,x86-64) =\u0026gt; /usr/lib64/libnvidia-container.so.1 libnvidia-container-go.so.1 (libc6,x86-64) =\u0026gt; /usr/lib64/libnvidia-container-go.so.1 NVIDIA/nvidia-container-toolkit NVIDIA/nvidia-docker The nvidia-docker wrapper is no longer supported, and the NVIDIA Container Toolkit has been extended to allow users to configure Docker to use the NVIDIA Container Runtime. NVIDIA/nvidia-container-runtime This project has been superseded by the NVIDIA Container Toolkit. "},{"id":803,"href":"/note-cs/docs/tool/linux/ubuntu/obsidian/","title":"obsidian","section":"4.2.1 Ubuntu","content":" obsidian # 同步数据 # obsidian-livesync # vrtmrz/obsidian-livesync self-hosted-livesync-server # mkdir obsidian cd obsidian git clone https://github.com/vrtmrz/self-hosted-livesync-server cd self-hosted-livesync-server # Create Caddy\u0026#39;s network docker network create caddy # 看教程 https://github.com/vrtmrz/self-hosted-livesync-server export COUCHDB_SERVER=\u0026#34;couchdb3.kingye.me\u0026#34; export COUCHDB_USER=\u0026#34;kingye\u0026#34; export COUCHDB_PW=\u0026#34;\u0026#34; # vim docker-compose.yml # 把和 nginx 冲突的 80 端口改成其他的，比如 8080 # - \u0026#34;8080:80\u0026#34; # 宿主机端口:容器端口 # docker compose version docker-compose -f docker-compose.yml up -d "},{"id":804,"href":"/note-cs/docs/tool/macos/ollama/","title":"Ollama","section":"4.1 MacOS","content":" Ollama # 使用教程 # ollama list ollama run qwen2:0.5b "},{"id":805,"href":"/note-cs/docs/tool/macos/orbstack/","title":"OrbStack","section":"4.1 MacOS","content":" OrbStack # cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; ~/.orbstack/config/docker.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker.kingye.me\u0026#34; ] } EOF docker info | grep -A 1 \u0026#34;Registry Mirrors\u0026#34; "},{"id":806,"href":"/note-cs/docs/tool/linux/ubuntu/php/","title":"PHP","section":"4.2.1 Ubuntu","content":" PHP # 安装 # sudo apt-get -y install php-fpm "},{"id":807,"href":"/note-cs/docs/tool/macos/picgo/","title":"picgo","section":"4.1 MacOS","content":" picgo # CLI 命令 # PicGo/PicGo-Core # Molunerfinn/PicGo # picgo vscode 快捷键 # Windows/Unix Uploading an image from clipoard: Ctrl + Alt + U Uploading images from explorer: Ctrl + Alt + E Uploading an image from input box: Ctrl + Alt + O OsX Uploading an image from clipboard: Cmd + Opt + U Uploading images from explorer: Cmd + Opt + E Uploading an image from input box: Cmd + Opt + O "},{"id":808,"href":"/note-cs/docs/tool/linux/ubuntu/pip/","title":"pip","section":"4.2.1 Ubuntu","content":" pip # # 设置 镜像源 python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade pip pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 临时安装 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple xxxx "},{"id":809,"href":"/note-cs/docs/tool/linux/ubuntu/pipenv/","title":"pipenv","section":"4.2.1 Ubuntu","content":" pipenv # pypa/pipenv # 进入虚拟环境 pipenv shell pipenv shell --python=3.10 # 退出虚拟环境 exit 设置镜像源 # # vim Pipfile [[source]] # url 替换成这个源 url = \u0026#34;https://pypi.tuna.tsinghua.edu.cn/simple\u0026#34; 如果没有 Pipfile 指定，pipenv 默认使用最高版本的 python\nPipenv uses a different finding approach that the highest version goes first. You can anyway pass the python version by pipenv install \u0026ndash;python=3.7.\n"},{"id":810,"href":"/note-cs/docs/tool/linux/centos/pipx/","title":"pipx","section":"4.2.2 CentOS","content":" pipx # "},{"id":811,"href":"/note-cs/docs/tool/linux/ubuntu/pipx/","title":"pipx","section":"4.2.1 Ubuntu","content":" pipx # pypa/pipx pipx 相对于 pip 的一些主要优点：\n隔离环境：pipx 为每个安装的应用创建一个独立的虚拟环境。这意味着每个应用及其依赖都被隔离，避免了依赖冲突和版本问题，这是直接使用 pip 安装到全局或用户环境中可能遇到的常见问题。 避免污染全局环境：使用 pipx 安装应用不会影响全局的 Python 环境，这使得系统更加干净、有序。这对于只需要作为命令行工具运行的 Python 包尤其有用，因为它们不需要与其他 Python 项目的依赖交互。 简易升级和移除：通过 pipx 安装的应用易于升级和移除，因为每个应用都在其自己的环境中，不会影响到其他应用。pipx 提供简单的命令来管理这些应用，如 pipx upgrade、pipx uninstall 等。 直接从源码安装：pipx 可以直接从源码安装应用，包括从 git 仓库。这使得测试开发中的工具或者尝试最新功能变得更加容易。 全局可用：虽然每个应用都安装在隔离的环境中，但 pipx 确保这些应用的命令行界面（CLI）是全局可访问的，这为用户提供了便利。 自动处理可执行文件：pipx 在安装包时会自动将其提供的可执行文件链接到公共的二进制目录中，用户无需额外配置就可以直接在命令行中使用这些工具。 总的来说，pipx 特别适合用来管理和使用命令行工具或者需要隔离的 Python 应用，而 pip 更适合于在开发环境中管理库的依赖关系。对于一般的库依赖管理，尤其是在开发项目中，使用 pip 配合虚拟环境（如 venv）通常是更合适的选择。\n安装 # apt install -y pipx 使用教程 # "},{"id":812,"href":"/note-cs/docs/tool/macos/plantuml/","title":"PlantUML","section":"4.1 MacOS","content":" PlantUML # plantuml/plantuml PlantUML 是一个开源项目，支持快速绘制时序图、用例图、类图、活动图、组件图、状态图、对象图、部署图等。同时还支持非 UML 图的甘特图、架构图等。\n"},{"id":813,"href":"/note-cs/docs/tool/linux/ubuntu/poetry/","title":"poetry","section":"4.2.1 Ubuntu","content":" poetry # python-poetry/poetry # 安装 pipx install poetry # tab completion, 参考：https://python-poetry.org/docs/#enable-tab-completion-for-bash-fish-or-zsh mkdir $ZSH_CUSTOM/plugins/poetry poetry completions zsh \u0026gt; $ZSH_CUSTOM/plugins/poetry/_poetry # 在 ~/.zshrc 的 plugins 里面加上 poetry，再执行 zsh # plugins( # poetry # ... # ) 教程 # Poetry replaces setup.py, requirements.txt, setup.cfg, MANIFEST.in and Pipfile with a simple pyproject.toml based project format.\nPoetry will not automatically install a python interpreter for you.\n# 新建项目 poetry new poetry-demo # 从已有的项目初始化 cd pre-existing-project poetry init # 进入虚拟环境，还会打开一个嵌套的 shell poetry shell # 1. 退出虚拟环境 deactivate # 2. 退出虚拟环境，并退出会话，丢失当前会话的所有上下文和未保存的状态 exit # 添加新的依赖 poetry add # 查看依赖 poetry show poetry show --tree poetry show --outdated # 更新 dependencies # This is equivalent to deleting the poetry.lock file and running install again poetry update # 移除依赖 poetry remove # https://python-poetry.org/docs/configuration/#cache-dir # 虚拟环境目录 cd ~/Library/Caches/pypoetry 版本说明 # 脱字符号 ^: 最左侧非零数字不能变 ^1.2: 1.2 \u0026lt;= 版本号 \u0026lt; 2.0 ^0.2.3: 0.2.3 \u0026lt;= 版本号 \u0026lt; 0.3.0 ^1.2.3: 1.2.3 \u0026lt;= 版本号 \u0026lt; 2.0.0 波浪号运算符 ~: 下一个重要版本（右侧第二位不能变） ~1.2: 1.2 \u0026lt;= 版本号 \u0026lt; 2.0 ~0.2.3: 0.2.3 \u0026lt;= 版本号 \u0026lt; 0.3.0 ~1.2.0: 1.2.0 \u0026lt;= 版本号 \u0026lt; 1.3.0 ~1.2.3: 1.2.3 \u0026lt;= 版本号 \u0026lt; 1.3.0 参考：语义化版本\n"},{"id":814,"href":"/note-cs/docs/tool/linux/ubuntu/pyenv/","title":"pyenv","section":"4.2.1 Ubuntu","content":" pyenv # pyenv/pyenv 安装 # curl https://pyenv.run | bash echo \u0026#39;export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;[[ -d $PYENV_ROOT/bin ]] \u0026amp;\u0026amp; export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;eval \u0026#34;$(pyenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # git clone https://github.com/pyenv/pyenv.git ~/.pyenv # 使用 taobao 的 npm 源 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc function pyenvinstall { wget -c https://registry.npmmirror.com/-/binary/python/$@/Python-$@.tar.xz -P ~/.pyenv/cache/ pyenv install \\$@ } EOF zsh 安装依赖 # 之后才能编译 python 成功\nsudo apt update sudo apt install -y \\ gcc \\ build-essential \\ curl \\ libbz2-dev \\ libffi-dev \\ liblzma-dev \\ libncursesw5-dev \\ libreadline-dev \\ libsqlite3-dev \\ libssl-dev \\ libxml2-dev \\ libxmlsec1-dev \\ llvm \\ make \\ tk-dev \\ wget \\ xz-utils \\ zlib1g-dev 使用 # pyenv # 列出所有可安装 python 版本 pyenv install -l # 安装 pyenv install 3.12.0 # 使用上面 .zshrc 定义的 npm 源 pyenvinstall 3.12.0 pyenvinstall 3.11.6 pyenvinstall 3.10.13 pyenvinstall 3.9.15 pyenvinstall 3.8.15 pyenvinstall 3.7.15 pyenvinstall 3.6.15 pyenvinstall 2.7.18 # 列出已安装 python 版本 pyenv versions pyenv global 3.10 # pyenv global 3.10 2.7 # writing the version name to a .python-version file in the current directory. pyenv local 3.10 "},{"id":815,"href":"/note-cs/docs/tool/macos/pyenv/","title":"pyenv","section":"4.1 MacOS","content":"pyenv/pyenv 安装 # 使用 # "},{"id":816,"href":"/note-cs/docs/tool/linux/centos/python/","title":"python","section":"4.2.2 CentOS","content":" python # # 安装 pipx # sudo yum install -y python3 python3 -m pip install --user pipx python3 -m pipx ensurepath # 升级 # python3 -m pip install --user --upgrade pipx # 再安装 poetry pipx install poetry # 安装 poetry # curl -sSL https://install.python-poetry.org | python3 - # 安装 pyenv curl https://pyenv.run | bash "},{"id":817,"href":"/note-cs/docs/tool/linux/ubuntu/python/","title":"python","section":"4.2.1 Ubuntu","content":" python # apt install -y pipx pipx install poetry "},{"id":818,"href":"/note-cs/docs/tool/macos/python/","title":"python","section":"4.1 MacOS","content":" python # # 先安装 pipx brew update brew install pipx # 再安装 poetry pipx install poetry # 安装 pyenv brew install pyenv # 从镜像下载 cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc function pyenvinstall { wget -c https://registry.npmmirror.com/-/binary/python/$@/Python-$@.tar.xz -P ~/.pyenv/cache/ pyenv install $@ } EOF zsh # 更新 pyenv 缓存 pyenv update # 列出可选的版本 pyenv install -l # 安装需要的 python 版本 pyenvinstall 3.13.1 "},{"id":819,"href":"/note-cs/docs/tool/linux/centos/pytorch/","title":"pytorch","section":"4.2.2 CentOS","content":" pytorch # install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia "},{"id":820,"href":"/note-cs/docs/tool/linux/ubuntu/pytorch/","title":"pytorch","section":"4.2.1 Ubuntu","content":" pytorch # # cuda 11.4 conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch "},{"id":821,"href":"/note-cs/docs/tool/macos/pytorch/","title":"pytorch","section":"4.1 MacOS","content":" pytorch # # 安装 # cd ~/code/study/ai/pytorch/study-pytorch/hello-pytorch mamba create -n hello-pytorch mamba activate hello-pytorch mamba install -y pytorch::pytorch torchvision torchaudio -c pytorch mamba install --file requirements.txt "},{"id":822,"href":"/note-cs/docs/basic/cc/rom/","title":"ROM","section":"1.1 计算机组成原理","content":" ROM: Read-only memory, 只读存储器 # ROM 有 5 种类型：\n掩膜编程的只读存储器 MROM（Mask-programmedROM） 可编程的只读存储器 PROM（Programmable ROM） 可擦除可编程的只读存储器 EPROM（Erasable Programmable ROM） 可电擦除可编程的只读存储器 EEPROM（Elecrically Erasable Programmable ROM） 快擦除读写存储器（Flash Memory） Memory Card 是一种使用 Flash Memory 技术的可移动存储卡 EPROM: Erasable Programmable Read-Only Memory 可擦除可编程式只读存储器 # EEPROM: Electrically-Erasable Programmable Read-Only Memory 电子式可擦除可编程只读存储器 # Flash memory 闪存 # 也叫快闪内存 手机上的闪存通常分为 eMMC UFS Universal Flash Storage, 通用闪存存储 UFS 卡被视作嵌入式多媒体记忆卡（embedded Multi Media Card，eMMC）和 SD 卡的取代者 UFS 相较 eMMC 最大的不同是并行信号改为了更加先进的串行信号，从而可以迅速提高频率；同时半双工改为全双工 UFS 基于小型电脑系统介面（SCSI）结构模型（SCSI Architectural Model）以及支援 SCSI 标记指令序列（SCSI Tagged Command Queuing） 2011-02 JEDEC 固态技术协会（JEDEC）研发了 UFS 1.0 标准，2013-09 发布 2.0，2016-04 发布 2.1，2018-01 发布 3.0，2020-01 发布 3.1，2020-08 发布 2.2，2022-08 发布 4.0 UFS Card: 2016-03 发布 1.0，2018-01 发布 1.1，2020-12 发布 3.0 NVME（特用于苹果设备中的闪存） NVM Express, 或称非易失性内存主机控制器接口规范 Non-Volatile Memory Host Controller Interface Specification，缩写：NVMHCIS NVM: Non-Volatile Memory 非挥发性内存 手机的闪存的内部构造与 U 盘和 SSD 的差异不大，同样具备了 NAND（存储数据的 MLC/TLC 闪存颗粒）以及负责控制数据传输和闪存磨损平衡的主控 IC。只是因为手机内部空间有限，两者是终被封装到同一块芯片内。 SSD: Solid State Disk 或 Solid State Drive，固态驱动器，是用固态电子存储芯片阵列制成的硬盘 SSD 其实也是 Flash 为什么现在市面上很少见到采用 eMMC 作为存储芯片的固态硬盘主控？ 市面上的 SSD 主控早就实现了 NAND 颗粒的多通道读写，具体可以类比多通道内存。这样看来，将多块 eMMC 组成类似 RAID 而后再包装成 SSD，无论是性能上还是耐久度上均无任何优势 Flash memory 在分类上属于 EEPROM 的一种，但一般业界所讲的 EEPROM 指的是那种非快闪式的普通 EEPROM，并不是指它 eMMC: embedded MMC # MMC: MultiMediaCard MMC 是一个相当古老的外置存储卡标准了，当年同台竞技的还有 CF（Compact Flash） The currently implemented eMMC architecture puts the MMC components (flash memory and controller) into a small ball grid array (BGA) IC package for use in circuit boards as an embedded non-volatile memory system. eMMC 本质上只是一个面向嵌入式设备的 I/O interface 及其物理层实现的标准集 eMMC 其实是 MMC 标准的近亲，多出来的一个 e 是嵌入式的首字母，因此这和 SD 卡家族不一样，面向的是要焊在电路板上的使用场景，eMMC 采用了 BGA 的封装标准 一块 eMMC 的芯片里面至少要包括三个功能组件：Flash、Flash 控制器还有 MMC 的总线控制器 eMMC 其实是从 Nand 进化而来 eMMC 是封装和引脚都是标准的，而 Nand 的接口和时序不标准 这个标准体现在至少三个方面：物理封装、硬件电平和脚位、软件时序 所有的 eMMC 芯片，不管是哪家厂家的，不管是多大容量的，都可以直接替换使用 eMMC 的引脚比 Nand 也更少，体积也更小 eMMC 基本都是 MLC Nand，因为便宜啊 eMMC 基本等于 U 盘，都是简单的主控 + Nand Flash NOR flash # NAND flash # Nand 内部的存储单元有两大类：\nSLC Nand 容量小价格高，但是质量好不容易坏 市场上流通的 Nand 很多还是 SLC 因为 MLC 太容量出现坏块和翻转等，所以广泛使用的 Nand 还都是 SLC 的。你如果直接用 MLC Nand，那你的管理成本就很高。 而 eMMC 解决了这个问题，他内置的控制器很好的管理了 MLC Nand，因此可以做到容量很大、使用简单，还便宜。 所以说，能干脏活就是生产力啊 如果你的产品需要大容量（譬如超过 8Gb 也就是 1GB 或更大），那一定是 eMMC 更合适。性价比更高，且软件上更简单。 那什么时候用 Nand 呢？需要容量在几十 MB（譬如 64MB）到几百个 MB（譬如 512MB）之间的存储，且不在意体积，且对稳定性要求高的情况下，可以用 SLC Nand MLC Nand 容量大价格便宜，但是质量不好容易出现坏块。 Flash Memory 是一种存储技术，而 Memory Card 是这项技术的一种物理实现，设计成可移动的形式以便于使用者在不同设备之间传输数据。 Flash Memory 的应用更为广泛，不仅包括可移动的 Memory Card，还包括内置于多种电子设备中的固定存储解决方案。 除了 Memory Card 之外，还有许多设备和存储解决方案使用了 Flash Memory 技术： USB 闪存驱动器（又称 U 盘）：便携式存储设备，通过 USB 接口连接电脑或其他设备，用于数据的存储和传输。 固态硬盘（SSD）：使用 Flash Memory 作为存储介质的硬盘，比传统的机械硬盘（HDD）速度更快，且更耐用、耗电量更低。SSD 现在是现代电脑和笔记本的标配存储设备。 智能手机和平板电脑内部存储：大多数智能手机和平板电脑使用 Flash Memory 作为其内部存储解决方案，用于存储操作系统、应用程序和用户数据。 嵌入式系统：许多嵌入式系统和微控制器使用 Flash Memory 来存储固件或软件，这些系统广泛应用于汽车电子、家用电器、工业控制等领域。 数字相机和摄像机：用于存储照片和视频文件。虽然这些设备经常使用 Memory Card 作为可移动存储，但它们也可能有内置的 Flash Memory 作为额外的存储选项。 游戏控制器和掌上游戏机：许多游戏设备，如游戏控制器和掌上游戏机，也使用 Flash Memory 来存储游戏数据、下载的内容和系统软件。 网络存储设备（NAS）：部分网络附加存储设备使用 Flash Memory 作为操作系统的存储介质，以提高系统的响应速度和稳定性。 Wearable Devices（可穿戴设备）：智能手表、健身追踪器等可穿戴设备使用 Flash Memory 来存储操作系统、应用程序和用户数据。 Memory Stick：由索尼公司开发的一种数据存储设备，主要用于其数码相机、摄像机和其他电子产品。 "},{"id":823,"href":"/note-cs/docs/tool/macos/ruby/","title":"ruby","section":"4.1 MacOS","content":" ruby # 安装 # brew install ruby\nIf you need to have ruby first in your PATH, run: echo \u0026#39;export PATH=\u0026#34;/opt/homebrew/opt/ruby/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc For compilers to find ruby you may need to set: export LDFLAGS=\u0026#34;-L/opt/homebrew/opt/ruby/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/ruby/include\u0026#34; For pkg-config to find ruby you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/ruby/lib/pkgconfig\u0026#34; "},{"id":824,"href":"/note-cs/docs/direction/be/auth/sso/saml/","title":"SAML","section":"SSO","content":" SAML # 1.0 # 2.0 # 参考 # How SAML Authentication Works "},{"id":825,"href":"/note-cs/docs/basic/pl/scala/","title":"Scala","section":"1.5 编程语言","content":" Scala # 详见：Scala 学习笔记\n"},{"id":826,"href":"/note-cs/docs/tool/linux/ubuntu/sealos/","title":"sealos","section":"4.2.1 Ubuntu","content":" sealos # labring/sealos sealos run registry.cn-shanghai.aliyuncs.com/labring/kubernetes:v1.30.5 registry.cn-shanghai.aliyuncs.com/labring/helm:v3.16.2 registry.cn-shanghai.aliyuncs.com/labring/cilium:v1.15.8 --single laf # # curl -LO https://raw.githubusercontent.com/labring/laf/refs/heads/main/deploy/install-on-linux.sh # sed -i \u0026#39;s#sealos pull labring#sealos pull registry.cn-shanghai.aliyuncs.com/labring#g\u0026#39; install-on-linux.sh # install required components sealos run registry.cn-shanghai.aliyuncs.com/labring/openebs:v1.9.0 sealos run registry.cn-shanghai.aliyuncs.com/labring/cert-manager:v1.8.0 sealos run registry.cn-shanghai.aliyuncs.com/labring/metrics-server:v0.6.2 sealos run registry.cn-shanghai.aliyuncs.com/labring/ingress-nginx:v1.8.1 \\ -e HELM_OPTS=\u0026#34;--set controller.hostNetwork=true --set controller.kind=DaemonSet --set controller.service.enabled=false\u0026#34; sealos run registry.cn-shanghai.aliyuncs.com/labring/kubeblocks:v0.7.1 sealos run --env DOMAIN=$DOMAIN --env DB_PV_SIZE=5Gi --env OSS_PV_SIZE=5Gi --env EXTERNAL_HTTP_SCHEMA=http registry.cn-shanghai.aliyuncs.com/labring/laf:latest "},{"id":827,"href":"/note-cs/docs/basic/cc/gpu/nvidia/SM-Version/","title":"SM Version","section":"Nvidia","content":" SM Version # SM Version # Compute Capability 也就是 SM Version Compute Capability 是一个硬件和架构的特性指标。Compute Capability 告诉你 GPU 支持哪些功能和指令集，而 TOPS 告诉你 GPU 能有多快。 NVIDIA 的 SM（Streaming Multiprocessor）版本指的是其 GPU（图形处理单元）架构中的流式多处理器的设计和版本。流式多处理器是 NVIDIA GPU 的基本计算单元，负责执行并行计算任务。每个版本的 SM 都有其特定的特性、计算能力和架构优化，这些都会直接影响到 GPU 的性能、能效和支持的功能。\n1.x Tesla Compute Capability 1.x 对应于 NVIDIA 的 Tesla 架构，这是 NVIDIA 第一代支持 CUDA 的 GPU 架构，引入了基本的 GPGPU（通用计算在图形处理单元上）计算能力。 2.x Fermi 3.x Kepler Compute Capability 版本号从 3.x（Kepler）直接跳到了 5.x（Maxwell），跳过了 4.x 5.x Maxwell 6.x Pascal 7.x Volta 7.5 Turing 8.x Ampere 9.x Hopper "},{"id":828,"href":"/note-cs/docs/tool/macos/ssh/","title":"ssh","section":"4.1 MacOS","content":" ssh # ssh-keygen # 代理 # ssh -o ProxyCommand=\u0026#39;socat - SOCKS4A:myproxy:%h:%p,socksuser=nobody\u0026#39; user@host # SOCKS5 ssh -o ProxyCommand=\u0026#39;socat - \u0026#34;SOCKS5:%h:%p|tcp:myproxy:1080\u0026#34;\u0026#39; user@host # http ssh -o ProxyCommand=\u0026#39;socat - \u0026#34;PROXY:%h:%p|tcp:myproxy:80\u0026#34;\u0026#39; user@host 参考：\nConnecting to host by SSH client in Linux by proxy my config # Host github HostName github.com User git IdentityFile ~/.ssh/id_rsa ProxyCommand nc -v -x 127.0.0.1:1081 %h %p Host gitlab HostName gitlab.com User git IdentityFile ~/.ssh/id_rsa ProxyCommand nc -v -x 127.0.0.1:1081 %h %p Host bitbucket HostName bitbucket.org User git IdentityFile ~/.ssh/id_rsa ProxyCommand nc -v -x 127.0.0.1:1081 %h %p Host gitee HostName gitee.com User git IdentityFile ~/.ssh/id_rsa ################ others ################ Host * # 复用之前已经建立的连接 ControlMaster auto # 在最后一个连接关闭之后也不真正的关掉连接 ControlPersist yes # 心跳 ServerAliveInterval 60 # 指定了这个连接的 socket 保存的路径 ControlPath ~/.ssh/connection-%r@%h:%p # ServerAliveCountMax 20 # ForwardAgent yes # KexAlgorithms +diffie-hellman-group1-sha1 # PreferredAuthentications publickey # TCPKeepAlive no # Compression yes # 走 HTTP 代理 # ProxyCommand socat - PROXY:127.0.0.1:%h:%p,proxyport=8081 # 走 socks5 代理（如 Shadowsocks） # ProxyCommand nc -v -x 127.0.0.1:1080 %h %p "},{"id":829,"href":"/note-cs/docs/tool/linux/ubuntu/streamlit/","title":"Streamlit","section":"4.2.1 Ubuntu","content":" Streamlit # streamlit/streamlit pip install streamlit streamlit run xxx.py --server.address \u0026#34;0.0.0.0\u0026#34; --server.port 7865 "},{"id":830,"href":"/note-cs/docs/tool/linux/ubuntu/systemd/","title":"systemd","section":"4.2.1 Ubuntu","content":" systemd # systemctl # systemctl list-units --type=service --state=active | grep ray "},{"id":831,"href":"/note-cs/docs/tool/macos/tabby/","title":"tabby","section":"4.1 MacOS","content":" tabby # "},{"id":832,"href":"/note-cs/docs/tool/macos/tmux/","title":"tmux","section":"4.1 MacOS","content":" tmux # gpakosz/.tmux 配置 # ChrisJohnsen/tmux-MacOSX-pasteboard # Using the Mac OS X programs pbpaste and pbcopy under tmux does not work.\nOther services and unpatched builds of screen are also affected.\ngpakosz/.tmux # Oh My Tmux!\ncd git clone https://github.com/gpakosz/.tmux.git ln -s -f .tmux/.tmux.conf cp .tmux/.tmux.conf.local . 教程 # tmux 2: Productive Mouse-Free Development by @bphogan. 手把手教你使用终端复用神器 Tmux，丢掉鼠标不是梦 [视频] 让你的 tmux 起死回生！[视频] "},{"id":833,"href":"/note-cs/docs/tool/macos/bmad/user-guide/","title":"User Guide","section":"bmad","content":" BMad Method — User Guide # This guide will help you understand and effectively use the BMad Method for agile AI-driven planning and development.\nThe BMad Plan and Execute Workflow # First, here is the full standard Greenfield Planning + Execution Workflow. Brownfield is very similar, but it\u0026rsquo;s suggested to understand this greenfield first, even if on a simple project before tackling a brownfield project. The BMad Method needs to be installed to the root of your new project folder. For the planning phase, you can optionally perform it with powerful web agents, potentially resulting in higher quality results at a fraction of the cost it would take to complete if providing your own API key or credits in some Agentic tools. For planning, powerful thinking models and larger context - along with working as a partner with the agents will net the best results.\nIf you are going to use the BMad Method with a Brownfield project (an existing project), review Working in the Brownfield.\nIf the diagrams below don\u0026rsquo;t render, install Markdown All in One along with the Markdown Preview Mermaid Support plugins to VSCode (or one of the forked clones). With these plugins, if you right click on the tab when open, there should be an Open Preview option, or check the IDE documentation.\nThe Planning Workflow (Web UI or Powerful IDE Agents) # Before development begins, BMad follows a structured planning workflow that\u0026rsquo;s ideally done in web UI for cost efficiency:\ngraph TD A[\u0026#34;Start: Project Idea\u0026#34;] --\u0026gt; B{\u0026#34;Optional: Analyst Research\u0026#34;} B --\u0026gt;|Yes| C[\u0026#34;Analyst: Brainstorming (Optional)\u0026#34;] B --\u0026gt;|No| G{\u0026#34;Project Brief Available?\u0026#34;} C --\u0026gt; C2[\u0026#34;Analyst: Market Research (Optional)\u0026#34;] C2 --\u0026gt; C3[\u0026#34;Analyst: Competitor Analysis (Optional)\u0026#34;] C3 --\u0026gt; D[\u0026#34;Analyst: Create Project Brief\u0026#34;] D --\u0026gt; G G --\u0026gt;|Yes| E[\u0026#34;PM: Create PRD from Brief (Fast Track)\u0026#34;] G --\u0026gt;|No| E2[\u0026#34;PM: Interactive PRD Creation (More Questions)\u0026#34;] E --\u0026gt; F[\u0026#34;PRD Created with FRs, NFRs, Epics \u0026amp; Stories\u0026#34;] E2 --\u0026gt; F F --\u0026gt; F2{\u0026#34;UX Required?\u0026#34;} F2 --\u0026gt;|Yes| F3[\u0026#34;UX Expert: Create Front End Spec\u0026#34;] F2 --\u0026gt;|No| H[\u0026#34;Architect: Create Architecture from PRD\u0026#34;] F3 --\u0026gt; F4[\u0026#34;UX Expert: Generate UI Prompt for Lovable/V0 (Optional)\u0026#34;] F4 --\u0026gt; H2[\u0026#34;Architect: Create Architecture from PRD \u0026#43; UX Spec\u0026#34;] H --\u0026gt; Q{\u0026#34;Early Test Strategy? (Optional)\u0026#34;} H2 --\u0026gt; Q Q --\u0026gt;|Yes| R[\u0026#34;QA: Early Test Architecture Input on High-Risk Areas\u0026#34;] Q --\u0026gt;|No| I R --\u0026gt; I[\u0026#34;PO: Run Master Checklist\u0026#34;] I --\u0026gt; J{\u0026#34;Documents Aligned?\u0026#34;} J --\u0026gt;|Yes| K[\u0026#34;Planning Complete\u0026#34;] J --\u0026gt;|No| L[\u0026#34;PO: Update Epics \u0026amp; Stories\u0026#34;] L --\u0026gt; M[\u0026#34;Update PRD/Architecture as needed\u0026#34;] M --\u0026gt; I K --\u0026gt; N[\u0026#34;📁 Switch to IDE (If in a Web Agent Platform)\u0026#34;] N --\u0026gt; O[\u0026#34;PO: Shard Documents\u0026#34;] O --\u0026gt; P[\u0026#34;Ready for SM/Dev Cycle\u0026#34;] style A fill:#f5f5f5,color:#000 style B fill:#e3f2fd,color:#000 style C fill:#e8f5e9,color:#000 style C2 fill:#e8f5e9,color:#000 style C3 fill:#e8f5e9,color:#000 style D fill:#e8f5e9,color:#000 style E fill:#fff3e0,color:#000 style E2 fill:#fff3e0,color:#000 style F fill:#fff3e0,color:#000 style F2 fill:#e3f2fd,color:#000 style F3 fill:#e1f5fe,color:#000 style F4 fill:#e1f5fe,color:#000 style G fill:#e3f2fd,color:#000 style H fill:#f3e5f5,color:#000 style H2 fill:#f3e5f5,color:#000 style Q fill:#e3f2fd,color:#000 style R fill:#ffd54f,color:#000 style I fill:#f9ab00,color:#fff style J fill:#e3f2fd,color:#000 style K fill:#34a853,color:#fff style L fill:#f9ab00,color:#fff style M fill:#fff3e0,color:#000 style N fill:#1a73e8,color:#fff style O fill:#f9ab00,color:#fff style P fill:#34a853,color:#fff Web UI to IDE Transition # Critical Transition Point: Once the PO confirms document alignment, you must switch from web UI to IDE to begin the development workflow:\nCopy Documents to Project: Ensure docs/prd.md and docs/architecture.md are in your project\u0026rsquo;s docs folder (or a custom location you can specify during installation) Switch to IDE: Open your project in your preferred Agentic IDE Document Sharding: Use the PO agent to shard the PRD and then the Architecture Begin Development: Start the Core Development Cycle that follows Planning Artifacts (Standard Paths) # PRD → docs/prd.md Architecture → docs/architecture.md Sharded Epics → docs/epics/ Sharded Stories → docs/stories/ QA Assessments → docs/qa/assessments/ QA Gates → docs/qa/gates/ The Core Development Cycle (IDE) # Once planning is complete and documents are sharded, BMad follows a structured development workflow:\ngraph TD A[\u0026#34;Development Phase Start\u0026#34;] --\u0026gt; B[\u0026#34;SM: Reviews Previous Story Dev/QA Notes\u0026#34;] B --\u0026gt; B2[\u0026#34;SM: Drafts Next Story from Sharded Epic \u0026#43; Architecture\u0026#34;] B2 --\u0026gt; S{\u0026#34;High-Risk Story? (Optional)\u0026#34;} S --\u0026gt;|Yes| T[\u0026#34;QA: *risk \u0026#43; *design on Draft Story\u0026#34;] S --\u0026gt;|No| B3 T --\u0026gt; U[\u0026#34;Test Strategy \u0026amp; Risk Profile Created\u0026#34;] U --\u0026gt; B3{\u0026#34;PO: Validate Story Draft (Optional)\u0026#34;} B3 --\u0026gt;|Validation Requested| B4[\u0026#34;PO: Validate Story Against Artifacts\u0026#34;] B3 --\u0026gt;|Skip Validation| C{\u0026#34;User Approval\u0026#34;} B4 --\u0026gt; C C --\u0026gt;|Approved| D[\u0026#34;Dev: Sequential Task Execution\u0026#34;] C --\u0026gt;|Needs Changes| B2 D --\u0026gt; E[\u0026#34;Dev: Implement Tasks \u0026#43; Tests\u0026#34;] E --\u0026gt; V{\u0026#34;Mid-Dev QA Check? (Optional)\u0026#34;} V --\u0026gt;|Yes| W[\u0026#34;QA: *trace or *nfr for Early Validation\u0026#34;] V --\u0026gt;|No| F W --\u0026gt; X[\u0026#34;Dev: Address Coverage/NFR Gaps\u0026#34;] X --\u0026gt; F[\u0026#34;Dev: Run All Validations\u0026#34;] F --\u0026gt; G[\u0026#34;Dev: Mark Ready for Review \u0026#43; Add Notes\u0026#34;] G --\u0026gt; H{\u0026#34;User Verification\u0026#34;} H --\u0026gt;|Request QA Review| I[\u0026#34;QA: Test Architect Review \u0026#43; Quality Gate\u0026#34;] H --\u0026gt;|Approve Without QA| M[\u0026#34;IMPORTANT: Verify All Regression Tests and Linting are Passing\u0026#34;] I --\u0026gt; J[\u0026#34;QA: Test Architecture Analysis \u0026#43; Active Refactoring\u0026#34;] J --\u0026gt; L{\u0026#34;QA Decision\u0026#34;} L --\u0026gt;|Needs Dev Work| D L --\u0026gt;|Approved| M H --\u0026gt;|Needs Fixes| D M --\u0026gt; N[\u0026#34;IMPORTANT: COMMIT YOUR CHANGES BEFORE PROCEEDING!\u0026#34;] N --\u0026gt; Y{\u0026#34;Gate Update Needed?\u0026#34;} Y --\u0026gt;|Yes| Z[\u0026#34;QA: *gate to Update Status\u0026#34;] Y --\u0026gt;|No| K Z --\u0026gt; K[\u0026#34;Mark Story as Done\u0026#34;] K --\u0026gt; B style A fill:#f5f5f5,color:#000 style B fill:#e8f5e9,color:#000 style B2 fill:#e8f5e9,color:#000 style S fill:#e3f2fd,color:#000 style T fill:#ffd54f,color:#000 style U fill:#ffd54f,color:#000 style B3 fill:#e3f2fd,color:#000 style B4 fill:#fce4ec,color:#000 style C fill:#e3f2fd,color:#000 style D fill:#e3f2fd,color:#000 style E fill:#e3f2fd,color:#000 style V fill:#e3f2fd,color:#000 style W fill:#ffd54f,color:#000 style X fill:#e3f2fd,color:#000 style F fill:#e3f2fd,color:#000 style G fill:#e3f2fd,color:#000 style H fill:#e3f2fd,color:#000 style I fill:#f9ab00,color:#fff style J fill:#ffd54f,color:#000 style K fill:#34a853,color:#fff style L fill:#e3f2fd,color:#000 style M fill:#ff5722,color:#fff style N fill:#d32f2f,color:#fff style Y fill:#e3f2fd,color:#000 style Z fill:#ffd54f,color:#000 Prerequisites # Before installing BMad Method, ensure you have:\nNode.js ≥ 18, npm ≥ 9 Git installed and configured (Optional) VS Code with \u0026ldquo;Markdown All in One\u0026rdquo; + \u0026ldquo;Markdown Preview Mermaid Support\u0026rdquo; extensions Installation # Optional # If you want to do the planning on the web with Claude (Sonnet 4 or Opus), Gemini Gem (2.5 Pro), or Custom GPTs:\nNavigate to dist/teams/ Copy team-fullstack.txt Create new Gemini Gem or CustomGPT Upload file with instructions: \u0026ldquo;Your critical operating instructions are attached, do not break character as directed\u0026rdquo; Type /help to see available commands IDE Project Setup # # Interactive installation (recommended) npx bmad-method install Codex (CLI \u0026amp; Web) # BMAD integrates with OpenAI Codex via AGENTS.md and committed core agent files.\nTwo installation modes:\nCodex (local only): keeps .bmad-core/ ignored for local dev. npx bmad-method install -f -i codex -d . Codex Web Enabled: ensures .bmad-core/ is tracked so you can commit it for Codex Web. npx bmad-method install -f -i codex-web -d . What gets generated:\nAGENTS.md at the project root with a BMAD section containing How-to-use with Codex (CLI \u0026amp; Web) Agent Directory (Title, ID, When To Use) Detailed per‑agent sections with source path, when-to-use, activation phrasing, and YAML Tasks with quick usage notes If a package.json exists, helpful scripts are added: bmad:refresh, bmad:list, bmad:validate Using Codex:\nCLI: run codex in the project root and prompt naturally, e.g., “As dev, implement …”. Web: commit .bmad-core/ and AGENTS.md, then open the repo in Codex and prompt the same way. Refresh after changes:\nRe-run the appropriate install mode (codex or codex-web) to update the BMAD block in AGENTS.md. Special Agents # There are two BMad agents — in the future they\u0026rsquo;ll be consolidated into a single BMad-Master.\nBMad-Master # This agent can do any task or command that all other agents can do, aside from actual story implementation. Additionally, this agent can help explain the BMad Method when on the web by accessing the knowledge base and explaining anything to you about the process.\nIf you don\u0026rsquo;t want to bother switching between different agents aside from the dev, this is the agent for you. Just remember that as the context grows, the performance of the agent degrades, therefore it is important to instruct the agent to compact the conversation and start a new conversation with the compacted conversation as the initial message. Do this often, preferably after each story is implemented.\nBMad-Orchestrator # This agent should NOT be used within the IDE, it is a heavyweight, special-purpose agent that utilizes a lot of context and can morph into any other agent. This exists solely to facilitate the teams within the web bundles. If you use a web bundle you will be greeted by the BMad Orchestrator.\nHow Agents Work # Dependencies System # Each agent has a YAML section that defines its dependencies:\ndependencies: templates: - prd-template.md - user-story-template.md tasks: - create-doc.md - shard-doc.md data: - bmad-kb.md Key Points:\nAgents only load resources they need (lean context) Dependencies are automatically resolved during bundling Resources are shared across agents to maintain consistency Agent Interaction # In IDE:\n# Some IDEs, like Cursor or Windsurf for example, utilize manual rules so interaction is done with the \u0026#39;@\u0026#39; symbol @pm Create a PRD for a task management app @architect Design the system architecture @dev Implement the user authentication # Some IDEs, like Claude Code, use slash commands instead /pm Create user stories /dev Fix the login bug Interactive Modes # Incremental Mode: Step-by-step with user input YOLO Mode: Rapid generation with minimal interaction IDE Integration # IDE Best Practices # Context Management: Keep relevant files only in context, keep files as lean and focused as necessary Agent Selection: Use appropriate agent for task Iterative Development: Work in small, focused tasks File Organization: Maintain clean project structure Commit Regularly: Save your work frequently The Test Architect (QA Agent) # Overview # The QA agent in BMad is not just a \u0026ldquo;senior developer reviewer\u0026rdquo; - it\u0026rsquo;s a Test Architect with deep expertise in test strategy, quality gates, and risk-based testing. Named Quinn, this agent provides advisory authority on quality matters while actively improving code when safe to do so.\nQuick Start (Essential Commands) # @qa *risk {story} # Assess risks before development @qa *design {story} # Create test strategy @qa *trace {story} # Verify test coverage during dev @qa *nfr {story} # Check quality attributes @qa *review {story} # Full assessment → writes gate Command Aliases (Test Architect) # The documentation uses short forms for convenience. Both styles are valid:\n*risk → *risk-profile *design → *test-design *nfr → *nfr-assess *trace → *trace-requirements (or just *trace) *review → *review *gate → *gate Core Capabilities # 1. Risk Profiling (*risk) # When: After story draft, before development begins (earliest intervention point)\nIdentifies and assesses implementation risks:\nCategories: Technical, Security, Performance, Data, Business, Operational Scoring: Probability × Impact analysis (1-9 scale) Mitigation: Specific strategies for each identified risk Gate Impact: Risks ≥9 trigger FAIL, ≥6 trigger CONCERNS (see tasks/risk-profile.md for authoritative rules) 2. Test Design (*design) # When: After story draft, before development begins (guides what tests to write)\nCreates comprehensive test strategies including:\nTest scenarios for each acceptance criterion Appropriate test level recommendations (unit vs integration vs E2E) Risk-based prioritization (P0/P1/P2) Test data requirements and mock strategies Execution strategies for CI/CD integration Example output:\ntest_summary: total: 24 by_level: unit: 15 integration: 7 e2e: 2 by_priority: P0: 8 # Must have - linked to critical risks P1: 10 # Should have - medium risks P2: 6 # Nice to have - low risks 3. Requirements Tracing (*trace) # When: During development (mid-implementation checkpoint)\nMaps requirements to test coverage:\nDocuments which tests validate each acceptance criterion Uses Given-When-Then for clarity (documentation only, not BDD code) Identifies coverage gaps with severity ratings Creates traceability matrix for audit purposes 4. NFR Assessment (*nfr) # When: During development or early review (validate quality attributes)\nValidates non-functional requirements:\nCore Four: Security, Performance, Reliability, Maintainability Evidence-Based: Looks for actual implementation proof Gate Integration: NFR failures directly impact quality gates 5. Comprehensive Test Architecture Review (*review) # When: After development complete, story marked \u0026ldquo;Ready for Review\u0026rdquo;\nWhen you run @qa *review {story}, Quinn performs:\nRequirements Traceability: Maps every acceptance criterion to its validating tests Test Level Analysis: Ensures appropriate testing at unit, integration, and E2E levels Coverage Assessment: Identifies gaps and redundant test coverage Active Refactoring: Improves code quality directly when safe Quality Gate Decision: Issues PASS/CONCERNS/FAIL status based on findings 6. Quality Gates (*gate) # When: After review fixes or when gate status needs updating\nManages quality gate decisions:\nDeterministic Rules: Clear criteria for PASS/CONCERNS/FAIL Parallel Authority: QA owns gate files in docs/qa/gates/ Advisory Nature: Provides recommendations, not blocks Waiver Support: Documents accepted risks when needed Note: Gates are advisory; teams choose their quality bar. WAIVED requires reason, approver, and expiry date. See templates/qa-gate-tmpl.yaml for schema and tasks/review-story.md (gate rules) and tasks/risk-profile.md for scoring.\nWorking with the Test Architect # Integration with BMad Workflow # The Test Architect provides value throughout the entire development lifecycle. Here\u0026rsquo;s when and how to leverage each capability:\nStage Command When to Use Value Output Story Drafting *risk After SM drafts story Identify pitfalls early docs/qa/assessments/{epic}.{story}-risk-{YYYYMMDD}.md *design After risk assessment Guide dev on test strategy docs/qa/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md Development *trace Mid-implementation Verify test coverage docs/qa/assessments/{epic}.{story}-trace-{YYYYMMDD}.md *nfr While building features Catch quality issues early docs/qa/assessments/{epic}.{story}-nfr-{YYYYMMDD}.md Review *review Story marked complete Full quality assessment QA Results in story + gate file Post-Review *gate After fixing issues Update quality decision Updated docs/qa/gates/{epic}.{story}-{slug}.yml Example Commands # # Planning Stage - Run these BEFORE development starts @qa *risk {draft-story} # What could go wrong? @qa *design {draft-story} # What tests should we write? # Development Stage - Run these DURING coding @qa *trace {story} # Are we testing everything? @qa *nfr {story} # Are we meeting quality standards? # Review Stage - Run when development complete @qa *review {story} # Comprehensive assessment + refactoring # Post-Review - Run after addressing issues @qa *gate {story} # Update gate status Quality Standards Enforced # Quinn enforces these test quality principles:\nNo Flaky Tests: Ensures reliability through proper async handling No Hard Waits: Dynamic waiting strategies only Stateless \u0026amp; Parallel-Safe: Tests run independently Self-Cleaning: Tests manage their own test data Appropriate Test Levels: Unit for logic, integration for interactions, E2E for journeys Explicit Assertions: Keep assertions in tests, not helpers Gate Status Meanings # PASS: All critical requirements met, no blocking issues CONCERNS: Non-critical issues found, team should review FAIL: Critical issues that should be addressed (security risks, missing P0 tests) WAIVED: Issues acknowledged but explicitly accepted by team Special Situations # High-Risk Stories:\nAlways run *risk and *design before development starts Consider mid-development *trace and *nfr checkpoints Complex Integrations:\nRun *trace during development to ensure all integration points tested Follow up with *nfr to validate performance across integrations Performance-Critical:\nRun *nfr early and often during development Don\u0026rsquo;t wait until review to discover performance issues Brownfield/Legacy Code:\nStart with *risk to identify regression dangers Use *review with extra focus on backward compatibility Best Practices # Early Engagement: Run *design and *risk during story drafting Risk-Based Focus: Let risk scores drive test prioritization Iterative Improvement: Use QA feedback to improve future stories Gate Transparency: Share gate decisions with the team Continuous Learning: QA documents patterns for team knowledge sharing Brownfield Care: Pay extra attention to regression risks in existing systems Output Paths Reference # Quick reference for where Test Architect outputs are stored:\n*risk-profile → docs/qa/assessments/{epic}.{story}-risk-{YYYYMMDD}.md *test-design → docs/qa/assessments/{epic}.{story}-test-design-{YYYYMMDD}.md *trace → docs/qa/assessments/{epic}.{story}-trace-{YYYYMMDD}.md *nfr-assess → docs/qa/assessments/{epic}.{story}-nfr-{YYYYMMDD}.md *review → QA Results section in story + gate file reference *gate → docs/qa/gates/{epic}.{story}-{slug}.yml Technical Preferences System # BMad includes a personalization system through the technical-preferences.md file located in .bmad-core/data/ - this can help bias the PM and Architect to recommend your preferences for design patterns, technology selection, or anything else you would like to put in here.\nUsing with Web Bundles # When creating custom web bundles or uploading to AI platforms, include your technical-preferences.md content to ensure agents have your preferences from the start of any conversation.\nCore Configuration # The bmad-core/core-config.yaml file is a critical config that enables BMad to work seamlessly with differing project structures, more options will be made available in the future. Currently the most important is the devLoadAlwaysFiles list section in the yaml.\nDeveloper Context Files # Define which files the dev agent should always load:\ndevLoadAlwaysFiles: - docs/architecture/coding-standards.md - docs/architecture/tech-stack.md - docs/architecture/project-structure.md You will want to verify from sharding your architecture that these documents exist, that they are as lean as possible, and contain exactly the information you want your dev agent to ALWAYS load into its context. These are the rules the agent will follow.\nAs your project grows and the code starts to build consistent patterns, coding standards should be reduced to include only the standards the agent still needs enforced. The agent will look at surrounding code in files to infer the coding standards that are relevant to the current task.\nGetting Help # Discord Community: Join Discord GitHub Issues: Report bugs Documentation: Browse docs YouTube: BMadCode Channel Conclusion # Remember: BMad is designed to enhance your development process, not replace your expertise. Use it as a powerful tool to accelerate your projects while maintaining control over design decisions and implementation details.\n"},{"id":834,"href":"/note-cs/docs/tool/macos/uv/","title":"uv","section":"4.1 MacOS","content":" uv # astral-sh/uv 教程 # # 安装 curl -LsSf https://astral.sh/uv/install.sh | sh uv init hello-world cd hello-world uv add requests uv add requests=2.52.1 # manually update the environment uv sync # active to run scripts and commands in the project without uv run source .venv/bin/activate # alias workon=\u0026#34;source .venv/bin/activate\u0026#34; # 如果需要 pip uv venv # uv venv --python 3.11.6 # 如果已经创建了 venv uv pip install -U pip uv init 生成的文件目录 # .python-version The .python-version file contains the project\u0026rsquo;s default Python version. This file tells uv which Python version to use when creating the project\u0026rsquo;s virtual environment. "},{"id":835,"href":"/note-cs/docs/tool/linux/ubuntu/v2ray/","title":"v2ray","section":"4.2.1 Ubuntu","content":" v2ray # 服务端 # wget -N --no-check-certificate -q -O install.sh \u0026#34;https://raw.githubusercontent.com/wulabing/Xray_onekey/nginx_forward/install.sh\u0026#34; \u0026amp;\u0026amp; chmod +x install.sh \u0026amp;\u0026amp; bash install.sh # 启动方式 # 启动 Xray：systemctl start xray # 停止 Xray：systemctl stop xray # 启动 Nginx：systemctl start nginx # 停止 Nginx：systemctl stop nginx # 相关目录 # Web 目录：/www/xray_web # Xray 服务端配置：/usr/local/etc/xray/config.json # Nginx 目录： /etc/nginx openai # 安装参考 [[ubuntu/docker]]\ndocker run -d --name warp -p 127.0.0.1:7081:1080 -p 127.0.0.1:7082:8080 --restart unless-stopped amirdaaee/cloudflare-warp:latest curl -x \u0026#34;socks5://127.0.0.1:7081\u0026#34; ipinfo.io vim /usr/local/etc/xray/config.json # outbounds 加上 { \u0026#34;protocol\u0026#34;: \u0026#34;socks\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;servers\u0026#34;: [ { \u0026#34;address\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 7081, \u0026#34;users\u0026#34;: [] } ] }, \u0026#34;tag\u0026#34;: \u0026#34;warp_proxy\u0026#34; }, # routing - rules 加上 { \u0026#34;type\u0026#34;: \u0026#34;field\u0026#34;, \u0026#34;outboundTag\u0026#34;: \u0026#34;warp_proxy\u0026#34;, \u0026#34;domain\u0026#34;: [\u0026#34;openai.com\u0026#34;] }, # 然后重启 systemctl restart xray ip 白名单 # # 第一次 # 安装依赖与目录 sudo apt-get update sudo apt-get install -y iptables-persistent ipset sudo mkdir -p /etc/iptables # 创建 ipset 集合（白名单容器） sudo ipset create PROXY_WL hash:ip -exist # iptables 链与规则（仅建立一次，幂等） # 端口 HTTP_PORT=3128 SOCKS_PORT=29108 # 若链不存在则创建 sudo iptables -L PROXY_WHITELIST -n \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || sudo iptables -N PROXY_WHITELIST # 链首：匹配 ipset 的来源就放行（幂等） sudo iptables -C PROXY_WHITELIST -m set --match-set PROXY_WL src -j RETURN 2\u0026gt;/dev/null \\ || sudo iptables -I PROXY_WHITELIST 1 -m set --match-set PROXY_WL src -j RETURN # 内网/回环（按需保留） for cidr in 127.0.0.0/8 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16; do sudo iptables -C PROXY_WHITELIST -s $cidr -j RETURN 2\u0026gt;/dev/null || \\ sudo iptables -A PROXY_WHITELIST -s $cidr -j RETURN done # 链尾：其余丢弃 sudo iptables -C PROXY_WHITELIST -j DROP 2\u0026gt;/dev/null || sudo iptables -A PROXY_WHITELIST -j DROP # 把链挂到端口（TCP：HTTP+SOCKS） sudo iptables -C INPUT -p tcp -m multiport --dports $HTTP_PORT,$SOCKS_PORT -j PROXY_WHITELIST 2\u0026gt;/dev/null \\ || sudo iptables -A INPUT -p tcp -m multiport --dports $HTTP_PORT,$SOCKS_PORT -j PROXY_WHITELIST # 如果需要 SOCKS 的 UDP（可选） sudo iptables -C INPUT -p udp --dport $SOCKS_PORT -j PROXY_WHITELIST 2\u0026gt;/dev/null \\ || sudo iptables -A INPUT -p udp --dport $SOCKS_PORT -j PROXY_WHITELIST # 持久化 + 自启动（保证重启也生效） # 保存当前 iptables/ipset sudo sh -c \u0026#39;iptables-save \u0026gt; /etc/iptables/rules.v4\u0026#39; sudo sh -c \u0026#39;ip6tables-save \u0026gt; /etc/iptables/rules.v6\u0026#39; # 用不到IPv6也可留空 sudo sh -c \u0026#39;ipset save \u0026gt; /etc/iptables/ipset.conf\u0026#39; # 创建 ipset 开机恢复服务（带 -exist，幂等） sudo tee /etc/systemd/system/ipset-restore.service \u0026gt;/dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; [Unit] Description=Restore ipset sets DefaultDependencies=no Before=netfilter-persistent.service [Service] Type=oneshot ExecStart=/usr/sbin/ipset restore -exist -f /etc/iptables/ipset.conf RemainAfterExit=yes [Install] WantedBy=multi-user.target EOF # 启用/启动 sudo systemctl daemon-reload sudo systemctl enable ipset-restore.service sudo systemctl enable netfilter-persistent sudo systemctl restart ipset-restore.service sudo systemctl restart netfilter-persistent # 安装 “白名单助手” 脚本 sudo tee /usr/local/sbin/proxy-wl \u0026gt;/dev/null \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; #!/usr/bin/env bash set -euo pipefail SET=PROXY_WL CONF_DIR=/etc/iptables IPSET_CONF=$CONF_DIR/ipset.conf IPT_V4=$CONF_DIR/rules.v4 usage() { echo \u0026#34;Usage: $0 {add IP|del IP|list|save}\u0026#34;; exit 1; } [ $# -ge 1 ] || usage cmd=\u0026#34;$1\u0026#34;; shift || true case \u0026#34;$cmd\u0026#34; in add) [ $# -eq 1 ] || usage sudo ipset add \u0026#34;$SET\u0026#34; \u0026#34;$1\u0026#34; -exist echo \u0026#34;[ADD] $1\u0026#34; ;; del) [ $# -eq 1 ] || usage sudo ipset del \u0026#34;$SET\u0026#34; \u0026#34;$1\u0026#34; echo \u0026#34;[DEL] $1\u0026#34; ;; list) sudo ipset list \u0026#34;$SET\u0026#34; ;; save) sudo mkdir -p \u0026#34;$CONF_DIR\u0026#34; sudo sh -c \u0026#34;ipset save \u0026gt; \u0026#39;$IPSET_CONF\u0026#39;\u0026#34; sudo sh -c \u0026#34;iptables-save \u0026gt; \u0026#39;$IPT_V4\u0026#39;\u0026#34; # 幂等恢复一次 sudo /usr/sbin/ipset restore -exist -f \u0026#34;$IPSET_CONF\u0026#34; echo \u0026#34;[SAVE] persisted \u0026amp; restored.\u0026#34; ;; *) usage ;; esac EOF sudo chmod +x /usr/local/sbin/proxy-wl # 增删 ip sudo proxy-wl add 1.180.13.249 sudo proxy-wl add 14.155.58.153 # sudo proxy-wl del 1.180.13.249 sudo proxy-wl list sudo proxy-wl save 使用方法 # cat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.bashrc # Proxy on/off helpers proxy() { local url=\u0026#34;http://A1kq-V7mQ3pX:zG7Y~m2Q9pL6_uV4-F3tC8wR@207.246.111.213:3128\u0026#34; export http_proxy=\u0026#34;$url\u0026#34; export https_proxy=\u0026#34;$url\u0026#34; export HTTP_PROXY=\u0026#34;$url\u0026#34; export HTTPS_PROXY=\u0026#34;$url\u0026#34; # 常见 no_proxy 列表，可按需加入内网网段 export no_proxy=\u0026#34;localhost,127.0.0.1,::1\u0026#34; export NO_PROXY=\u0026#34;$no_proxy\u0026#34; echo \u0026#34;Proxy ON -\u0026gt; $url\u0026#34; } unproxy() { unset http_proxy https_proxy HTTP_PROXY HTTPS_PROXY no_proxy NO_PROXY echo \u0026#34;Proxy OFF\u0026#34; } EOF # 让当前 shell 生效 . ~/.bashrc cat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # Proxy on/off helpers proxy() { local url=\u0026#34;http://A1kq-V7mQ3pX:zG7Y~m2Q9pL6_uV4-F3tC8wR@207.246.111.213:3128\u0026#34; export http_proxy=\u0026#34;$url\u0026#34; export https_proxy=\u0026#34;$url\u0026#34; export HTTP_PROXY=\u0026#34;$url\u0026#34; export HTTPS_PROXY=\u0026#34;$url\u0026#34; # 常见 no_proxy 列表，可按需加入内网网段 export no_proxy=\u0026#34;localhost,127.0.0.1,::1\u0026#34; export NO_PROXY=\u0026#34;$no_proxy\u0026#34; echo \u0026#34;Proxy ON -\u0026gt; $url\u0026#34; } unproxy() { unset http_proxy https_proxy HTTP_PROXY HTTPS_PROXY no_proxy NO_PROXY echo \u0026#34;Proxy OFF\u0026#34; } EOF # 让当前 shell 生效 . ~/.zshrc Linux 客户端 # v2rayA # # 添加公钥 wget -qO - https://apt.v2raya.org/key/public-key.asc | sudo tee /etc/apt/keyrings/v2raya.asc # 添加 V2RayA 软件源 echo \u0026#34;deb [signed-by=/etc/apt/keyrings/v2raya.asc] https://apt.v2raya.org/ v2raya main\u0026#34; | sudo tee /etc/apt/sources.list.d/v2raya.list sudo apt update # 安装 V2RayA sudo apt install v2raya v2ray ## 也可以使用 xray 包 sudo systemctl start v2raya.service sudo systemctl enable v2raya.service 参考： v2raya 快速上手\n"},{"id":836,"href":"/note-cs/docs/tool/macos/vim/","title":"vim","section":"4.1 MacOS","content":" vim # 教程 # iggredible/Learn-Vim # A book for learning the Vim editor the smart way.\n"},{"id":837,"href":"/note-cs/docs/tool/macos/vscode/","title":"VSCode","section":"4.1 MacOS","content":" VSCode # Microsoft/vscode 安装 # brew cask install visual-studio-code 配置 # settings.json\n{ \u0026#34;gitlens.advanced.messages\u0026#34;: { \u0026#34;suppressShowKeyBindingsNotice\u0026#34;: true }, \u0026#34;gitlens.historyExplorer.enabled\u0026#34;: true, \u0026#34;java.errors.incompleteClasspath.severity\u0026#34;: \u0026#34;ignore\u0026#34;, \u0026#34;materialTheme.autoApplyIcons\u0026#34;: true, \u0026#34;workbench.colorCustomizations\u0026#34;: {}, \u0026#34;materialTheme.accentPrevious\u0026#34;: \u0026#34;Breaking Bad\u0026#34;, \u0026#34;materialTheme.fixIconsRunning\u0026#34;: false, // Controls the font family. \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;Consolas, \u0026#39;微软雅黑\u0026#39;, Dengxian, Menlo, Monaco, \u0026#39;Courier New\u0026#39;, monospace\u0026#34;, // \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;Inconsolata, Consolas, \u0026#39;微软雅黑\u0026#39;, Dengxian, Menlo, Monaco, \u0026#39;Courier New\u0026#39;, monospace\u0026#34;, \u0026#34;editor.lineHeight\u0026#34;: 22, \u0026#34;editor.fontSize\u0026#34;: 14, \u0026#34;workbench.startupEditor\u0026#34;: \u0026#34;newUntitledFile\u0026#34;, \u0026#34;editor.suggestSelection\u0026#34;: \u0026#34;first\u0026#34;, \u0026#34;vsintellicode.modify.editor.suggestSelection\u0026#34;: \u0026#34;automaticallyOverrodeDefaultValue\u0026#34;, \u0026#34;python.jediEnabled\u0026#34;: false, \u0026#34;leetcode.endpoint\u0026#34;: \u0026#34;leetcode-cn\u0026#34;, \u0026#34;python.linting.pylintEnabled\u0026#34;: true, \u0026#34;leetcode.defaultLanguage\u0026#34;: \u0026#34;golang\u0026#34;, \u0026#34;leetcode.hint.configWebviewMarkdown\u0026#34;: false, \u0026#34;leetcode.hint.commentDescription\u0026#34;: false, \u0026#34;[go]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.organizeImports\u0026#34;: true, }, // Optional: Disable snippets, as they conflict with completion ranking. \u0026#34;editor.snippetSuggestions\u0026#34;: \u0026#34;none\u0026#34;, }, \u0026#34;[go.mod]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.organizeImports\u0026#34;: true, }, }, \u0026#34;gopls\u0026#34;: { // Add parameter placeholders when completing a function. \u0026#34;usePlaceholders\u0026#34;: true, // If true, enable additional analyses with staticcheck. // Warning: This will significantly increase memory usage. \u0026#34;staticcheck\u0026#34;: false, }, \u0026#34;leetcode.workspaceFolder\u0026#34;: \u0026#34;/Users/yewang/.leetcode\u0026#34;, \u0026#34;leetcode.hint.commandShortcut\u0026#34;: false, // Configure glob patterns for excluding files and folders. // For example, the files explorer decides which files and folders to show or hide based on this setting. // Read more about glob patterns [here](https://code.visualstudio.com/docs/editor/codebasics#_advanced-search-options). \u0026#34;files.exclude\u0026#34;: { \u0026#34;**/.git\u0026#34;: true, \u0026#34;**/.svn\u0026#34;: true, \u0026#34;**/.hg\u0026#34;: true, \u0026#34;**/CVS\u0026#34;: true, \u0026#34;**/.DS_Store\u0026#34;: true, \u0026#34;**/.classpath\u0026#34;: true, \u0026#34;**/.project\u0026#34;: true, \u0026#34;**/.settings\u0026#34;: true, \u0026#34;**/.factorypath\u0026#34;: true }, // \u0026#34;http.proxy\u0026#34;: \u0026#34;http://127.0.0.1:5081\u0026#34;, \u0026#34;terminal.integrated.inheritEnv\u0026#34;: true, \u0026#34;terminal.integrated.shell.osx\u0026#34;: \u0026#34;/bin/zsh\u0026#34;, // 为了使用 agnoster zsh 主题 \u0026#34;terminal.integrated.fontFamily\u0026#34;: \u0026#34;Meslo LG M DZ for Powerline\u0026#34;, // \u0026#34;terminal.integrated.fontFamily\u0026#34;: \u0026#34;Meslo LG M for Powerline\u0026#34;, \u0026#34;terminal.integrated.rendererType\u0026#34;: \u0026#34;dom\u0026#34;, \u0026#34;terminal.integrated.copyOnSelection\u0026#34;: true, \u0026#34;sourcetrail.startServerAtStartup\u0026#34;: true, // vim \u0026#34;vim.normalModeKeyBindingsNonRecursive\u0026#34;: [ { \u0026#34;before\u0026#34;: [ \u0026#34;:\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;workbench.action.showCommands\u0026#34;, ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;\u0026lt;leader\u0026gt;\u0026#34;, \u0026#34;m\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;bookmarks.toggle\u0026#34; ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;\u0026lt;leader\u0026gt;\u0026#34;, \u0026#34;b\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;bookmarks.list\u0026#34; ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;Z\u0026#34;, \u0026#34;Z\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;:wq\u0026#34; ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;\u0026lt;C-n\u0026gt;\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;:nohl\u0026#34;, ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;leader\u0026#34;, \u0026#34;w\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;workbench.action.files.save\u0026#34;, ] }, ], // 无法兼容 R 插入模式 // \u0026#34;vim.insertModeKeyBindings\u0026#34;: [ // { // \u0026#34;before\u0026#34;: [\u0026#34;j\u0026#34;, \u0026#34;j\u0026#34;], // \u0026#34;after\u0026#34;: [\u0026#34;\u0026lt;Esc\u0026gt;\u0026#34;] // } // ], \u0026#34;vim.visualModeKeyBindingsNonRecursive\u0026#34;: [ { \u0026#34;before\u0026#34;: [ \u0026#34;p\u0026#34;, ], \u0026#34;after\u0026#34;: [ \u0026#34;p\u0026#34;, \u0026#34;g\u0026#34;, \u0026#34;v\u0026#34;, \u0026#34;y\u0026#34; ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;\u0026gt;\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;editor.action.indentLines\u0026#34; ] }, { \u0026#34;before\u0026#34;: [ \u0026#34;\u0026lt;\u0026#34; ], \u0026#34;commands\u0026#34;: [ \u0026#34;editor.action.outdentLines\u0026#34; ] }, ], \u0026#34;explorer.confirmDragAndDrop\u0026#34;: false, \u0026#34;explorer.confirmDelete\u0026#34;: false, \u0026#34;markdown-preview-enhanced.automaticallyShowPreviewOfMarkdownBeingEdited\u0026#34;: false, \u0026#34;markdown.extension.preview.autoShowPreviewToSide\u0026#34;: false, \u0026#34;[html]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34; }, // Activate Python Environment in Terminal created using the Extension. \u0026#34;python.terminal.activateEnvironment\u0026#34;: false, // Path to folder with a list of Virtual Environments (e.g. ~/.pyenv, ~/Envs, ~/.virtualenvs). \u0026#34;python.venvPath\u0026#34;: \u0026#34;~/.local/share/virtualenvs\u0026#34;, \u0026#34;editor.largeFileOptimizations\u0026#34;: false, \u0026#34;C_Cpp.updateChannel\u0026#34;: \u0026#34;Insiders\u0026#34;, \u0026#34;[markdown]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34; }, // Format a file on save. A formatter must be available, the file must not be saved after delay, and the editor must not be shutting down. \u0026#34;editor.formatOnSave\u0026#34;: false, \u0026#34;[cpp]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;ms-vscode.cpptools\u0026#34; }, \u0026#34;clang-format.executable\u0026#34;: \u0026#34;/Users/yewang/.vscode/extensions/ms-vscode.cpptools-0.27.0-insiders3/LLVM/bin/clang-format.darwin\u0026#34;, \u0026#34;[json]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;HookyQR.beautify\u0026#34; }, // markdownlint config object \u0026#34;markdownlint.config\u0026#34;: { \u0026#34;MD004\u0026#34;: false, \u0026#34;MD013\u0026#34;: false, \u0026#34;MD024\u0026#34;: false, \u0026#34;MD025\u0026#34;: false, \u0026#34;MD026\u0026#34;: false, \u0026#34;MD040\u0026#34;: false, \u0026#34;MD045\u0026#34;: false, }, \u0026#34;markdownlint.run\u0026#34;: \u0026#34;onSave\u0026#34;, \u0026#34;window.title\u0026#34;: \u0026#34;${dirty} ${activeEditorMedium}${separator}${rootName}\u0026#34;, // 右侧概览 用色块代替缩小的字符; 设置水平最大列数; 始终显示滑块 \u0026#34;editor.minimap.renderCharacters\u0026#34;: false, \u0026#34;editor.minimap.maxColumn\u0026#34;: 200, \u0026#34;editor.minimap.showSlider\u0026#34;: \u0026#34;always\u0026#34;, // 标签 \u0026#34;editor.smoothScrolling\u0026#34;: true, \u0026#34;editor.cursorBlinking\u0026#34;: \u0026#34;phase\u0026#34;, // \u0026#34;editor.cursorSmoothCaretAnimation\u0026#34;: true, // 最后一行 \u0026#34;files.insertFinalNewline\u0026#34;: true, // 取消最后空格 \u0026#34;files.trimTrailingWhitespace\u0026#34;: true, // 取消发送给 ms \u0026#34;telemetry.enableCrashReporter\u0026#34;: false, \u0026#34;telemetry.enableTelemetry\u0026#34;: false, \u0026#34;workbench.settings.enableNaturalLanguageSearch\u0026#34;: false, // \u0026#34;editor.renderWhitespace\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;editor.wordWrap\u0026#34;: \u0026#34;on\u0026#34;, // Fit code within this line limit // \u0026#34;prettier.printWidth\u0026#34;: 80, // Controls the wrapping column of the editor when `editor.wordWrap` is `wordWrapColumn` or `bounded`. // \u0026#34;editor.wordWrapColumn\u0026#34;: 80, \u0026#34;python.formatting.autopep8Args\u0026#34;: [ \u0026#34;--max-line-length=100\u0026#34; ], \u0026#34;javascript.updateImportsOnFileMove.enabled\u0026#34;: \u0026#34;always\u0026#34;, \u0026#34;[javascript]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;HookyQR.beautify\u0026#34; }, \u0026#34;[java]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;redhat.java\u0026#34; }, \u0026#34;[yaml]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34; }, \u0026#34;java.semanticHighlighting.enabled\u0026#34;: true, \u0026#34;extensions.ignoreRecommendations\u0026#34;: true, \u0026#34;java.project.importOnFirstTimeStartup\u0026#34;: \u0026#34;automatic\u0026#34;, \u0026#34;picgo.picBed.current\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;picgo.picBed.github.repo\u0026#34;: \u0026#34;ikingye/imagehost\u0026#34;, \u0026#34;picgo.picBed.github.token\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;picgo.picBed.github.branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;picgo.picBed.github.customUrl\u0026#34;: \u0026#34;https://cdn.jsdelivr.net/gh/ikingye/imagehost\u0026#34;, \u0026#34;picgo.picBed.github.path\u0026#34;: \u0026#34;picgo/\u0026#34;, \u0026#34;picgo.customOutputFormat\u0026#34;: \u0026#34;![](${url})\u0026#34;, \u0026#34;sonarlint.rules\u0026#34;: { \u0026#34;Web:LinkToImageCheck\u0026#34;: { \u0026#34;level\u0026#34;: \u0026#34;off\u0026#34; } }, \u0026#34;python.showStartPage\u0026#34;: false, \u0026#34;hediet.vscode-drawio.codeLinkActivated\u0026#34;: true, // \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;dark\u0026#34; // set light theme \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;atlas\u0026#34;, // \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;Kennedy\u0026#34;, // Configure which editor to use for specific file types. \u0026#34;workbench.editorAssociations\u0026#34;: { \u0026#34;*.png\u0026#34;: \u0026#34;hediet.vscode-drawio\u0026#34;, \u0026#34;*.svg\u0026#34;: \u0026#34;hediet.vscode-drawio-text\u0026#34;, \u0026#34;*.drawio\u0026#34;: \u0026#34;hediet.vscode-drawio-text\u0026#34;, \u0026#34;*.ipynb\u0026#34;: \u0026#34;jupyter-notebook\u0026#34; }, \u0026#34;[dockerfile]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;ms-azuretools.vscode-docker\u0026#34; }, \u0026#34;jupyter.sendSelectionToInteractiveWindow\u0026#34;: true, \u0026#34;pasteImage.defaultName\u0026#34;: \u0026#34;YMMDDHHmmss\u0026#34;, \u0026#34;pasteImage.path\u0026#34;: \u0026#34;${projectRoot}/private/static/image/2021\u0026#34;, \u0026#34;jupyter.alwaysTrustNotebooks\u0026#34;: true, \u0026#34;tabnine.experimentalAutoImports\u0026#34;: true, \u0026#34;[php]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;bmewburn.vscode-intelephense-client\u0026#34; }, \u0026#34;todo-tree.tree.showScanModeButton\u0026#34;: true, \u0026#34;todo-tree.regex.regex\u0026#34;: \u0026#34;(//|#|\u0026lt;!--|;|/\\\\*|^|^\\\\s*(-|\\\\d+.))\\\\s*($TAGS)\u0026#34;, \u0026#34;todo-tree.general.tags\u0026#34;: [ \u0026#34;BUG\u0026#34;, \u0026#34;HACK\u0026#34;, \u0026#34;FIXME\u0026#34;, \u0026#34;TODO\u0026#34;, \u0026#34;XXX\u0026#34;, \u0026#34;[ ]\u0026#34;, \u0026#34;[x]\u0026#34; ], \u0026#34;todo-tree.highlights.customHighlight\u0026#34;: { \u0026#34;[ ]\u0026#34;: { \u0026#34;background\u0026#34;: \u0026#34;#ff000080\u0026#34; }, \u0026#34;[x]\u0026#34;: { \u0026#34;background\u0026#34;: \u0026#34;#00ff0080\u0026#34; }, \u0026#34;TODO\u0026#34;: { \u0026#34;icon\u0026#34;: \u0026#34;check\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;line\u0026#34; }, \u0026#34;FIXME\u0026#34;: { \u0026#34;foreground\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;iconColour\u0026#34;: \u0026#34;yellow\u0026#34;, \u0026#34;gutterIcon\u0026#34;: true } }, \u0026#34;go.toolsManagement.autoUpdate\u0026#34;: true, \u0026#34;go.toolsEnvVars\u0026#34;: { \u0026#34;GOPROXY\u0026#34;: \u0026#34;https://goproxy.cn,direct\u0026#34;, }, \u0026#34;editor.codeActionsOnSave\u0026#34;: null, \u0026#34;editor.accessibilitySupport\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;security.workspace.trust.startupPrompt\u0026#34;: \u0026#34;never\u0026#34;, \u0026#34;security.workspace.trust.enabled\u0026#34;: false, \u0026#34;redhat.telemetry.enabled\u0026#34;: true, \u0026#34;files.associations\u0026#34;: { \u0026#34;*.md\u0026#34;: \u0026#34;markdown\u0026#34; }, \u0026#34;notebook.cellToolbarLocation\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;right\u0026#34;, \u0026#34;jupyter-notebook\u0026#34;: \u0026#34;left\u0026#34; }, \u0026#34;workbench.editor.untitled.hint\u0026#34;: \u0026#34;hidden\u0026#34;, \u0026#34;workbench.colorTheme\u0026#34;: \u0026#34;Material Theme\u0026#34;, \u0026#34;cSpell.enableFiletypes\u0026#34;: [ \u0026#34;!less\u0026#34; ], \u0026#34;bracketPairColorizer.depreciation-notice\u0026#34;: false, } 参考：\nHow to set Go Proxy in VS Code? 插件 # 插件列表 # code --list-extensions code --list-extensions --show-versions ouuan/my-vscode-extensions List your installed VS Code extensions in a Markdown file\n参考：\nCommand line extension management 推荐插件 # 插件 类型 推荐 备注 ESLint 格式化 - JavaScript ★★★★ TabNine 代码补全 ★★★★ ESLint # Microsoft/vscode-eslint TabNine # codota/tabnine-vscode Tabnine works with all major programming languages including JavaScript, Python, TypeScript, PHP, C/C++, HTML/CSS, Go, Java, Ruby, C#, Rust, SQL, Bash, Kotlin, Julia, Lua, OCaml, Perl, Haskell, and React.​\n参考：\nVSCode 插件列表 PicGo/vs-picgo # https://github.com/PicGo/vs-picgo\nformat # autopep8 # 设置每行最大长度\n\u0026#34;python.formatting.autopep8Args\u0026#34;: [ \u0026#34;--max-line-length=200\u0026#34; ] Draw.io # hediet/vscode-drawio This unofficial extension integrates Draw.io (also known as diagrams.net) into VS Code.\n设置背景色\nFor set light theme, add in your settings.json next: \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;atlas\u0026#34; // or if you\u0026#39;d like white menu on the top, not blue, use \u0026#34;Kennedy\u0026#34; theme \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;Kennedy\u0026#34; // or if you mostly view, not edit, use \u0026#34;minimal\u0026#34; theme \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;min\u0026#34; Dark: \u0026#34;hediet.vscode-drawio.theme\u0026#34;: \u0026#34;dark\u0026#34; 参考：\nFeature request: match theme colors Paste Image # mushanshitiancai/vscode-paste-image paste image from clipboard to markdown/asciidoc directly!\n快捷键 # MacOS ### 选择 - 选中所有同一个词 `cmd + shift + L` ### 跳转 - 左右括号跳转 `cmd + shift + \\` - 跳到定义 `cmd + 鼠标左键单击` - 返回光标上一个位置 `ctrl + -` ### 编辑 - 格式化 `opt + shift + f` Windows ### 选择 - 选中所有同一个词 `ctrl + shift + L` ### 跳转 - 左右括号跳转 `ctrl + shift + \\` - 跳到定义 `ctrl + 鼠标左键单击` - 返回光标上一个位置 `alt + ←` Debug # 参考：\nUSER GUIDE - Debugging Debug C++ in Visual Studio Code 常见问题 # Could not create temporary directory: Permission denied # sudo chown -R $USER ~/Library/Caches/* 教程 # 帮你高效使用 VS Code 的秘诀 解决 Mac 下 VSCode 打开 zsh 乱码 "},{"id":838,"href":"/note-cs/docs/tool/macos/xdm/","title":"XDM","section":"4.1 MacOS","content":" XDM # 下载\n"},{"id":839,"href":"/note-cs/docs/tool/linux/centos/zsh/","title":"zsh","section":"4.2.2 CentOS","content":" zsh # oh-my-zsh # 安装\nsudo yum install -y git zsh # sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc export PROMPT=\u0026#39;%{$fg[magenta]%}%(?..%?%1v)%n@%{$fg[green]%}%M:%{$fg[cyan]%}%c%{$reset_color%} $(git_prompt_info)\u0026#39; EOF zsh alias cdcode=\u0026#39;cd ~/code\u0026#39; alias cdstudy=\u0026#39;cdcode \u0026amp;\u0026amp; cd study\u0026#39; alias cdtest=\u0026#39;cdstudy \u0026amp;\u0026amp; cd test\u0026#39; alias cdgithub=\u0026#39;cdcode \u0026amp;\u0026amp; cd github\u0026#39; alias cdgitlab=\u0026#39;cdcode \u0026amp;\u0026amp; cd gitlab\u0026#39; alias cdbitbucket=\u0026#39;cdcode \u0026amp;\u0026amp; cd bitbucket\u0026#39; # proxy # export http_proxy=149.28.137.166:20171 # export https_proxy=149.28.137.166:20171 # 设置默认为 zsh sudo chsh -s /usr/bin/zsh yewang "},{"id":840,"href":"/note-cs/docs/tool/linux/ubuntu/zsh/","title":"zsh","section":"4.2.1 Ubuntu","content":" zsh # oh-my-zsh # 安装\napt install -y git zsh # sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt;\u0026gt; ~/.zshrc export PROMPT=\u0026#39;%{$fg[magenta]%}%(?..%?%1v)%n@%{$fg[green]%}%M:%{$fg[cyan]%}%c%{$reset_color%} $(git_prompt_info)\u0026#39; EOF . ~/.zshrc # 使用 hostnamectl hostnamectl set-hostname master1 alias cdcode=\u0026#39;cd ~/code\u0026#39; alias cdstudy=\u0026#39;cdcode \u0026amp;\u0026amp; cd study\u0026#39; alias cdtest=\u0026#39;cdstudy \u0026amp;\u0026amp; cd test\u0026#39; alias cdgithub=\u0026#39;cdcode \u0026amp;\u0026amp; cd github\u0026#39; alias cdgitlab=\u0026#39;cdcode \u0026amp;\u0026amp; cd gitlab\u0026#39; alias cdbitbucket=\u0026#39;cdcode \u0026amp;\u0026amp; cd bitbucket\u0026#39; # proxy # export http_proxy=149.28.137.166:20171 # export https_proxy=149.28.137.166:20171 # 设置默认为 zsh sudo chsh -s /usr/bin/zsh yewang Oh-my-zsh 主题乱码解决办法 # cd ~/Downloads \u0026amp;\u0026amp; git clone https://github.com/powerline/fonts.git\t#将 Powerline 字体文件下载到「下载」文件夹中 cd fonts \u0026amp;\u0026amp; ./install.sh\t#安装所有 Powerline 字体 cd \u0026amp;\u0026amp; rm -rf ~/Downloads/fonts\t#删除下载的字体文件 Iterm2 的设置路径是: [iTerm2] -\u0026gt; [Profiles] -\u0026gt; [Default] -\u0026gt; [Text] -\u0026gt; [Font] -\u0026gt; [DejaVu Sans Mono for Powerline]\n"},{"id":841,"href":"/note-cs/docs/domain/cc/others/","title":"其他","section":"3.1 云计算","content":" 其他 # "},{"id":842,"href":"/note-cs/docs/tool/macos/package-manager/","title":"包管理工具","section":"4.1 MacOS","content":" 包管理工具 # Linux # Ubuntu # apt # sudo apt install # download .deb package sudo dpkg -i fd_8.0.0_amd64.deb # adapt version number and architecture Debian # apt-get # sudo apt-get install Fedora # dnf # dnf install dnf copr # dnf copr enable keefle/fd dnf install fd Alpine Linux # apk # apk add Arch Linux # pacman # pacman -S Gentoo Linux # emerge # emerge -av openSUSE Linux # zypper # zypper in Void Linux # xbps-install # xbps-install -S FreeBSD # pkg # pkg install Mac # Homebrew # MacPorts # Windows # Scoop # Chocolatey # 其他 # NixOS / via Nix # Nix package manager # nix-env -i Node.js # NPM # # On linux and macOS npm install -g Rust # cargo # cargo install "},{"id":843,"href":"/note-cs/docs/basic/cc/storage/","title":"存储","section":"1.1 计算机组成原理","content":" 存储 # 块存储 文件存储 HDFS (Hadoop) GPFS GFS (google) 对象存储 Swift 统一存储（支持块存储、对象存储和文件存储） Ceph 参考：\nOpenStack 中的 Swift 是对象存储？ 分布式文件存储 # gluster/glusterfs # ceph/ceph # Ceph is a distributed object, block, and file storage platform\n参考：\nCeph 分布式存储工作原理 及 部署介绍 块存储 vs 文件存储 vs 对象存储 # 文件存储的用户是自然人 块存储的用户是可以读写块设备的软件系统，例如传统的文件系统、数据库 对象存储的用户则是其它计算机软件 总体区别：\n文件存储会以文件和文件夹的层次结构来整理和呈现数据; 块存储会将数据拆分到任意划分且大小相同的卷中; 对象存储会管理数据并将其链接至关联的元数据。 协议区别：\n1、文件存储对外提供 NFS、SMB、FTP、POSIX 等协议； 2、块存储对外提供 iSCSI，FC，NBD 等协议； 3、对象存储对外提供 S3 协议 在网络存储中，服务器把本地的一个逻辑块设备通过某种协议模拟成一个块设备，远程的客户端使用相同的协议把这个逻辑块设备作为一个本地存储介质来使用，划分分区，格式化自己的文件系统等等。 这就是块存储，比较常见的块存储协议是 iSCSI。\n这三种存储，分别对应了不同的访问协议，这也就决定了他们的本质差别。\n文件存储，主要操作对象是文件和文件夹。 以 NFS 为例，文件相关的接口包括：LOOKUP/ACCESS/READ/WRITE/CREATE/REMOVE/RENAME 等等，文件夹相关的接口包括：MKDIR/RMDIR/READDIR 等等。同时也会有 FSSTAT/FSINFO 等接口用于提供文件系统级别的信息。POSIX，SAMBA 等也是文件存储协议。 协议更注重接口的灵活，以及访问权限控制。 块存储，主要操作对象是磁盘。 以 SCSI 为例，主要接口有 Read/Write/Read Capacity/Inquiry 等等。FC，iSCSI，也是块存储协议。 和文件存储相比，没有文件和目录树的概念，一般协议也不会定义磁盘的创建和删除操作。 协议更注重传输控制。 块存储是排它的 对象存储，主要操作对象是对象（Object）。 以 S3 为例，主要接口有 PUT/GET/DELETE 等。 和文件和对象存储相比，没有随机读写的接口。和文件存储相比，没有目录树的概念。 协议更注重简洁。 参考：\n块存储、文件存储、对象存储这三者的本质差别是什么？ 块存储，对象存储，分布式存储本质区别？ 统一存储 # Unified Storage Systems\n所谓统一，其实就是把 NAS 和 SAN 结合在了一起， 在一个架构中，NAS 和 SAN 共存，且由一个统一界面管理。\n真正的统一存储，可以从一个设施为 SAN，NAS 和 iSCSI 提供多层存储， 它是一个支持基于块访问协议，如 FCP 和 iSCSI， 和基于文件访问协议， 如 CIFS 和 NFS， 使用相同管理工具的系统，\n统一存储不应该存在网关， 在 SAN 产品上部署一个 NAS 网关不是统一存储， 同样，离开文件系统的 SAN 也不算，故障转移事件超过 30 秒也不能算是企业级的统一存储产品。\n"},{"id":844,"href":"/note-cs/docs/basic/cc/memory-card/","title":"存储卡","section":"1.1 计算机组成原理","content":" 存储卡 # memory card 存储卡，快闪存储卡、闪卡\nMemory Card 是一种使用 Flash Memory 技术的可移动存储卡\nminiSD\n首次于 2003 年的 CeBIT 展览中由 SanDisk 公布 MiniSD 卡由 SD 卡发展派生而来 记忆棒，Memory Stick，由日本索尼公司最先研发出来的移动存储媒体\nXD 卡，全称为 XD Picture Card，XD 取自于“Extreme Digital”\nXD 卡是由日本奥林巴斯株式会社和富士有限公司联合推出 微硬盘（Microdrive）\n由 IBM 公司开发的一款超级迷你硬盘机产品 华为 NM 存储卡（Nano Memory Card，简称 NM 卡）\n是华为自创的一种超微型存储卡，与 MicroSD 存储卡相比，体积减小 45%，和 Nano SIM 卡的规格几乎完全相同。 CF 卡（Compact Flash）\n1994 年首次由 SanDisk 公司生产并制定了相关规范 对于现在的消费电子产品而言，CF 卡体积是个很大的问题 SM 卡，Smart Media\n由东芝公司在 1995-11 发布的 Flash Memory 存储卡 MMC 卡，MultiMedia Card\n由美国 SANDISK 公司和德国西门子公司在 2000 年共同开发 SD 卡，Secure Digital Memory Card\nSD 存储卡的技术是从 MMC 卡(MultiMedia Card）格式上发展而来 SD 卡是一种基于半导体快闪记忆器的新一代记忆设备，由日本松下、东芝及美国 SanDisk 公司于 1999-08 共同开发研制 SD 卡容量有：128G 64G 32G 16G 8G 6G 4G 2G 1G 512M 256M 128M，早期从 8512 MB，18(SDHC) GB 一般用于数码相机 microSD\nmicroSD 卡原本称为 TF 卡（T-Flash 卡或 Trans-Flash Card），由摩托罗拉与 SanDisk 共同研发，在 2004 年推出 microSD 是 MMC 标准的继承者，接着还点了 SDHC 和 SDXC 的技能树，到后面的 UHS，大有分道扬镳之势 TF 卡是极细小的快闪存储器卡，采用 SanDisk 最新 NAND MLC 技术及控制器技术 TF 卡容量有：128G 64G 32G 16G 8G 6G 4G 2G 1G 512M 256M 128M 一般用于手机 TF 卡插入适配器（adapter）可以转换成 SD 卡，但 SD 卡一般无法转换成 TF 卡 快闪存储卡曾被视为软盘的替代品，但是这一角色被U 盘所取代。\n"},{"id":845,"href":"/note-cs/docs/direction/be/search/","title":"搜索引擎","section":"2.2 后端","content":" 搜索引擎 # "},{"id":846,"href":"/note-cs/docs/study/skill/type/","title":"文档类型","section":"4.1 技能树","content":" 文档类型 # "},{"id":847,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/template-method/","title":"模板方法","section":"行为型","content":" 模板方法模式 # Template Method Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":848,"href":"/note-cs/docs/study/skill/stream-media/lorawan/chirpstack/","title":"ChirpStack","section":"LoRaWan","content":" ChirpStack # ChirpStack Network Server # ChirpStack Network Server is an open-source LoRaWAN network-server. https://www.chirpstack.io\nChirpStack Application Server # ChirpStack Application Server is an open-source LoRaWAN application-server. https://www.chirpstack.io\n"},{"id":849,"href":"/note-cs/docs/study/skill/stream-media/lorawan/claa/","title":"CLAA","section":"LoRaWan","content":" CLAA # The China LoRa Application Alliance\nCLAA IoT Ecosystem\n"},{"id":850,"href":"/note-cs/docs/basic/pl/julia/","title":"Julia","section":"1.5 编程语言","content":" Julia # 详见：Julia 学习笔记\n"},{"id":851,"href":"/note-cs/docs/study/skill/stream-media/lorawan/","title":"LoRaWan","section":"4.5 流媒体","content":" LoRaWan # "},{"id":852,"href":"/note-cs/docs/direction/se/design-pattern/behavioral/visitor/","title":"参观者","section":"行为型","content":" 参观者模式 # Visitor Pattern\n代码示例 # --- C ```c ``` --- C\u0026#43;\u0026#43; ```c++ ``` --- C# ```c# ``` --- Go ```go ``` --- Java ```java ``` --- JavaScript ```javascript ``` --- Kotlin ```kotlin ``` --- PHP ```php ``` --- Python2 ```python ``` --- Python3 ```python ``` --- Ruby ```ruby ``` --- Rust ```rust ``` --- Scala ```scala ``` --- Swift ```swift ``` --- TypeScript ```typescript ``` --- "},{"id":853,"href":"/note-cs/docs/basic/pl/csharp/","title":"C#","section":"1.5 编程语言","content":" C# 学习笔记 # 详见：C# 学习笔记\n"},{"id":854,"href":"/note-cs/docs/basic/pl/typescript/","title":"TypeScript","section":"1.5 编程语言","content":" TypeScript 学习笔记 # "},{"id":855,"href":"/note-cs/docs/basic/pl/swift/","title":"Swift","section":"1.5 编程语言","content":" Swift 学习笔记 # "},{"id":856,"href":"/note-cs/docs/domain/cc/istio/advanced/eco/other/easegress/","title":"Easegress","section":"其他","content":" Easegress # megaease/easegress A Cloud Native traffic orchestration system\n"},{"id":857,"href":"/note-cs/docs/basic/pl/erlang/","title":"Erlang","section":"1.5 编程语言","content":" Erlang 学习笔记 # Erlang/OTP # erlang/otp "},{"id":858,"href":"/note-cs/docs/basic/pl/r/","title":"R","section":"1.5 编程语言","content":" R 学习笔记 # "},{"id":859,"href":"/note-cs/docs/study/skill/stream-media/ffmpeg/","title":"FFmpeg","section":"4.5 流媒体","content":" FFmpeg # FFmpeg/FFmpeg Fast Forward Moving Picture Experts Group\nFFmpeg is a collection of libraries and tools to process multimedia content such as audio, video, subtitles and related metadata.\n安装 # linux 安装 ffmpeg\nhttps://www.tecmint.com/install-ffmpeg-in-linux/\nffmpeg -re -i car-brand.MOV -rtsp_transport tcp -vcodec h264 -f rtsp rtsp://localhost/test ffplay # # 添加到 ~/.zshrc function rtsp() { ffplay -analyzeduration 1000000 -fflags nobuffer -probesize 32 -sync ext $@ } 命令 # ffmpeg -i rtsp://admin:root123@192.168.66.119/ -vcodec copy -acodec copy -rtsp_transport tcp -f rtsp rtsp://127.0.0.1/test.sdp # 音视频转码后推送 ffmpeg -i rtsp://admin:root123@192.168.66.119/ -vcodec libx264 -acodec libvo_aacenc -rtsp_transport tcp -f rtsp rtsp://127.0.0.1/test.sdp ffmpeg -re -i ./car-brand.MOV -stream_loop -1 -vcodec libx264 -acodec aac -f rtsp rtsp://10.159.11.167:8194/car-brand ffmpeg -re -i ./car-brand.MOV -rtsp_transport tcp -vcodec h264 -f rtsp rtsp://localhost/test ffmpeg -re -i ./car-brand.MOV -rtsp_transport udp -vcodec h264 -f rtsp rtsp://localhost/test ffmpeg -re -stream_loop -1 -i carbrand.MOV -rtsp_transport tcp -vcodec h264 -f rtsp rtsp://localhost/test1 ffmpeg -re -stream_loop -1 -i carbrand.MOV -c copy -f rtsp rtsp://localhost:8554/mystream ffmpeg 参数 # # 参考文档 https://ffmpeg.org/ffmpeg.html Main options: # Force input or output file format. The format is normally auto detected for input files and guessed from the file extension for output files, so this option is not needed in most cases. -f fmt force format # Select an encoder (when used before an output file) # or a decoder (when used before an input file) for one or more streams. # codec is the name of a decoder/encoder # or a special value copy (output only) to indicate that the stream is not to be re-encoded. -c codec codec name -codec codec codec name # input file url -i url # Set number of times input stream shall be looped. Loop 0 means no loop, loop -1 means infinite loop. # -1 无限循环 -stream_loop number Video options: -r rate set frame rate (Hz value, fraction or abbreviation) -vcodec codec force video codec (\u0026#39;copy\u0026#39; to copy stream) Audio options: -acodec codec force audio codec (\u0026#39;copy\u0026#39; to copy stream) # Read input at native frame rate. Mainly used to simulate a grab device, or live input stream (e.g. when reading from a file). # 用来模拟一个摄像头或者实时流，不要在正式环境使用 -re h264_nvenc vs libx264 vs h264 # h264_nvenc uses the NVidia hardware assisted H.264 video encoder. libx264 is a software (CPU) based H.264 encoder.\n参考：\nWhat is the difference between libx264 and h264_nvenc? "},{"id":860,"href":"/note-cs/docs/study/skill/stream-media/gb28181/","title":"GB28181","section":"4.5 流媒体","content":" GB28181 # GB28181 协议是设备端主动向服务端发起注册消息，并定时发送保活消息，服务端收到后就认为设备在线，超时收不到保活的话就认为设备离线了。客户端发起播放视频请求时，服务端给指定的设备发送 INVITE 请求，通知设备将指定的通道的视频推送到服务端，服务端再转发给客户端，用户就可以播放了。\nGB28181 传输协议是 RTP，去掉 RTP 头部，剩余数据为 H264 PS 流，可使用 VLC 直接播放\nGB28181 报文 # 国标 IPC 的 IP 为 192.168.10.8， IPC 本地 SIP 端口为 60719， SIP ID 为 34020000002000000719；\nSIP 服务器的 IP 为 192.168.10.10， SIP 服务器的端口为 57030， SIP ID 为 34020000002000000001。\n整个国标信令部分基于 UDP 协议进行传输。\n开发基于 resiprocate/resiprocate 注册（REGISTER） # 注销（CANCEL） # 心跳（Keepalive） # INVITE # 云台控制（PTZ） # GB28181 协议版本 # 2012 年，GB/T-28181 的第一版标准 # 国家为了规范安防行业的设备平台互联互通，在 2012 年出台了 GB/T-28181 的第一版标准\n协议对流媒体的规范还是比较好（H.264 + G711 封装成 PS 流，再经过 RTP 协议进行实时传输），但是控制方面有很多不足，相对于当前流行的 ONVIF 协议在控制信令上还是有很多不足。\n2014 年，修改补充文件 # 后续公安一所又感觉 2011 版本的协议不能满足方方面面的信令需求，于是增加了修改补充协议 这次的补充，完善之前协议各地方说辞有误或是不清晰的地方，还增加了不少的信令需求，如：回放、下载、配置、传输协议、设备控制（拉宽放大、缩小）等待一系列的功能。\n2016 年，GB/T-28181 - 2016 版本 # 2016 年公安部一所又推出了 GB/T-28181 - 2016 版本，此版本就是对之前的 2011 版和修改补充版进行合并，并增加一些信令，说明制定协议的同志们一直都在努力。\n这次的版本应该算是阶段性的版本了，短时间内应该不会修改了。\nUDP vs TCP 主动 vs TCP 被动 # 在 GB28181 的 2016 版中，对于媒体流的传输在原有 UDP 传输的基础中，增加了主动 tcp 和被动 tcp 的方式。\nRTP over UDP vs RTP over TCP\n# 默认 UDP m=audio 6000 RTP/AVP 8 # 指定 TCP m=video 6000 TCP/RTP/AVP 96 主动 TCP vs 被动 TCP\na=setup:active a=setup:passive UDP # 这个是普遍的传输方式\nGB28181 服务端在发 invite 时，在携带的 SDP 中包含了接收媒体的端口，设备端（被呼叫端）收到 invite 后，解析该端口，通过 UDP 将媒体流发向该端口。\nTCP 被动 # GB28181 服务端在发 invite 时，在携带的 SDP 中包含了接收媒体的端口，并监听该端口的媒体数据，设备端（被呼叫端）收到 invite 后，解析该端口，通过 TCP 将媒体流发向该端口。\nTCP 主动 # 设备端（被呼叫端）告知服务端自己的媒体流 tcp 端口，服务端主动去连接设备端（被呼叫端）的该端口，获取数据。\n参考：\nGB28181 协议实现简介 GB28181 的协议栈实现 # GB/T-28181 协议其实就是在国际上通用的 SIP 协议进行私有化定制， 流媒体方面就是在国际最流行的编码上进行封装（当然也有我们国家的编码标准 SVAC）。\nlibosip + libexosip + libxml 来实现 IPC 和平台协议功能，前面两者负责 sip 协议的实现，libxml 用来封装和解析实体信令。通过 3~4 年的市场应用感觉挺稳定的。\n流媒体方面：从编码中获取的 h.264 + g711 的视音频帧，进行 PS 媒体协议封装（自己写的 PS 封装协议），再经过 RTP 传输协议（自己实现）发送至平台。\n平台对收到的 RTP 流媒体进行解 RTP, 解 PS，再进行 h.264 + g711 的解码。\nSIP 协议 # 会话初始协议\nSIP 协议是一个应用层的点对点协议，用于初始、管理和终止网络中的语音和视频会话，是 GB28181 的核心之一。\n会话发起协议（ Session Initiation Protocol，缩写 SIP）是一个由 IETF MMUSIC 工作组开发的协议，作为标准被提议用于创建，修改和终止包括视频，语音，即时通信，在线游戏和虚拟现实等多种多媒体元素在内的交互式用户会话。2000 年 11 月，SIP 被正式批准成为 3GPP 信号协议之一，并成为 IMS 体系结构的一个永久单元。SIP 与 H.323 一样，是用于 VoIP 最主要的信令协议之一。\nAntisip\nList of SIP software\nosip vs exosip # osip # oSIP is a free software library for VoIP applications implementing lower layers of Session Initiation Protocol (SIP).\noSIP 的开发开始于 2000 年 7 月，第一个版本在 2001 年 5 月发布。\noSIP 采用 ANSI C 编写，而且结构简单小巧，所以速度特别快。\n它并不提供高层的 SIP 会话 控制 API，它主要提供一些解析 SIP/SDP 消息的 API 和事务处理的状态机。\noSIP 不提供任何快速产生请求消息和响应消息的方法，所有请求消息和响应消息的形成必须调用一组 sip message api 来手动组装完成，\noSIP 的作者还开发了基于 oSIP 的 UA lib:exosip 和 proxy server lib:partysip\nSoftware using oSIP\neXosip, the \u0026ldquo;eXtended osip\u0026rdquo; library. An extension of oSIP for softphone implementation written by Aymeric Moizard. GNU SIP Witch exosip # pjsip # PJSIP 是一个开源的 SIP 协议库，它实现了 SIP、SDP、RTP、STUN、TURN 和 ICE。PJSIP 作为基于 SIP 的一个多媒体通信框架提供了非常清晰的 API，以及 NAT 穿越的功能。PJSIP 具有非常好的移植性，几乎支持现今所有系统：从桌面系统、嵌入式系统到智能手机。\nPJSIP 同时支持语音、视频、状态呈现和即时通讯。PJSIP 具有非常完善的文档，对开发者非常友好。\nPJSIP 由 Benny Prijono、Perry Ismangil 在 2005 年创建，之后不久，Nanang Izzuddin、Sauw Ming 加入开发团队。2006 年成立 Teluu Ltd.，成为开发和维护 PJSIP 的公司。PJSIP 采用双 License：GPLv2 以及商业许可证，开发者可以根据需要选择不同的 License。\n"},{"id":861,"href":"/note-cs/docs/study/skill/stream-media/gb28181/sdp/","title":"SDP","section":"GB28181","content":" SDP # Session Description Protocol\nSDP 本身并不提供媒体服务，它只是描述了媒体服务在哪，以及如何和那个媒体服务打交道。\n媒体传输相关的协议在 SIP 消息 SDP 段携带， 在服务器和客户端之间进行商议。\nSDP 协议的具体内容参看：RFC2327\n由于 Web 端、IOS、Android、PC、MAC 端的差异性导致它们对音视频的支持能力不同， 所以我们进行一些音视频会话之前，需要交互下彼此的音视频编解码能力、网络带宽和传输协议等信息， 这些需要协商的信息需要用 SDP 来描述。\nSDP 并不是传输协议，需要用 RTSP、SIP、HTTP 等协议进行承载传输、交换， 如果大家协调好了之后，就可以建立会话，完成真实的音视频码流传输，再完成解码和播放。\nSDP 一般用在媒体会话建立之前，可以适用于实时流媒体、点播、直播等领域，特别在音视频通话、视频会议、VoIP、视频监控等领域应用较多。 媒体码流一般基于 RTP 传输，服务质量用 RTCP 协议保障。\n但是 SDP 的交互不是所有音视频会话建立时都是必须的，假如双方提前约定好这些音视频会话创建需要的信息就不用这个步骤来交互彼此的 SDP 信息， 比如 HTTP-FLV、RTMP-FLV 直播和点播方案，因为一旦采用了这套方案，这些音视频会话建立需要的信息都是确定的， 但是这样会降低或者说没有充分发挥端到端的音视频能力，协商显得更加灵活点。\nSDP 作用 # SDP 作用包括以下一些方面\n建立会话的详细信息，包括名称，网络，带宽等信息 包含在会话中的媒体信息，包括： 媒体类型 (video, audio, etc) 传输协议 (RTP/UDP/IP, H.320, etc) 媒体格式 (H.261 video, MPEG video, etc) 多播或远端（单播）地址和端口 为接收媒体而需的信息 使用的带宽信息 可信赖的接洽信息 如果拓展，还可以描述会话的安全方案信息、服务质量信息等，其中 WebRTC 就在 SDP 的基础上进行了继续拓展\n协议包格式 # Protocol: SIP/SDP\nFrame 238: 633 bytes on wire (5064 bits), 633 bytes captured (5064 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (200) Status-Line: SIP/2.0 200 OK Status-Code: 200 [Resent Packet: False] [Request Frame: 234] [Response Time (ms): 17] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport=5060;branch=z9hG4bK575396672;received=192.168.137.105 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=139396672 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=403895202 Call-ID: 325396492 CSeq: 3 INVITE Contact: \u0026lt;sip:34020000001320000001@192.168.64.3:41073\u0026gt; Content-Type: application/sdp User-Agent: IP Camera Content-Length: 191 Message Body Session Description Protocol Session Description Protocol Version (v): 0 Owner/Creator, Session Id (o): 34020000001320000001 1136 1136 IN IP4 192.168.137.109 Session Name (s): Play Connection Information (c): IN IP4 192.168.137.109 Time Description, active time (t): 0 0 Media Description, name and address (m): video 15060 RTP/AVP 96 Media Attribute (a): sendonly Media Attribute (a): rtpmap:96 PS/90000 Media Attribute (a): filesize:0 Unknown: y=0200000001 Version (v) # Session Name (s) # Media Description, name and address (m) # Media Attribute (a) # y # GB28181 规定， y 用 10 位十进制数来表示 32 bit 的 SSRC\n第 1 位为历史或者实时媒体流的标识位，0 为实时，1 为历史； 第 2 位到第 6 位取 20 位 SIP 监控域 ID 之中的 4-8 位作为域标识； 第 7-10 位作为域内媒体流标识，是一个与当前域内产生的媒体流 SSRC 值后 4 位不重复的四位十进制整数； "},{"id":862,"href":"/note-cs/docs/study/skill/stream-media/gb28181/sip/","title":"SIP","section":"GB28181","content":" SIP # SIP 协议使用 RTP 协议传送音视频数据流，使用 SDP 协议进行媒体描述。\nCALL-ID # SIP 的一次通话，可以通过 From, To, Call-ID 三元组来区分。\nCALL-ID 字段用于标识一个特定邀请以及与这个邀请相关的所有后续事务（即标识一个会话）\n包内容 # Message # Session Initiation Protocol (MESSAGE) Request-Line: MESSAGE sip:34020000002000000001@3402000000 SIP/2.0 Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport;branch=z9hG4bK1013136823 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=676399389 To: \u0026lt;sip:34020000002000000001@3402000000\u0026gt; Call-ID: 1119613114 CSeq: 20 MESSAGE Content-Type: Application/MANSCDP+xml Max-Forwards: 70 User-Agent: IP Camera Content-Length: 178 Message Body \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;GB2312\u0026#34;?\u0026gt;\\n \u0026lt;Notify\u0026gt;\\n \u0026lt;CmdType\u0026gt;Keepalive\u0026lt;/CmdType\u0026gt;\\n \u0026lt;SN\u0026gt;123\u0026lt;/SN\u0026gt;\\n \u0026lt;DeviceID\u0026gt;34020000001320000001\u0026lt;/DeviceID\u0026gt;\\n \u0026lt;Status\u0026gt;OK\u0026lt;/Status\u0026gt;\\n \u0026lt;Info\u0026gt;\\n \u0026lt;/Info\u0026gt;\\n \u0026lt;/Notify\u0026gt;\\n Bye # 同一个会话，CSeq 要 +1\nInvite-\u0026gt;100-\u0026gt;200-\u0026gt;Ack -\u0026gt;Bye-\u0026gt;200\nBye 的包，From 和 To 要和 Ack 的一致（包括 tag），Call-ID 也要一致\n包字段 # SN（命令序列号） # MANSCDP 消息中的 SN 值用于与请求命令的匹配处理,响应命令中的 SN 值应使用请求命令中的 SN 值。\nSIP Proxy # SIP Proxy 有分为两种模式，一种是状态代理模式，另外一种是无状态代理模式。\nSIP 代理自己本身不能发起 INVITE 或者 BYE 请求，这样就不能满足 IP 语音通信的基本呼叫功能。\n双方终端通过多个 Proxy 代理以后，根据 Route Set 返回处理流程。 但是，在一些情况下，如果终端忽略了 Route Set 以后，直接通过呼叫方和被呼叫方，双方可能进行非法呼叫， 它们跳过了代理服务器，导致业务控制层很难对其进行管理。\n为了解决这个问题，引入了 B2BUA 机制，通过背靠背的方式来实现业务能力的管理和会话的管理\n开源实现 # Kamalio # kamailio/kamailio OpenSIPS # OpenSIPS/opensips B2BUA # B2BUA 是一个逻辑实体，它由一个 UAS 和一个 UAC 两个部分构成，分别负责接收请求，处理请求和生成请求。 B2BUA 和 SIP 代理不同，它必须保持在 dialog 中所有创建的请求。只有这样，B2BUA 才能完全控制所有需要管理的会话。\nB2BUA 具体的构成如下：\nB2BUA 介于两个终端之间\nUAC 对 B2BUA 发起一个 INVITE 请求，在 B2BUA 端，B2BUA 是一个 UAS 来接收这个请求，创建了第一个会话来管理这个请求。双方保存了彼此的 Route Set 记录消息。 为了对另外一个终端发起 INVITE 请求，B2BUA 同时也扮演了一个 UAC 的角色，它创建了第二个会话，并且再次对下游终端发起 INVITE 请求。这里，UAC 需要从 UAS 端拷贝 SDP 消息和其他必要消息内容。然后，UAC 对下游终端发起 INVITE 请求。终端接收了 INVITE 请求，并且保存了 Route Set 数据记录。 为了响应 INVITE 请求，这里，下游终端就会变成一个 UAS 回复 B2BUA 200 OK。B2BUA 再次拷贝 200 OK 的消息，然后通过 UAS 再次返回到 UAC 终端。 UAC 终端收到 200 OK 以后，保存为 Route Set 数据内容。 为什么需要 B2BUA # 如果计费模块检测到双方呼叫费用出现超额的时候，这时，B2BUA 会切换成 UAC/UAC 的状态，同时对终端发送 BYE 消息。\n教程 # Session Initiation Protocol Tutorial (by tutorialspoint) 参考 # B2BUA/SBC/Proxy 的 SIP 消息重构和 RFC7092 详解 "},{"id":863,"href":"/note-cs/docs/study/skill/stream-media/voip/","title":"VoIP","section":"4.5 流媒体","content":" VoIP # VoIP vs SIP # In simple terms, VoIP means making or receiving phone calls over the internet or internal networks. SIP, on the other hand, is an application layer protocol that is used to establish, modify and terminate multimedia sessions such as VoIP calls.\nA major difference between VoIP and SIP is their scope. VoIP is not a discrete technology in its own right. Rather, it is actually a family of technologies used within modern telecommunication networks, whereas SIP is a signalling protocol used within the VoIP umbrella.\nA further difference is that, whilst VoIP sends only voice messages, SIP can carry all forms of media, not just voice messages. Transmitted via data networks, SIP trunks send packets, which may include voice, data, or video content. This means that SIP systems allow users to make voice and video calls online, often for free.\n参考：\nKey differences between SIP \u0026amp; VOIP "},{"id":864,"href":"/note-cs/docs/study/skill/stream-media/gb28181/protocal/","title":"协议详情","section":"GB28181","content":" GB28181 协议解析 # 点击在线查看标准完整文本： 公共安全视频监控联网系统信息传输、交换、控制技术要求。\n名词解释 # SIP 服务器 # SIP client # 具有注册登记、建立 / 终止会话连接、接收和播放视音频流等功能，主要包括用户界面、用户代理 (UA)、媒体解码模块和媒体通信模块。\nSIP device # 具有注册、建立 / 终止会话连接和控制、采集 / 编解码以及传送视音频流等的功能实体，主要包括用户代理 (UA)、媒体采集 / 编解码模块和媒体通信模块。\n联网系统中 SIP 设备的实现形式主要有支持 SIP 协议的网络摄像机、视频编 / 解码设备、数字硬盘录像机 (DVR) 和报警设备等。若 SIP 设备具有多路视音频编解码通道，每个通道宜成为一个 SIP 逻辑 UA, 具有唯一的 SIPURI, 并向 SIP 服务器注册。\nSIP 监控域 SIP surveil lance realm # 支持本标准规定的通信协议的监控网络，通常由 SIP 服务器和注册在 SIP 服务器上的监控资源、用户终端、网络等组成。\n注册服务器 register server # IETF RFC 3261 规定的 SIP 逻辑实体，是具有接收注册请求、将请求中携带的信息进行保存并提供本域内位置服务的功能服务器。\n中心信令控制服务器 center control server # 具有向 SIP 客户端、SIP 设备、媒体服务器和网关提供注册、路由选择以及逻辑控制功能，并且提供接口与应用服务器通信。\n组成中心信令控制的逻辑实体包括代理服务器、注册服务器、重定向服务器、背靠背用户代理等的一种或者几种，是负责核心 SIP 信令应用处理的 SIP 服务器。\n媒体服务器 media server # 提供实时媒体流的转发服务，提供媒体的存储、历史媒体信息的检索和点播服务。\n媒体服务器接收来自 SIP 设备、网关或其他媒体服务器等设备的媒体数据，并根据指令，将这些数据转发到其他单个或者多个 SIP 客户端和媒体服务器。\n信令安全路由网关 secure signal routing gateway # 具有接收或转发域内外 SIP 信令功能，并且完成信令安全路由网关间路由信息的传递以及路由信令、信令身份标识的添加和鉴别等功能，是一种具有安全功能的 SIP 服务器。\nSIP 监控域互联结构 # GB28181 通信协议结构 # 交互过程 # 客户端主动发起 # 趣解：\n第三方呼叫控制 # 编码规则 # 设备 ID, 通道 ID # # 一共 20 位 34020000001320000001 省 市 区 单位 行业 设备类型 网络标识 设备序号 34 02 00 00 00 132 0 000001 "},{"id":865,"href":"/note-cs/docs/study/skill/stream-media/gb28181/packet/","title":"数据包","section":"GB28181","content":" 数据包 # Register # request: Register (no auth) # Frame 2117: 442 bytes on wire (3536 bits), 442 bytes captured (3536 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (REGISTER) Request-Line: REGISTER sip:34020000002000000001@3402000000 SIP/2.0 Method: REGISTER Request-URI: sip:34020000002000000001@3402000000 [Resent Packet: True] [Suspected resend of frame: 1613] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport;branch=z9hG4bK1935014795 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=496441511 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt; Call-ID: 1188137981 CSeq: 1 REGISTER Contact: \u0026lt;sip:34020000001320000001@192.168.137.109:5060\u0026gt; Max-Forwards: 70 User-Agent: IP Camera Expires: 3600 Content-Length: 0 response: 401 # Frame 2121: 524 bytes on wire (4192 bits), 524 bytes captured (4192 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (401) Status-Line: SIP/2.0 401 Unauthorized Status-Code: 401 [Resent Packet: False] [Request Frame: 1613] [Response Time (ms): 15594] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport=47918;received=192.168.64.3;branch=z9hG4bK1935014795 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=496441511 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=697042285 CSeq: 1 REGISTER Call-ID: 1188137981 User-Agent: LiveGBS v200603 Contact: \u0026lt;sip:34020000002000000001@192.168.64.3:15060\u0026gt; Content-Length: 0 WWW-Authenticate: Digest realm=\u0026#34;3402000000\u0026#34;,qop=\u0026#34;auth\u0026#34;,nonce=\u0026#34;a1b6ba00d8cbaa8ce99d1d39b2905d12\u0026#34; request: register (auth) # Frame 2122: 704 bytes on wire (5632 bits), 704 bytes captured (5632 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (REGISTER) Request-Line: REGISTER sip:34020000002000000001@3402000000 SIP/2.0 Method: REGISTER Request-URI: sip:34020000002000000001@3402000000 [Resent Packet: False] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport;branch=z9hG4bK2038639153 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=496441511 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt; Call-ID: 1188137981 CSeq: 2 REGISTER Contact: \u0026lt;sip:34020000001320000001@192.168.137.109:5060\u0026gt; [truncated]Authorization: Digest username=\u0026#34;34020000001320000001\u0026#34;, realm=\u0026#34;3402000000\u0026#34;, nonce=\u0026#34;a1b6ba00d8cbaa8ce99d1d39b2905d12\u0026#34;, uri=\u0026#34;sip:34020000002000000001@3402000000\u0026#34;, response=\u0026#34;487b46591eae35a8d8f684db454ec471\u0026#34;, algorithm=MD5, cnonce Max-Forwards: 70 User-Agent: IP Camera Expires: 3600 Content-Length: 0 response: 200 # Frame 2123: 463 bytes on wire (3704 bits), 463 bytes captured (3704 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (200) Status-Line: SIP/2.0 200 OK Status-Code: 200 [Resent Packet: False] [Request Frame: 2122] [Response Time (ms): 17] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport=60954;received=192.168.64.3;branch=z9hG4bK2038639153 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=496441511 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=410042311 CSeq: 2 REGISTER Call-ID: 1188137981 User-Agent: LiveGBS v200603 Contact: \u0026lt;sip:34020000002000000001@192.168.64.3:15060\u0026gt; Content-Length: 0 Date: 2020-06-09T14:09:01.830 Expires: 3600 remove 1 binding # 有 remove 1 binding, 然后重新 register 的现象\nMessage Header：\nCSeq 加 1， Contact 的 expires=0 Message # request: sip server -\u0026gt; ipc # Frame 2136: 571 bytes on wire (4568 bits), 571 bytes captured (4568 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (MESSAGE) Request-Line: MESSAGE sip:34020000001320000001@3402000000 SIP/2.0 Method: MESSAGE Request-URI: sip:34020000001320000001@3402000000 [Resent Packet: False] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport;branch=z9hG4bK268043391 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=181043391 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt; Call-ID: 44043391 CSeq: 1 MESSAGE Content-Type: Application/MANSCDP+xml Max-Forwards: 70 User-Agent: LiveGBS v200603 Content-Length: 162 Message Body \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\\r\\n \u0026lt;Query\u0026gt;\\r\\n \u0026lt;CmdType\u0026gt;Catalog\u0026lt;/CmdType\u0026gt;\\r\\n \u0026lt;SN\u0026gt;445043391\u0026lt;/SN\u0026gt;\\r\\n \u0026lt;DeviceID\u0026gt;34020000001320000001\u0026lt;/DeviceID\u0026gt;\\r\\n \u0026lt;/Query\u0026gt;\\r\\n response: ipc -\u0026gt; sip server # Frame 2137: 352 bytes on wire (2816 bits), 352 bytes captured (2816 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (200) Status-Line: SIP/2.0 200 OK Status-Code: 200 [Resent Packet: False] [Request Frame: 2136] [Response Time (ms): 5] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport=5060;branch=z9hG4bK268043391;received=192.168.137.105 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=181043391 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=2000290983 Call-ID: 44043391 CSeq: 1 MESSAGE User-Agent: IP Camera Content-Length: 0 request: ipc -\u0026gt; sip server # Frame 2138: 1001 bytes on wire (8008 bits), 1001 bytes captured (8008 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (MESSAGE) Request-Line: MESSAGE sip:34020000002000000001@3402000000 SIP/2.0 Method: MESSAGE Request-URI: sip:34020000002000000001@3402000000 [Resent Packet: False] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport;branch=z9hG4bK461606833 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=106117409 To: \u0026lt;sip:34020000002000000001@3402000000\u0026gt; Call-ID: 2113631911 CSeq: 20 MESSAGE Content-Type: Application/MANSCDP+xml Max-Forwards: 70 User-Agent: IP Camera Content-Length: 591 Message Body \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;GB2312\u0026#34;?\u0026gt;\\n \u0026lt;Response\u0026gt;\\n \u0026lt;CmdType\u0026gt;Catalog\u0026lt;/CmdType\u0026gt;\\n \u0026lt;SN\u0026gt;445043391\u0026lt;/SN\u0026gt;\\n \u0026lt;DeviceID\u0026gt;34020000001320000001\u0026lt;/DeviceID\u0026gt;\\n \u0026lt;SumNum\u0026gt;1\u0026lt;/SumNum\u0026gt;\\n \u0026lt;DeviceList Num=\u0026#34;1\u0026#34;\u0026gt;\\n \u0026lt;Item\u0026gt;\\n \u0026lt;DeviceID\u0026gt;34020000001320000001\u0026lt;/DeviceID\u0026gt;\\n \u0026lt;Name\u0026gt;Camera 01\u0026lt;/Name\u0026gt;\\n \u0026lt;Manufacturer\u0026gt;Hikvision\u0026lt;/Manufacturer\u0026gt;\\n \u0026lt;Model\u0026gt;IP Camera\u0026lt;/Model\u0026gt;\\n \u0026lt;Owner\u0026gt;Owner\u0026lt;/Owner\u0026gt;\\n \u0026lt;CivilCode\u0026gt;3402000000\u0026lt;/CivilCode\u0026gt;\\n \u0026lt;Address\u0026gt;Address\u0026lt;/Address\u0026gt;\\n \u0026lt;Parental\u0026gt;0\u0026lt;/Parental\u0026gt;\\n \u0026lt;ParentID\u0026gt;34020000002000000001\u0026lt;/ParentID\u0026gt;\\n \u0026lt;SafetyWay\u0026gt;0\u0026lt;/SafetyWay\u0026gt;\\n \u0026lt;RegisterWay\u0026gt;1\u0026lt;/RegisterWay\u0026gt;\\n \u0026lt;Secrecy\u0026gt;0\u0026lt;/Secrecy\u0026gt;\\n \u0026lt;Status\u0026gt;ON\u0026lt;/Status\u0026gt;\\n \u0026lt;/Item\u0026gt;\\n \u0026lt;/DeviceList\u0026gt;\\n \u0026lt;/Response\u0026gt;\\n request: sip server -\u0026gt; ipc # Frame 2139: 360 bytes on wire (2880 bits), 360 bytes captured (2880 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (200) Status-Line: SIP/2.0 200 OK Status-Code: 200 [Resent Packet: False] [Request Frame: 2138] [Response Time (ms): 16] Message Header Via: SIP/2.0/UDP 192.168.137.109:5060;rport=60954;received=192.168.64.3;branch=z9hG4bK461606833 From: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=106117409 To: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=443043407 CSeq: 20 MESSAGE Call-ID: 2113631911 User-Agent: LiveGBS v200603 Content-Length: 0 Invite # request: sip server -\u0026gt; ipc (SIP/SDP) # Frame 288: 746 bytes on wire (5968 bits), 746 bytes captured (5968 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (INVITE) Request-Line: INVITE sip:34020000001320000001@3402000000 SIP/2.0 Method: INVITE Request-URI: sip:34020000001320000001@3402000000 [Resent Packet: False] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport;branch=z9hG4bK685516389 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=171516389 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt; Call-ID: 16516245 CSeq: 4 INVITE Content-Type: APPLICATION/SDP Contact: \u0026lt;sip:34020000002000000001@192.168.64.3:15060\u0026gt; Max-Forwards: 70 User-Agent: LiveGBS v200603 Subject: 34020000001320000001:0200000001,34020000002020000001:0 Content-Length: 226 Message Body Session Description Protocol Session Description Protocol Version (v): 0 Owner/Creator, Session Id (o): 34020000002000000001 0 0 IN IP4 192.168.137.105 Session Name (s): Play Connection Information (c): IN IP4 192.168.137.105 Time Description, active time (t): 0 0 Media Description, name and address (m): video 30000 RTP/AVP 96 97 98 Media Attribute (a): recvonly Media Attribute (a): rtpmap:96 PS/90000 Media Attribute (a): rtpmap:97 MPEG4/90000 Media Attribute (a): rtpmap:98 H264/90000 Unknown: y=0200000001 response: 100 Trying (ipc -\u0026gt; sip server, SIP) # Frame 295: 340 bytes on wire (2720 bits), 340 bytes captured (2720 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (100) Status-Line: SIP/2.0 100 Trying Status-Code: 100 [Resent Packet: False] [Request Frame: 288] [Response Time (ms): 16] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport=5060;branch=z9hG4bK685516389;received=192.168.137.105 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=171516389 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt; Call-ID: 16516245 CSeq: 4 INVITE User-Agent: IP Camera Content-Length: 0 response: 200 (ipc -\u0026gt; sip server, SIP/SDP) # Frame 297: 632 bytes on wire (5056 bits), 632 bytes captured (5056 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (200) Status-Line: SIP/2.0 200 OK Status-Code: 200 [Resent Packet: False] [Request Frame: 288] [Response Time (ms): 20] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport=5060;branch=z9hG4bK685516389;received=192.168.137.105 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=171516389 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=614786748 Call-ID: 16516245 CSeq: 4 INVITE Contact: \u0026lt;sip:34020000001320000001@192.168.64.3:55302\u0026gt; Content-Type: application/sdp User-Agent: IP Camera Content-Length: 191 Message Body Session Description Protocol Session Description Protocol Version (v): 0 Owner/Creator, Session Id (o): 34020000001320000001 2346 2346 IN IP4 192.168.137.109 Session Name (s): Play Connection Information (c): IN IP4 192.168.137.109 Time Description, active time (t): 0 0 Media Description, name and address (m): video 15060 RTP/AVP 96 Media Attribute (a): sendonly Media Attribute (a): rtpmap:96 PS/90000 Media Attribute (a): filesize:0 Unknown: y=0200000001 ACK # request: sip server -\u0026gt; ipc (SIP) # Frame 298: 430 bytes on wire (3440 bits), 430 bytes captured (3440 bits) on interface 0 Ethernet II, Src: Apple_70:23:0d (88:e9:fe:70:23:0d), Dst: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52) Internet Protocol Version 4, Src: 192.168.137.105, Dst: 192.168.137.109 User Datagram Protocol, Src Port: 5060, Dst Port: 5060 Session Initiation Protocol (ACK) Request-Line: ACK sip:34020000001320000001@3402000000 SIP/2.0 Method: ACK Request-URI: sip:34020000001320000001@3402000000 [Resent Packet: False] [Request Frame: 288] [Response Time (ms): 61] Message Header Via: SIP/2.0/UDP 192.168.64.3:15060;rport;branch=z9hG4bK193516446 From: \u0026lt;sip:34020000002000000001@3402000000\u0026gt;;tag=171516389 To: \u0026lt;sip:34020000001320000001@3402000000\u0026gt;;tag=614786748 Call-ID: 16516245 CSeq: 4 ACK Contact: \u0026lt;sip:34020000002000000001@192.168.64.3:15060\u0026gt; Max-Forwards: 70 User-Agent: LiveGBS v200603 Content-Length: 0 RTP # ipc -\u0026gt; sip server # Sequence number 递增\nFrame 299: 1454 bytes on wire (11632 bits), 1454 bytes captured (11632 bits) on interface 0 Ethernet II, Src: 98:df:82:6d:9e:52 (98:df:82:6d:9e:52), Dst: Apple_70:23:0d (88:e9:fe:70:23:0d) Internet Protocol Version 4, Src: 192.168.137.109, Dst: 192.168.137.105 User Datagram Protocol, Src Port: 15060, Dst Port: 30000 Real-Time Transport Protocol [Stream setup by SDP (frame 288)] 10.. .... = Version: RFC 1889 Version (2) ..0. .... = Padding: False ...0 .... = Extension: False .... 0000 = Contributing source identifiers count: 0 0... .... = Marker: False Payload type: PS (96) Sequence number: 0 [Extended sequence number: 65536] Timestamp: 0 Synchronization Source identifier: 0x0bebc201 (200000001) Payload: 000001ba6e617c97940107599ffeffff01f2c2b4000001bb... "},{"id":866,"href":"/note-cs/docs/study/skill/stream-media/gb28181/code/","title":"源码实现","section":"GB28181","content":" 源码实现 # 名词解释 # AOR：Address Of Record 是 header 中的 From 字段 开源实现 # go # StefanKopieczek/gossip rainliu/gosips 1lann/go-sip ghettovoice/gosip Inspired by: StefanKopieczek/gossip 1lann/go-sip kirm/sip.js cloudwebrtc/go-sip-ua Dependencies ghettovoice/gosip SIP stack c-bata/go-prompt Console for b2bua pixelbender/go-sdp SDP C # pjsip/pjproject C# # GB28181/GB28181.Solution C++ # ossrs/srs xiongziliang/ZLMediaKit Node.js # kirm/sip.js 二进制（前端开源，后端不开源） # livegbs/GB28181-Server "},{"id":867,"href":"/note-cs/docs/study/skill/stream-media/onvif/gsoap/","title":"gsoap 生成 onvif 框架","section":"ONVIF","content":" gsoap 生成 onvif 框架 # 生成参数 # wsdl2h # -O4 # aggressively optimizes the output by \u0026ldquo;schema slicing\u0026rdquo; to remove unused schema components, see our article Schema Slicing Methods to Reduce Development Costs of WSDL-Based Web Services for details;\n-P # don\u0026rsquo;t create polymorphic types inherited from xsd__anyType;\nremoves the base class xsd__anyType from the generated C++ classes, which are normally added by wsdl2h if the xsd:anyType XSD type is used somewhere in a WSDL.\nHowever, for the ONVIF protocols we do not need to inherit the xsd__anyType class and we can reduce the generated code size accordingly;\n-x # don\u0026rsquo;t generate _XML any/anyAttribute extensibility elements;\nremoves the unnecessary generated code for the extensibility elements xsd:any and attributes xsd:anyAttribue, since we do not need to support these in general, except for some specific cases see further below. An alternative is to use option -d to generate embedded DOM code which allows you to add any XML content via the generated xsd__anyType __any members that are DOM nodes;\nwsdl2h 其他参数：\n-h : help -s : don\u0026rsquo;t generate STL code (no std::string and no std::vector) -t : typemapfile soapcpp2 # -2 # forces SOAP 1.2, which is required by ONVIF;\n-j # For C++ projects you should generate C++ proxy classes using soapcpp2 option -j. Proxy classes are** easier to use** than the global functions that are generated without this option.\nsoapcpp2 其他参数:\n-h: help -x : don\u0026rsquo;t generate sample XML message files -d : use path to save files -p: save files with new prefix name instead of \u0026lsquo;soap\u0026rsquo; -C: generate client-side source code only -L: don\u0026rsquo;t generate soapClientLib/soapServerLib -I : use path(s) for #import (paths separated with \u0026lsquo;:\u0026rsquo;) 生成过程要做的事情 # 执行前 # 修改 typemap.dat\nduration.h 毫秒级 （选了这个）\nchrono_duration.h 纳秒级\nTo automatically enable the first choice of serializer for xsd:duration, add the following line to typemap.dat if not already there:\nxsd__duration = #``import \u0026quot;custom/duration.h\u0026quot; | xsd__duration\nThis imports custom/duration.h into the wsdl2h-generated onvif.h binding interface.\n执行 wsdl2h 后 # change #import \u0026quot;wsdd10.h\u0026quot; to #import \u0026quot;wsdd5.h\u0026quot; in onvif.h\nYou may want to change #import \u0026quot;wsdd10.h\u0026quot; to #import \u0026quot;wsdd5.h\u0026quot; in onvif.h, because ONVIF uses WS-Addressing 2005/08 whereas WS-Discovery declared in wsdd10.h assumes WS-Addressing 2004/08\n添加 #import \u0026ldquo;wsse.h\u0026rdquo;\n执行 soapcpp2 后 # Using WS-Security # include\ngsoap/plugin/wsseapi.h compile\ngsoap/plugin/wsseapi.c\ngsoap/plugin/smdevp.c\ngsoap/plugin/mecevp.c\n-DWITH_OPENSSL and -DWITH_DOM\nlink\n-lgsoapssl++ 或 compilegsoap/stdsoap2.cppandgsoap/dom.cpp\\ 2.\nUsing WS-Discovery # When the ONVIF remotediscovery WSDL is used to build an ONVIF application, WS-Discovery is required.\ninclude gsoap/plugin/wsddapi.h compile gsoap/plugin/wsddapi.c To support client-side WS-Discovery operations, we run soapcpp2 as follows as documented here:\nsoapcpp2 -a -x -L -pwsdd -I ~/gsoap-``2.8``/gsoap/``import ~/gsoap-``2.8``/gsoap/``import``/wsdd5.h\nThis generates wsddClient.cpp, which we will use later to compile with the project.\n编译参数 # makefile\nCC = g++ CPPFLAG = -Wall -g -std=c++11 -w -fPIC -DWITH_NONAMESPACES -fno-use-cxa-atexit -fexceptions -DWITH_DOM -DWITH_OPENSSL -DSOAP_DEBUG BASE_DIR = . INCLUDE += -I$(BASE_DIR) -I$(BASE_DIR)/onvif -I$(BASE_DIR)/gsoap -I/usr/local/opt/openssl@1.0/include LIB = -lssl -lcrypto -L/usr/local/opt/openssl@1.0/lib GsoapSOURCE = $(BASE_DIR)/gsoap GsoapOBJ = $(GsoapSOURCE)/wsaapi.o $(GsoapSOURCE)/wsseapi.o $(GsoapSOURCE)/threads.o $(GsoapSOURCE)/duration.o \\ $(GsoapSOURCE)/smdevp.o $(GsoapSOURCE)/mecevp.o $(GsoapSOURCE)/dom.o $(GsoapSOURCE)/struct_timeval.o OnvifSOURCE = $(BASE_DIR)/onvif OnvifOBJ = $(OnvifSOURCE)/soapAdvancedSecurityServiceBindingProxy.o $(OnvifSOURCE)/soapDeviceBindingProxy.o $(OnvifSOURCE)/soapDeviceIOBindingProxy.o \\ $(OnvifSOURCE)/soapImagingBindingProxy.o $(OnvifSOURCE)/soapMediaBindingProxy.o $(OnvifSOURCE)/soapPTZBindingProxy.o \\ $(OnvifSOURCE)/soapPullPointSubscriptionBindingProxy.o $(OnvifSOURCE)/soapRemoteDiscoveryBindingProxy.o SRC = $(GsoapSOURCE)/stdsoap2.o $(OnvifSOURCE)/soapC.o $(OnvifSOURCE)/wsddClient.o $(BASE_DIR)/main.o $(GsoapOBJ) $(OnvifOBJ) OBJECTS = $(patsubst %.cpp,%.o,$(SRC)) TARGET = starry-eyes all: $(TARGET) $(TARGET):$(OBJECTS) $(CC) $(CPPFLAG) $(OBJECTS) $(INCLUDE) $(LIB) -o $(TARGET) $(OBJECTS):%.o : %.cpp $(CC) -c $(CPPFLAG) $(INCLUDE) $\u0026lt; -o $@ clean: rm -rf $(OBJECTS) 遇到的主要问题是这个错误：\nUndefined symbols for architecture x86_64: \u0026#34;soap_s2xsd__dateTime(soap*, char const*, timeval*)\u0026#34;, referenced from: soap_in_saml2__AuthnStatementType(soap*, char const*, saml2__AuthnStatementType*, char const*) in soapC.o soap_in_saml2__ConditionsType(soap*, char const*, saml2__ConditionsType*, char const*) in soapC.o soap_in_saml2__SubjectConfirmationDataType(soap*, char const*, saml2__SubjectConfirmationDataType*, char const*) in soapC.o soap_in_saml2__AssertionType(soap*, char const*, saml2__AssertionType*, char const*) in soapC.o soap_in_saml1__AuthenticationStatementType(soap*, char const*, saml1__AuthenticationStatementType*, char const*) in soapC.o soap_in_saml1__ConditionsType(soap*, char const*, saml1__ConditionsType*, char const*) in soapC.o soap_in_saml1__AssertionType(soap*, char const*, saml1__AssertionType*, char const*) in soapC.o ... soap_s2xsd__dateTime 这个函数在框架生成的 soapC.cpp 中有多次调用，之前 onvif wsdl 生成的框架里是没有的。\n后面找到是 gsoap 的 struct_timeval.c 中实现的，加入编译后，问题解决。\n参考：https://www.genivia.com/examples/onvif/index.html\n生成过程详情 # 1. 修改 typemap.dat，取消注释\nxsdduration = #import \u0026ldquo;custom/duration.h\u0026rdquo; | xsdduration\n2. 执行 wsdl2h 生成 onvif.h\nwsdl2h -O4 -P -x -o onvif.h \\ http://www.onvif.org/onvif/ver10/device/wsdl/devicemgmt.wsdl \\ http://www.onvif.org/onvif/ver10/events/wsdl/event.wsdl \\ http://www.onvif.org/onvif/ver10/deviceio.wsdl \\ http://www.onvif.org/onvif/ver20/imaging/wsdl/imaging.wsdl \\ http://www.onvif.org/onvif/ver10/media/wsdl/media.wsdl \\ http://www.onvif.org/onvif/ver20/ptz/wsdl/ptz.wsdl \\ http://www.onvif.org/onvif/ver10/network/wsdl/remotediscovery.wsdl \\ http://www.onvif.org/ver10/advancedsecurity/wsdl/advancedsecurity.wsdl 3. 修改 onvif.h，change #import \u0026quot;wsdd10.h\u0026quot; to #import \u0026quot;wsdd5.h\n4. 修改 onvif.h，添加 #import \u0026ldquo;wsse.h\u0026rdquo;\n5. 执行 soapcpp2 生成框架代码\n6. 执行 soapcpp2 -pwsdd 生成 wsddClient.cpp\nsoapcpp2 -2 -C -j -x -I ~/code/onvif/app-gsoap-2.8.98/gsoap:~/code/onvif/app-gsoap-2.8.98/gsoap/import:~/code/onvif/app-gsoap-2.8.98/gsoap/custom onvif.h -d onvif/ soapcpp2 -a -x -L -pwsdd -I ~/code/onvif/app-gsoap-2.8.98/gsoap/import ~/code/onvif/app-gsoap-2.8.98/gsoap/import/wsdd5.h -d onvif/ "},{"id":868,"href":"/note-cs/docs/study/skill/stream-media/onvif/","title":"ONVIF","section":"4.5 流媒体","content":" ONVIF # 官网：www.onvif.org\n"},{"id":869,"href":"/note-cs/docs/study/skill/stream-media/easydarwin/","title":"EasyDarwin","section":"4.5 流媒体","content":" EasyDarwin # EasyDarwin 是基于 Apple 的开源项目 Darwin Streaming Server 衍生而来的， Darwin 本身支持的是 RTSP 流媒体协议\nmacosforge/dss # Darwin Streaming Server is Apple\u0026rsquo;s open source version of the QuickTime Streaming Server technology allowing you to send streaming media across the Internet using the industry standard RTP and RTSP protocols.\nEasyDarwin 生态 # EasyDarwin 开源流媒体服务器：www.EasyDarwin.org EasyDSS 商用流媒体解决方案：www.EasyDSS.com, 点播与直播服务器 EasyBMS EasyRMS, 录播服务器 EasyNVR 无插件直播方案：www.EasyNVR.com, 摄像机互联网直播服务 EasyGB28181Server # EasyNVR 采用的是 Onvif 协议接入云平台， 而 EasyGB28181Server 则是以 GB/T28181 方式接入云平台\nEasyGB28181Server 交互流程\n启动 EasyGB28181Server, 接受摄像机的注册； EasyGB28181Server 将接收到的摄像机信息写入到 Redis 的设备列表； 与摄像机维持心跳； 打开网页客户端，即可看到所有的设备列表； 单击列表中的任一设备，EasyDSS 则向 EasyGB28181 服务器请求音视频； EasyGB28181Server 在收到 EasyDSS 的请求后，在 Redis 中找到负载最小的 EasyGB28181StreamServer; EasyGB28181Server 向找到的 EasyGB28181StreamServer 发送接收摄像机流的请求 EasyGB28181StreamServer 返回自身的外网 IP 和收流的端口 EasyGB28181Server 通知摄像机向 EasyGB28181StreamServer 的 IP 和 Port 发送音视频流 EasyGB28181StreamServer 收到摄像机的音视频后，将 PS 流转换为 ES 流，再转换为 RTMP 协议，传到 EasyDSS; EasyDSS 再将 RTMP 流转发给网页客户端； 至此，EasyGB28181Server + EasyGB28181StreamServer + EasyDSS 的整个流程完成；\n"},{"id":870,"href":"/note-cs/docs/study/skill/stream-media/srs/","title":"SRS","section":"4.5 流媒体","content":" SRS # ossrs/srs SRS is a RTMP/HLS/WebRTC/SRT/GB28181 streaming cluster, high efficiency, stable and simple.\n配置信息 # "},{"id":871,"href":"/note-cs/docs/study/skill/stream-media/zlmediakit/","title":"ZLMediaKit","section":"4.5 流媒体","content":" ZLMediaKit # xiongziliang/ZLMediaKit # h264推流 ffmpeg -re -i \u0026#34;/path/to/test.mp4\u0026#34; -vcodec h264 -acodec aac -f rtsp -rtsp_transport tcp rtsp://127.0.0.1/live/test ffmpeg -re -stream_loop -1 -i carbrand.MOV -vcodec h264 -acodec aac -f rtp_mpegts rtp://127.0.0.1:10000 rtsp __defaultVhost__ rtp 55667788 CodecH264[1920/1080/50] rtsp://127.0.0.1/rtp/55667788 "},{"id":872,"href":"/note-cs/docs/study/skill/stream-media/stream-media/","title":"流媒体技术","section":"4.5 流媒体","content":" 流媒体技术 # 视频编码 # H.264 H.265 H.266 Apple Pro Res (MOV 格式的专用编码) 音频编码 # AAC MP3 WAV FLAC（无损） APE（无损） 参考：\n音频编码格式的比较 视频容器 / 视频格式 # 一个格式却可以有不同的编码\nAVI (Audio Video Interleaved 音视频交错格式) RMVB FLV (Flash Video) MOV WMV (Windows Media Video) MP4 MKV MP4 # MP4 或称 MPEG-4 第 14 部分（英语：MPEG-4 Part 14）是一种标准的数字多媒体容器格式。MPEG-4 第 14 部分的扩展名为.mp4，以存储数字音频及数字视频为主，但也可以存储字幕和静止图像。因其可容纳支持比特流的视频流（如高级视频编码），MP4 可以在网络传输时使用流式传输。\nMKV # MKV 格式是民间流行的一种视频格式，以它兼容众多视频编码见长，可以是 DivX、XviD、RealVideo、H264、MPEG2、VC1 等等。但是由于是民间格式，没有版权限制，又易于播放，所以官方发布的视频影片都不采用 mkv，网上制作下载常见。\n视频传输协议 # RTP/RTCP RTMP HLS (HTTP Live Streaming) 流媒体传输协议 # 流媒体协议的作用：流同步，播放控制，质量控制，多端跨平台播放等 直播三要素：低延时，高可用，质量反馈和检测\n常见流媒体协议类型\n常见流媒体协议适用场景\nRTP/RTCP/RTSP # 封装：\nps ts 视频：\nH.264 H.265 VP9 音频：\naac g711.a RTSP\n基于 TCP 基于文本的双向实时传输协议，类似 HTTP 每个会话都含有状态，保持长连接，请求信令按顺序（HTTP 无状态） RTP/RTCP\n基于 UDP RTMP # Real-Time Messaging Protocol\nAdobe 的私有协议，性能相对 HTTP 比较低下。 数据和信令在一条通道。 长连接 基于 TCP HLS # HTTP Live Streaming\n基于 HTTP，性能不错 延时常常大于 10 秒，无法做直播互动 HLS 是由苹果公司提出基于 HTTP 的 流媒体网络传输协议。是苹果公司 QuickTime X 和 iPhone 软件系统的一部分。它的工作原理是把整个流分成一个个小的基于 HTTP 的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的 extended M3U (m3u8) playlist 文件，用于寻找可用的媒体流。\nHLS 只请求基本的 HTTP 报文，与实时传输协议（RTP）不同，HLS 可以穿过任何允许 HTTP 数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。\nHLS 基于 HTTP 协议实现，传输内容包括两部分，一是 M3U8 描述文件，二是 TS 媒体文件。\n为什么要用 TS 而不是 MP4？ # 这是因为两个 TS 片段可以无缝拼接，播放器能连续播放， 而 MP4 文件由于编码方式的原因，两段 MP4 不能无缝拼接，播放器连续播放两个 MP4 文件会出现破音和画面间断，影响用户体验。\n而且如果要在一段长达一小时的视频中跳转，如果使用单个 MP4 格式的视频文件，并且也是用 HTTP 协议，那么需要代理服务器支持 HTTP range request 获取大文件中的一部分。 这样的话，对于代理服务器的性能来说要求较高。 而 HTTP Live Streaming 则只需要根据列表文件中的时间轴找出对应的 TS 片段下载即可， 不需要 range request，对代理服务器的要求小很多。 所有代理服务器都支持小文件的高效缓存。\n流媒体协议 # RTP/RTCP # RTP(Real-time Transport Protocol) 是用于 Internet 上针对多媒体数据流的一种传输协议。\nRTCP 为 RTP 媒体流提供信道外控制。 RTCP 定期在流多媒体会话参加者之间传输控制数据。 RTCP 的主要功能是为 RTP 所提供的服务质量提供反馈。\nRTP 使用一个 偶数 UDP port， 而 RTCP 则使用 RTP 的下一个 port，也就是一个奇数 port。\nRTSP # RTMP # H264 # H265 # TS # MPEG2-TS 传输流 （MPEG-2 Transport Stream；又称 MPEG-TS、MTS、TS） 是一种传输和存储包含视频、音频与通信协议各种数据的标准格式，用于数字电视广播系统，如 DVB、ATSC、ISDB、IPTV 等等。\nRTP Payload type # 有效负载 (载荷) 类型\n有些负载类型由于诞生的较晚，没有具体的 PT 值，只能使用动态（dynamic）PT 值，即 96 到 127， 这就是为什么大家普遍指定 H264 的 PT 值为 96。\nPayload identifiers 96–127 are used for payloads defined dynamically during a session. It is recommended to dynamically assigned port numbers, although port numbers 5004 and 5005 have been registered for use of the profile when a dynamically assigned port is not required.\nMP2T (Payload type: 33)\nRFC 2250: RTP Payload Format for MPEG1/MPEG2 Video\n参考：\nRTP 有效负载 (载荷) 类型 (RTP Payload Type) "},{"id":873,"href":"/note-cs/docs/study/skill/stream-media/stream-media/live-tech/","title":"直播技术","section":"流媒体技术","content":" 直播技术 # 摄像头视频采集，原始视频数据：RGB/YUV 话筒音频采集，原始音频数据：PCM 视频文件编码，RGB/YUV -\u0026gt; H.264/H.265 音频文件编码，PCM -\u0026gt; AAC 编码为有流媒体特性的多媒体容器格式（Multimedia Container Format）， 如 FLV/TS/RTMP Package 推流到流媒体服务器 应用层：HLS/RTSP/RTMP 传输层：RTP/RTCP 网络层：RSVP 服务端处理 转码/录制/截图/鉴黄 生成拉流 URL 拉流到客户端 应用层：HLS/RTMP 传输层：RTP/RTCP 网络层：RSVP 解复用，多媒体容器格式（FLV/TS/RTMP Package）的流 -\u0026gt; 音视频数据（H.264/AAC） 解码视频文件为 YUV/RGB，解码音频文件为 PCM 硬解码（GPU 解码，CPU 辅助） 软解码（CPU 解码） 音画同步 视频数据（YUV/RGB）发送到视频输出设备，音频数据（PCM）发送到音频输出设备 "},{"id":874,"href":"/note-cs/docs/study/skill/stream-media/stream-media/video-codec/","title":"视频编码","section":"流媒体技术","content":" 视频编码 # 年份 标准 制定组织 解除著作权保护（DRM-free） 主要应用 1984 H.120 ITU-T 是 1990 H.261 ITU-T 是 视频会议、视频通话 1993 MPEG-1 第二部分 ISO／IEC 是 影音光盘（VCD） 1995 H.262/MPEG-2 第二部分 ISO／IEC、ITU-T 否 DVD 影碟（DVD-Video）、 蓝光（ Blu-Ray）影碟、数字视频广播（DVB）、SVCD 1996 H.263 ITU-T 视频会议、视频通话、 3G 手机视频（3GP） 1999 MPEG-4 第二部分 ISO／IEC 否 2003 H.264/MPEG-4 AVC ISO／IEC、ITU-T 否 蓝光（ Blu-Ray）影碟、数字视频广播（DVB）、iPod 视频、 高清 DVD（HD DVD） 2013 H.265/High Efficiency Video Coding ISO/IEC、ITU-T 否 尚未普及 AVC (H.264) # H.264，又称为 MPEG-4 第 10 部分，高级视频编码（英语： MPEG-4 Part 10, Advanced Video Coding ，缩写为 MPEG-4 AVC）是一种面向块，基于运动补偿的视频编码标准（英语：Advanced Video Coding） 。\nHEVC (H.265) # 高效率视频编码（ High Efficiency Video Coding，简称 HEVC），又称为 H.265 和 MPEG-H 第 2 部分，是一种视频压缩标准，被视为是 ITU-T H.264/MPEG-4 AVC 标准的继任者。\n比起 H.264/AVC，H.265/HEVC 提供了更多不同的工具来降低码率， 以编码单位来说，H.264 中每个宏块（macroblock/MB）大小都是固定的 16x16 像素，而 H.265 的编码单位可以选择从最小的 8x8 到最大的 64x64。 那么，在相同的图象质量下，相比于 H.264，通过 H.265 编码的视频大小将减少大约 39%-44%；\nVVC (H.266) # Versatile Video Coding, MPEG-I Part 3\n应用 # CD # Compact Disc\n激光唱片，镭射唱片\nCD 在 1982 年面世，至今仍然是商业录音的标准存储设备。\n在 CD 尚未发明之前，音响系统都是属于模拟信号， 音乐的来源大多是 30 公分直径的密纹唱片、收音机以及录音机等，CD 发明之前没有数字音响。\nVCD # Video Compact Disc\n影音光盘，又称影音压缩光盘，是一种在光盘（Compact Disc）上存储视频信息的标准。\nVCD 标准由索尼、飞利浦、 JVC、 松下电器等电器生产厂商联合于 1993 年制定，属于数字光盘的白皮书标准。\nDVD # Digital Versatile Disc\nDVD 原是 Digital Video Disc（数字视频光盘）的首字母缩略字，因初推出时大多厂商只针对视频方面的宣传及推出产品，而且当时的电脑产业对高容量的存储媒体没有太大需求。 后因定位更改，于 1995 年规格正式确立时，重新定义为 Digital Versatile Disc（数字多用途光盘），但旧称的 Digital Video Disc 也有人继续沿用。现在一般都只以 “DVD” 作为其称呼。\nHD DVD # High Definition Digital Versatile Disc\nHD DVD（英语：High Definition DVD ，“高清晰度 DVD” 或 “高清 DVD”）是一种以蓝光镭射技术存储数字格式信息于光盘上的产品，现已发展成高清晰度 DVD 标准，由 HD DVD 推广协会负责制定及开发。HD DVD 与其竞争对手 Blu-ray Disc（简写为 “BD”，蓝光光盘）有些许些相似之处，光盘均是和 CD 同样大小（直径 120mm）的光学数字格式存储介质，使用 405 纳米波长的蓝色镭射。\nHD DVD 由东芝、 NEC、 三洋电机等企业组成的 HD DVD 推广协会负责推广，惠普（同时支持 BD）、 微软及英特尔等相继加入 HD DVD 阵营，其中的主流片厂环球影业亦是成员之一。\n但在 2008 年，随着原先支持 HD DVD 的华纳公司宣布脱离 HD DVD，以及美国数家连锁卖场决定支持蓝光产品，东芝公司终在 2008 年 2 月 19 日正式宣布将终止 HD DVD 事业。\nBD 蓝光光盘 # Blu-ray Disc\n蓝光光盘是由索尼及松下电器等企业组成的蓝光光盘联盟（Blu-ray Disc Association）策划的次世代光盘规格，并以索尼为首于 2006 年开始全面推动相关产品。\nUHD-BD # 超高清蓝光光盘（英语： Ultra HD Blu-ray ）是改良型蓝光光盘的数字光盘数据存储格式。 超高清蓝光光盘的碟片尺寸规格虽与传统的 CD、DVD 及现有的蓝光光盘相同，并且采用和传统蓝光盘相似的碟片和光头。 但影音的格式有出入而专用的播放器的软硬件不兼容，需使用支持读取超高清蓝光光盘播放器才可播放，而以新的格式可以用和传统蓝光相同容量下，播放更高清晰度的影片或延长播放时间。 超高清蓝光光盘支持 4KUHD（分辨率：3840×2160）视频，帧速率高达每秒 60 帧，使用高效率视频编码（H.265）进行编码。\n"},{"id":875,"href":"/note-cs/docs/basic/pl/haskell/","title":"Haskell","section":"1.5 编程语言","content":" Haskell 学习笔记 # "},{"id":876,"href":"/note-cs/docs/basic/pl/lua/","title":"Lua","section":"1.5 编程语言","content":" Lua 学习笔记 # Lua（发音： /ˈluːə/，葡萄牙语含义是月亮）是一个简洁、轻量、可扩展的 脚本语言。\nLua 有着相对简单的 C API 而很容易嵌入应用中。很多应用程序使用 Lua 作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。\n参考：Lua Wikipedia\nLua 源码解析 # "},{"id":877,"href":"/note-cs/docs/basic/pl/ruby/","title":"Ruby","section":"1.5 编程语言","content":" Ruby 学习笔记 # "},{"id":878,"href":"/note-cs/docs/basic/pl/zig/","title":"Zig","section":"1.5 编程语言","content":" Zig 学习笔记 # ziglang/zig "},{"id":879,"href":"/note-cs/docs/basic/pl/assembly/","title":"汇编","section":"1.5 编程语言","content":" 汇编语言学习笔记 # "},{"id":880,"href":"/note-cs/docs/basic/pl/shell/","title":"Shell","section":"1.5 编程语言","content":" Shell 学习笔记 # Shell 与 Linux 的关系 # Shell 本质应该是 CLI，它是一个让用户通过命令行来实现和系统交互的接口。\n"}]